{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a89f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Nixtla/neuralforecast/blob/main/nbs/models.deepar.ipynb\n",
    "# https://github.com/Nixtla/neuralforecast/blob/main/nbs/losses.pytorch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506b73c",
   "metadata": {},
   "source": [
    "# DeepAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3970eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions import NegativeBinomial, Normal, Poisson\n",
    "from torch.distributions import constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32f3ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_to_outputs(level):\n",
    "    qs = sum([[50-l/2, 50+l/2] for l in level], [])\n",
    "    output_names = sum([[f'-lo-{l}', f'-hi-{l}'] for l in level], [])\n",
    "\n",
    "    # Sort in increasing order\n",
    "    sort_idx = np.argsort(qs)\n",
    "    quantiles = np.array(qs)[sort_idx]\n",
    "    output_names = list(np.array(output_names)[sort_idx])\n",
    "    \n",
    "    # Add median by default\n",
    "    quantiles = np.concatenate([np.array([50]), quantiles])\n",
    "    quantiles = torch.Tensor(quantiles) / 100\n",
    "    output_names.insert(0, '-median')\n",
    "\n",
    "    return quantiles, output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84080ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_scale_decouple(output, loc=None, scale=None, eps: float = 0.2):\n",
    "    mean, std = output\n",
    "    std = F.softplus(std)\n",
    "    if (loc is not None) and (scale is not None):\n",
    "        mean = (mean * scale) + loc\n",
    "        std = (std + eps) * scale\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "def nbinomial_scale_decouple(output, loc=None, scale=None):\n",
    "    mu, alpha = output\n",
    "    mu = F.softplus(mu) + 1e-08\n",
    "    alpha = F.softplus(alpha) + 1e-08\n",
    "    if (loc is not None) and (scale is not None):\n",
    "        mu = mu * scale + loc\n",
    "        alpha = alpha / (scale + 1.)\n",
    "\n",
    "    total_count = 1.0 / alpha\n",
    "    probs = (mu * alpha / (1.0 + mu * alpha)) + 1e-8\n",
    "    return total_count, probs\n",
    "\n",
    "\n",
    "def poisson_scale_decouple(output, loc=None, scale=None):\n",
    "    eps = 1e-10\n",
    "    rate, _ = output\n",
    "    if (loc is not None) and (scale is not None):\n",
    "        rate = (rate * scale) + loc\n",
    "    rate = F.softplus(rate) + eps\n",
    "    return (rate, )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d680b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistributionLoss\n",
    "\n",
    "class DistributionLoss(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        distribution: str,\n",
    "        level=[80, 90],  # Confidence levels of prediction intervals\n",
    "        num_samples=1000,\n",
    "        return_params=False,\n",
    "        **distribution_kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        qs, output_names = level_to_outputs(level)\n",
    "        qs = torch.Tensor(qs)\n",
    "        self.quantiles = torch.nn.Parameter(qs, requires_grad=False)\n",
    "        self.output_names = output_names\n",
    "\n",
    "        available_distributions = dict(\n",
    "            Normal=Normal,\n",
    "            NegativeBinomial=NegativeBinomial,\n",
    "            Poisson=Poisson\n",
    "        )\n",
    "        scale_decouples = dict(\n",
    "            Normal=normal_scale_decouple,\n",
    "            NegativeBinomial=nbinomial_scale_decouple,\n",
    "            Poisson=poisson_scale_decouple,\n",
    "        )\n",
    "        param_names = dict(\n",
    "            Normal=[\"-loc\", \"-scale\"],\n",
    "            NegativeBinomial=[\"-total_count\", \"-logits\"], \n",
    "            Poisson=[\"-loc\"],\n",
    "        )\n",
    "        \n",
    "        assert distribution in available_distributions\n",
    "        self.distribution = distribution\n",
    "        self._base_distribution = available_distributions[distribution]\n",
    "        self.scale_decouple = scale_decouples[distribution]\n",
    "        self.param_names = param_names[distribution]\n",
    "        self.outputsize_multiplier = len(self.param_names)\n",
    "        self.num_samples = num_samples\n",
    "        self.return_params = return_params\n",
    "        if self.return_params:\n",
    "            self.output_names = self.output_names + self.param_names\n",
    "        self.distribution_kwargs = distribution_kwargs\n",
    "        \n",
    "    \n",
    "    def _domain_map(self, input: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Maps output of neural network to domain of distribution loss\n",
    "        \"\"\"\n",
    "        output = torch.tensor_split(input, self.outputsize_multiplier, dim=2)\n",
    "        return output\n",
    "        \n",
    "    \n",
    "    def get_distribution(self, distr_args, **distribution_kwargs) -> Distribution:\n",
    "        distr = self._base_distribution(*distr_args, **distribution_kwargs)\n",
    "        self.distr_mean = distr.mean\n",
    "        \n",
    "        if self.distribution in ('Poisson', 'NegativeBinomial'):\n",
    "              distr.support = constraints.nonnegative\n",
    "        return distr\n",
    "    \n",
    "    def sample(self, distr_args: torch.Tensor, num_samples=None):\n",
    "        if num_samples is None:\n",
    "            num_samples = self.num_samples\n",
    "        \n",
    "        # Instantiate Scale Decoupled Distribution\n",
    "        distr = self.get_distribution(distr_args=distr_args, **self.distribution_kwargs)\n",
    "        samples = distr.sample(sample_shape=(num_samples,))\n",
    "        samples = samples.permute(1, 2, 3, 0)  # [samples, B, H, N] -> [B, H, N, samples]\n",
    "        \n",
    "        # Compute mean and quantiles\n",
    "        sample_mean = torch.mean(samples, dim=-1, keepdim=True)\n",
    "        quants = torch.quantile(samples, self.quantiles, dim=-1)\n",
    "        quants = quants.permute(1, 2, 3, 0)  # [Q, B, H, N] -> [B, H, N, Q]\n",
    "\n",
    "        return samples, sample_mean, quants\n",
    "    \n",
    "    def __call__(self, y: torch.Tensor, distr_args: torch.Tensor):\n",
    "        # Instantiate Scale Decoupled Distribution\n",
    "        distr = self.get_distribution(distr_args=distr_args, **self.distribution_kwargs)\n",
    "        loss_values = -distr.log_prob(y)\n",
    "        return loss_values.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1733b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "distr_loss = DistributionLoss(distribution=\"Normal\", level=[80, 90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17e6f6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.5000, 0.0500, 0.1000, 0.9000, 0.9500])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distr_loss.quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c219d537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-median',\n",
       " np.str_('-lo-90'),\n",
       " np.str_('-lo-80'),\n",
       " np.str_('-hi-80'),\n",
       " np.str_('-hi-90')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distr_loss.output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ead2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = distr_loss.get_distribution(torch.Tensor([0.0, 1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e491db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8742,  1.0081, -0.0538],\n",
       "        [-0.1986, -0.7672,  2.0808],\n",
       "        [ 0.1821,  0.3600,  0.2400],\n",
       "        [-0.0665,  0.6896, -0.7004],\n",
       "        [ 2.1068, -0.3302, -0.8646],\n",
       "        [-0.2016, -0.2594, -0.3241],\n",
       "        [-0.4470,  0.1718,  1.6635],\n",
       "        [ 2.2733,  1.1294, -0.1248],\n",
       "        [ 1.5230,  0.2701,  0.4043],\n",
       "        [ 0.0521,  0.0704, -0.8703],\n",
       "        [ 0.1721, -0.6784, -0.1979],\n",
       "        [-0.9488, -0.8515, -1.3582],\n",
       "        [-1.2985,  0.6006, -0.0716],\n",
       "        [ 0.8799, -0.7836, -0.1932],\n",
       "        [-0.8165, -0.6849,  0.9421],\n",
       "        [-0.7901,  0.0940, -0.0192],\n",
       "        [-0.0060, -2.0451,  0.4674],\n",
       "        [-0.1573, -0.1187,  1.0787],\n",
       "        [-0.0842, -1.9280, -0.4245],\n",
       "        [-1.4284, -0.2805,  2.5322],\n",
       "        [ 0.4390, -0.9358,  0.7516],\n",
       "        [ 0.0729, -0.0640,  1.1803],\n",
       "        [ 0.9518, -0.9017, -0.8626],\n",
       "        [ 0.6758,  1.1942, -1.2869],\n",
       "        [ 2.7938, -0.9241, -0.9130],\n",
       "        [-0.0929,  1.0451,  1.5427],\n",
       "        [-0.7759, -0.2445, -0.6072],\n",
       "        [ 0.5347, -0.1787,  0.2090],\n",
       "        [-1.8353,  0.7468,  1.0587],\n",
       "        [-0.8888,  0.4505, -1.2870],\n",
       "        [-0.6273, -0.0292,  0.2222],\n",
       "        [-1.3140,  0.9313, -0.7709],\n",
       "        [-0.2614,  1.6532,  0.5625],\n",
       "        [ 1.4142,  1.7154, -1.0044],\n",
       "        [-1.4392, -0.9354,  1.0949],\n",
       "        [-0.1874,  0.1133,  2.7003],\n",
       "        [ 1.4992, -1.7638, -0.5097],\n",
       "        [ 0.9709,  0.2079, -0.0104],\n",
       "        [ 0.0785, -1.6772, -1.4064],\n",
       "        [ 1.3177, -1.2150, -0.1396],\n",
       "        [-1.4434, -0.3877, -0.4057],\n",
       "        [-0.6783, -1.9905, -1.6023],\n",
       "        [-0.3611, -1.2677, -0.5289],\n",
       "        [ 0.4279, -0.1160, -2.6944],\n",
       "        [-1.1735,  0.4212,  0.6231],\n",
       "        [ 2.3913, -0.8200,  1.3610],\n",
       "        [-2.4026,  0.5849, -1.0420],\n",
       "        [ 0.3988, -0.4845, -0.1093],\n",
       "        [ 0.9231,  0.3907, -0.4920],\n",
       "        [ 0.8594,  0.7150,  0.6025],\n",
       "        [-0.2875,  1.1122, -1.2899],\n",
       "        [-0.1135,  0.2421, -1.1151],\n",
       "        [ 0.6494,  0.9193, -0.9673],\n",
       "        [ 0.9114, -0.4340, -0.4044],\n",
       "        [-0.5013,  1.9065, -1.5955],\n",
       "        [-0.3949, -1.4163,  0.6594],\n",
       "        [ 0.9070, -0.2632, -0.1165],\n",
       "        [-0.3837, -0.6685,  0.0653],\n",
       "        [-0.2737, -2.8783, -0.7694],\n",
       "        [-1.8818, -0.7291,  1.8256],\n",
       "        [ 1.1708, -2.6686, -1.3151],\n",
       "        [ 0.3598,  0.6886,  1.4374],\n",
       "        [ 0.9183, -0.4070,  2.1974],\n",
       "        [ 0.0249, -3.1132,  1.0940],\n",
       "        [-0.2986, -0.6454, -2.3586],\n",
       "        [-1.9646, -0.1179,  0.4727],\n",
       "        [ 0.4207,  0.5168,  0.6962],\n",
       "        [ 0.9654, -0.8853,  0.2921],\n",
       "        [ 1.1445,  0.6274,  1.1579],\n",
       "        [-2.0117, -1.6794,  0.2256],\n",
       "        [ 0.5190,  1.2554, -0.3900],\n",
       "        [-0.1399, -1.5754, -0.4230],\n",
       "        [-3.5595, -0.7945, -0.2311],\n",
       "        [ 0.5142, -0.0439, -0.2900],\n",
       "        [-0.4232,  0.5155,  0.6132],\n",
       "        [-0.0979, -1.4311, -0.4277],\n",
       "        [ 0.9400, -0.0400, -0.6157],\n",
       "        [ 0.3038, -0.8238,  1.2591],\n",
       "        [-0.5257,  0.6437,  0.9288],\n",
       "        [-1.6338, -0.5356,  0.9539],\n",
       "        [-0.1862, -0.2020,  0.7247],\n",
       "        [ 0.5952, -1.6076, -1.0104],\n",
       "        [-0.9381, -0.0284,  0.6301],\n",
       "        [ 0.4362, -0.9911,  0.9553],\n",
       "        [-0.0939, -0.2201,  0.8953],\n",
       "        [-1.8710,  0.3029,  1.0124],\n",
       "        [ 1.3496,  0.8219, -0.2037],\n",
       "        [ 1.5792,  0.0167,  1.2298],\n",
       "        [ 0.2859,  0.1137,  0.5362],\n",
       "        [ 0.2239,  0.1526, -0.1409],\n",
       "        [-0.1898,  1.8152, -0.0966],\n",
       "        [-0.1237,  0.7735, -0.1199],\n",
       "        [-0.5529, -0.5810,  0.7115],\n",
       "        [-0.1780, -0.1820, -0.7193],\n",
       "        [ 0.2074,  0.4241,  1.0485],\n",
       "        [-0.6003,  0.2967,  0.9960],\n",
       "        [-0.9281, -0.9307, -0.7357],\n",
       "        [ 0.3761,  1.5155,  0.1950],\n",
       "        [-0.2694,  0.0141,  0.1993],\n",
       "        [ 1.6551,  0.0126,  0.5970]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distr.sample(sample_shape=(100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f23815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
