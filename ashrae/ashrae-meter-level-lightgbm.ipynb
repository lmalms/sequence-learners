{
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "sourceId": 9994,
                    "databundleVersionId": 752467,
                    "sourceType": "competition"
                },
                {
                    "sourceId": 10748143,
                    "sourceType": "datasetVersion",
                    "datasetId": 6473980
                }
            ],
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": false
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "!pip install scikit-learn==1.3.1 -q",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:46:32.409818Z",
                    "iopub.execute_input": "2025-02-12T07:46:32.410181Z",
                    "iopub.status.idle": "2025-02-12T07:46:35.913276Z",
                    "shell.execute_reply.started": "2025-02-12T07:46:32.410152Z",
                    "shell.execute_reply": "2025-02-12T07:46:35.911405Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "import gc\n\nimport lightgbm as lgbm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pyarrow.parquet as pq\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import TargetEncoder, OrdinalEncoder",
            "metadata": {
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:46:35.915064Z",
                    "iopub.execute_input": "2025-02-12T07:46:35.915518Z",
                    "iopub.status.idle": "2025-02-12T07:46:37.508811Z",
                    "shell.execute_reply.started": "2025-02-12T07:46:35.915470Z",
                    "shell.execute_reply": "2025-02-12T07:46:37.507711Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "SUBMISSION_RUN = True",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:46:37.511030Z",
                    "iopub.execute_input": "2025-02-12T07:46:37.511824Z",
                    "iopub.status.idle": "2025-02-12T07:46:37.515725Z",
                    "shell.execute_reply.started": "2025-02-12T07:46:37.511787Z",
                    "shell.execute_reply": "2025-02-12T07:46:37.514880Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Constants\nINPUT_DATA_PATH = \"/kaggle/input/ashrae-energy-prediction\"\n\nMIN_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-01-01 00:00:00\")\nMAX_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-12-31 23:00:00\")\nMIN_TEST_TIMESTAMP = pd.Timestamp(\"2017-01-01 00:00:00\")\nMAX_TEST_TIMESTAMP = pd.Timestamp('2018-12-31 23:00:00')\n\nDATA_RESOLUTION = \"1h\"\n\nVALIDATION_PERIODS = [\n    (pd.Timestamp(\"2016-08-01 00:00:00\"), pd.Timestamp(\"2016-09-01 00:00:00\")),\n    (pd.Timestamp(\"2016-09-01 00:00:00\"), pd.Timestamp(\"2016-10-01 00:00:00\")),\n    (pd.Timestamp(\"2016-10-01 00:00:00\"), pd.Timestamp(\"2016-11-01 00:00:00\")),\n    (pd.Timestamp(\"2016-11-01 00:00:00\"), pd.Timestamp(\"2016-12-01 00:00:00\")),\n    (pd.Timestamp(\"2016-12-01 00:00:00\"), pd.Timestamp(\"2017-01-01 00:00:00\")),\n]\n\n# VALIDATION_PERIODS = [\n#     (pd.Timestamp(\"2016-08-01 00:00:00\"), pd.Timestamp(\"2016-10-01 00:00:00\")),\n#     (pd.Timestamp(\"2016-09-01 00:00:00\"), pd.Timestamp(\"2016-11-01 00:00:00\")),\n#     (pd.Timestamp(\"2016-10-01 00:00:00\"), pd.Timestamp(\"2016-12-01 00:00:00\")),\n#     (pd.Timestamp(\"2016-11-01 00:00:00\"), pd.Timestamp(\"2017-01-01 00:00:00\")),\n# ]\n\nMETER_IDS = [0, 1, 2, 3]",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:46:37.516912Z",
                    "iopub.execute_input": "2025-02-12T07:46:37.517115Z",
                    "iopub.status.idle": "2025-02-12T07:46:37.538432Z",
                    "shell.execute_reply.started": "2025-02-12T07:46:37.517098Z",
                    "shell.execute_reply": "2025-02-12T07:46:37.537331Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Data loading",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "CATEGORY_COLS = [\"building_id\", \"meter_id\", \"site_id\", \"primary_use\"]\nUINT8_COLS = [\"hour\", \"day_of_week\", \"month\"]\n\n\ndef drop_cols(df: pd.DataFrame) -> pd.DataFrame:\n    cols_to_drop = [\"hour\", \"day_of_week\", \"month\"]\n    cols_to_drop = cols_to_drop + ([\"timestamp\"] if SUBMISSION_RUN else [])\n    df = df.drop(columns=cols_to_drop)\n    return df\n\n\ndef cast_dtypes(df: pd.DataFrame, verbose: bool = False) -> pd.DataFrame:\n\n    # Timestamps\n    try:\n        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n    except KeyError:\n        if verbose:\n            print(\"Col 'timestamp' missing from df. Skipping ...\")\n\n    # Categories\n    for col in CATEGORY_COLS:\n        try:\n            df[col] = df[col].astype(\"category\")\n        except KeyError:\n            if verbose:\n                print(f\"Col '{col}' missing from df. Skipping ...\")\n\n    # UINT8\n    for col in UINT8_COLS:\n        try:\n            if df[col].max() > np.iinfo(np.uint8).max:\n                if verbose:\n                    print(f\"Col max for '{col}' exceeds np.uint8 max. Skipping ...\")\n                continue\n            df[col] = df[col].astype(np.uint8)\n        except KeyError:\n            if verbose:\n                print(f\"Col '{col}' missing from df. Skipping ...\")\n    \n    return df",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:46:37.539551Z",
                    "iopub.execute_input": "2025-02-12T07:46:37.539908Z",
                    "iopub.status.idle": "2025-02-12T07:46:37.564252Z",
                    "shell.execute_reply.started": "2025-02-12T07:46:37.539862Z",
                    "shell.execute_reply": "2025-02-12T07:46:37.563084Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "train_dataset = pd.read_parquet(\"/kaggle/input/ashrae-iii/train_df.parquet\")\ntrain_dataset = drop_cols(train_dataset)\ntrain_dataset = cast_dtypes(train_dataset, verbose=True)",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:46:37.565271Z",
                    "iopub.execute_input": "2025-02-12T07:46:37.565556Z",
                    "iopub.status.idle": "2025-02-12T07:46:43.321147Z",
                    "shell.execute_reply.started": "2025-02-12T07:46:37.565533Z",
                    "shell.execute_reply": "2025-02-12T07:46:43.319843Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Cross Validation",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "CATEGORICAL_FEATURES = [\"site_id\", \"primary_use\"]\nNUMERICAL_FEATURES = [\n    \"square_feet\",\n    \"floor_count\",\n    \"air_temperature\",\n    \"cloud_coverage\",\n    \"dew_temperature\",\n    \"precip_depth_1_hr\",\n    \"sea_level_pressure\",\n    \"wind_direction_sin\",\n    \"wind_direction_cos\",\n    \"wind_speed\",\n    \"air_temperature_smoothed_lag_1\",\n    \"air_temperature_smoothed_lag_2\",\n    \"air_temperature_smoothed_lag_3\",\n    \"air_temperature_smoothed_lag_4\",\n    \"air_temperature_smoothed_lag_5\",\n    \"air_temperature_smoothed_rolling_mean_12\",\n    \"air_temperature_smoothed_rolling_mean_24\",\n    \"dew_temperature_smoothed_lag_1\",\n    \"dew_temperature_smoothed_lag_2\",\n    \"dew_temperature_smoothed_lag_3\",\n    \"dew_temperature_smoothed_lag_4\",\n    \"dew_temperature_smoothed_lag_5\",\n    \"dew_temperature_smoothed_rolling_mean_12\",\n    \"dew_temperature_smoothed_rolling_mean_24\",\n    \"sea_level_pressure_smoothed_lag_1\",\n    \"sea_level_pressure_smoothed_lag_2\",\n    \"sea_level_pressure_smoothed_lag_3\",\n    \"sea_level_pressure_smoothed_lag_4\",\n    \"sea_level_pressure_smoothed_lag_5\",\n    \"sea_level_pressure_smoothed_rolling_mean_12\",\n    \"sea_level_pressure_smoothed_rolling_mean_24\",\n    \"hour_sin\",\n    \"hour_cos\",\n    \"day_of_week_sin\",\n    \"day_of_week_cos\",\n    \"month_sin\",\n    \"month_cos\",\n    \"is_weekend\",\n    \"building_age_years\",\n    \"building_area_square_feet\",\n    \"relative_humidity\",\n    \"cold_chill\",\n    \"apparent_temperature\",\n    \"heat_index\",\n]\n\n# building_id is encoded differently for different meter ids\nFEATURES = CATEGORICAL_FEATURES + NUMERICAL_FEATURES + [\"building_id\"]\nLABEL = \"meter_reading\"",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:46:43.322090Z",
                    "iopub.execute_input": "2025-02-12T07:46:43.322379Z",
                    "iopub.status.idle": "2025-02-12T07:46:43.328852Z",
                    "shell.execute_reply.started": "2025-02-12T07:46:43.322353Z",
                    "shell.execute_reply": "2025-02-12T07:46:43.327302Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "N_ITERATIONS = 2000\nTRAIN_PARAMETERS = {\n    \"objective\": \"mean_squared_error\",\n    \"learning_rate\": 0.01,\n    \"seed\": 1,\n    \"max_bin\": 255,\n    \"num_leaves\": 2 ** 6 - 1,\n    \"min_data_in_leaf\": 1000,\n    \"bagging_fraction\": 0.75,\n    \"bagging_freq\": 1,\n    \"feature_fraction\": 0.8,\n    \"metric\": [\"rmse\"],\n}",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:46:43.331725Z",
                    "iopub.execute_input": "2025-02-12T07:46:43.332100Z",
                    "iopub.status.idle": "2025-02-12T07:46:43.360624Z",
                    "shell.execute_reply.started": "2025-02-12T07:46:43.332070Z",
                    "shell.execute_reply": "2025-02-12T07:46:43.358832Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "def get_column_transformer(meter_id: int) -> ColumnTransformer:\n    ordinal_encoder = OrdinalEncoder(\n        categories=\"auto\",\n        handle_unknown=\"use_encoded_value\",\n        unknown_value=-1,\n        dtype=np.int32,\n    )\n    target_encoder = TargetEncoder(\n        categories=\"auto\",\n        target_type=\"continuous\",\n        smooth=\"auto\",\n    )\n\n    transformers = [(\"ordinal_encoder\", ordinal_encoder, [\"primary_use\"])]\n    if meter_id in (1, 2):\n        transformers += [(\"target_encoder\", target_encoder, [\"building_id\"])]\n    \n    transformer = ColumnTransformer(\n        transformers=transformers,\n        remainder=\"passthrough\",\n        verbose_feature_names_out=False,\n    )\n    transformer.set_output(transform=\"pandas\")\n    return transformer\n\n\ndef get_feature_dtypes(meter_id: int):\n    dtypes = {\n        \"building_id\": np.float32 if meter_id in (1, 2) else \"category\",\n        \"primary_use\": \"category\",\n    }\n    return dtypes\n\n\ndef target_transform(y: pd.Series) -> pd.Series:\n    return np.log1p(y)",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:46:43.362103Z",
                    "iopub.execute_input": "2025-02-12T07:46:43.362500Z",
                    "iopub.status.idle": "2025-02-12T07:46:43.385885Z",
                    "shell.execute_reply.started": "2025-02-12T07:46:43.362468Z",
                    "shell.execute_reply": "2025-02-12T07:46:43.384194Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "def train_valid_split(train_df: pd.DataFrame):\n    for val_start, val_end in VALIDATION_PERIODS:\n        train_mask = train_df[\"timestamp\"] < val_start\n        test_mask = (train_df[\"timestamp\"] >= val_start) & (train_df[\"timestamp\"] < val_end)\n        yield train_df.loc[train_mask], train_df.loc[test_mask]\n\n\ndef train_predict_score(train_df: pd.DataFrame, valid_df: pd.DataFrame):\n    results_by_meter_id = {}\n    for meter_id in METER_IDS:\n        print(f\"Running train/predict/score for meter id {meter_id}\")\n        \n        train_meter_df = train_df[train_df[\"meter_id\"] == meter_id]\n        valid_meter_df = valid_df[valid_df[\"meter_id\"] == meter_id]\n\n        X_train, y_train = train_meter_df[FEATURES], train_meter_df[LABEL]\n        X_valid, y_valid = valid_meter_df[FEATURES], valid_meter_df[LABEL]\n\n        print(f\"Train shape: {X_train.shape, y_train.shape}\")\n        print(f\"Valid shape: {X_valid.shape, y_valid.shape}\\n\")\n\n        # Target transform\n        y_train = target_transform(y_train)\n        y_valid = target_transform(y_valid)\n\n        # Feature transforms\n        col_transformer = get_column_transformer(meter_id=meter_id)\n        col_transformer.fit(X_train, y_train)\n        X_train = col_transformer.transform(X_train)\n        X_valid = col_transformer.transform(X_valid)\n        \n        dtypes = get_feature_dtypes(meter_id)\n        X_train = X_train.astype(dtypes)\n        X_valid = X_valid.astype(dtypes)\n\n        # Train LightGBM\n        cat_features = CATEGORICAL_FEATURES + ([\"building_id\"] if meter_id in (0, 3) else [])\n        ds_params = {\"categorical_feature\": cat_features}\n        train_ds = lgbm.Dataset(data=X_train, label=y_train, **ds_params)\n        valid_ds = lgbm.Dataset(data=X_valid, label=y_valid, **ds_params)\n\n        train_valid_loss = {}\n        model = lgbm.train(\n            TRAIN_PARAMETERS,\n            num_boost_round=N_ITERATIONS,\n            train_set=train_ds,\n            valid_sets=[train_ds, valid_ds],\n            valid_names=[\"train\", \"valid\"],\n            callbacks=[\n                lgbm.log_evaluation(period=10),\n                lgbm.record_evaluation(train_valid_loss),\n            ]\n        )\n\n        y_hat = model.predict(X_valid)\n        results = {\"y_true\": y_valid, \"y_pred\": y_hat, \"train_valid_loss\": train_valid_loss}\n        results_by_meter_id[meter_id] = results\n\n        print(\"====================================\")\n\n    return results_by_meter_id",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:46:43.387132Z",
                    "iopub.execute_input": "2025-02-12T07:46:43.387582Z",
                    "iopub.status.idle": "2025-02-12T07:46:43.420907Z",
                    "shell.execute_reply.started": "2025-02-12T07:46:43.387546Z",
                    "shell.execute_reply": "2025-02-12T07:46:43.419053Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "if not SUBMISSION_RUN:\n    cv_results = []\n    for i, (train_df, valid_df) in enumerate(train_valid_split(train_dataset)):\n        print(f\"Running cross validation on split {i}\\n\")\n        results = train_predict_score(train_df, valid_df)\n        cv_results.append(results)\n        print(\"====================================\")\n\nelse:\n    print(f\"Training models for submission run.\")\n    COL_TRANSFORMERS, MODELS = {}, {}\n    for meter_id in METER_IDS:\n        print(f\"Training models for meter id {meter_id}\")\n        \n        train_meter_df = train_dataset[train_dataset[\"meter_id\"] == meter_id]\n        X_train, y_train = train_meter_df[FEATURES], train_meter_df[LABEL]\n        print(f\"Train shape: {X_train.shape, y_train.shape}\")\n\n        # Target and feature transform\n        y_train = target_transform(y_train)\n\n        col_transformer = get_column_transformer(meter_id=meter_id)\n        col_transformer.fit(X_train, y_train)\n        X_train = col_transformer.transform(X_train)\n        dtypes = get_feature_dtypes(meter_id)\n        X_train = X_train.astype(dtypes)\n\n        # Train LightGBM\n        cat_features = CATEGORICAL_FEATURES + ([\"building_id\"] if meter_id in (0, 3) else [])\n        ds_params = {\"categorical_feature\": cat_features}\n        train_ds = lgbm.Dataset(data=X_train, label=y_train, **ds_params)\n        model = lgbm.train(\n            TRAIN_PARAMETERS,\n            num_boost_round=N_ITERATIONS,\n            train_set=train_ds,\n            valid_sets=[train_ds],\n            valid_names=[\"train\"],\n            callbacks=[lgbm.log_evaluation(period=10)]\n        )\n\n        # Save transformer and model for inference\n        COL_TRANSFORMERS[meter_id] = col_transformer\n        MODELS[meter_id] = model\n\n        print(\"====================================\")\n\n    del train_dataset\n    gc.collect()",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:46:43.422088Z",
                    "iopub.execute_input": "2025-02-12T07:46:43.422428Z",
                    "iopub.status.idle": "2025-02-12T07:47:19.436707Z",
                    "shell.execute_reply.started": "2025-02-12T07:46:43.422395Z",
                    "shell.execute_reply": "2025-02-12T07:47:19.435447Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Plot training loss\nif not SUBMISSION_RUN:\n    fig, ax = plt.subplots(4, 2, figsize=(10, 12), sharex=True)\n    \n    for split_idx, split_scores in enumerate(cv_results):\n        for meter_id, meter_scores in split_scores.items():\n            ax[meter_id, 0].plot(\n                meter_scores[\"train_valid_loss\"][\"train\"][\"rmse\"],\n                label=f\"split {split_idx}\",\n            )\n            \n            ax[meter_id, 1].plot(\n                meter_scores[\"train_valid_loss\"][\"valid\"][\"rmse\"],\n                label=f\"split {split_idx}\",\n            )\n\n    for meter_id in METER_IDS:\n        ax[meter_id, 0].legend()\n        ax[meter_id, 0].set(ylabel=f\"loss, meter_id {meter_id}\")\n        ax[meter_id, 1].legend()\n    \n    ax[0, 0].set(title=\"train\")\n    ax[0, 1].set(title=\"valid\")\n\n    fig.tight_layout();\n    plt.savefig(\"loss_curves.png\", dpi=300)",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:47:19.439050Z",
                    "iopub.execute_input": "2025-02-12T07:47:19.439350Z",
                    "iopub.status.idle": "2025-02-12T07:47:21.801531Z",
                    "shell.execute_reply.started": "2025-02-12T07:47:19.439322Z",
                    "shell.execute_reply": "2025-02-12T07:47:21.800312Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Submission",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Make predictions in batches\ndef load_test_df_in_batches(pq_file: str, batch_size: int = 200_000):\n    test_pq_file = pq.ParquetFile(pq_file)\n    for batch in tqdm(test_pq_file.iter_batches(batch_size)):\n        batch_df = batch.to_pandas()\n        yield batch_df",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:47:21.802470Z",
                    "iopub.execute_input": "2025-02-12T07:47:21.802745Z",
                    "iopub.status.idle": "2025-02-12T07:47:21.808353Z",
                    "shell.execute_reply.started": "2025-02-12T07:47:21.802722Z",
                    "shell.execute_reply": "2025-02-12T07:47:21.807036Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "def kwh_to_kbtu(df: pd.DataFrame) -> pd.DataFrame:\n    mask = (df[\"building_id\"] == 0) & (df[\"meter_id\"] == 0)\n    df.loc[mask, \"meter_reading\"] = df.loc[mask, \"meter_reading\"] * 3.4118\n    return df",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:47:21.809360Z",
                    "iopub.execute_input": "2025-02-12T07:47:21.809697Z",
                    "iopub.status.idle": "2025-02-12T07:47:21.830998Z",
                    "shell.execute_reply.started": "2025-02-12T07:47:21.809669Z",
                    "shell.execute_reply": "2025-02-12T07:47:21.829980Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "if SUBMISSION_RUN:\n    # Load data and make predictions in batches\n    prediction_dfs = []\n    \n    test_pq_file = \"/kaggle/input/ashrae-iii/test_df.parquet\"\n    for test_df in load_test_df_in_batches(test_pq_file):\n        test_df = drop_cols(test_df)\n        test_df = cast_dtypes(test_df)\n    \n        for meter_id in METER_IDS:\n            test_meter_df = test_df[test_df[\"meter_id\"] == meter_id]\n            if test_meter_df.empty: continue\n            X_test = test_meter_df[FEATURES]\n    \n            transformer = COL_TRANSFORMERS[meter_id]\n            X_test = transformer.transform(X_test)\n            dtypes = get_feature_dtypes(meter_id)\n            X_test = X_test.astype(dtypes)\n            \n            model = MODELS[meter_id]\n            y_hat = np.expm1(model.predict(X_test))\n            y_hat = np.clip(y_hat, a_min=0.0, a_max=None).astype(np.float32)\n    \n            prediction_df = test_meter_df[[\"row_id\", \"building_id\", \"meter_id\"]].copy()\n            prediction_df[\"meter_reading\"] = y_hat\n            prediction_dfs.append(prediction_df)\n        \n    # Submit\n    submission_df = pd.concat(prediction_dfs, axis=0, ignore_index=True)\n    submission_df = kwh_to_kbtu(submission_df)\n    submission_df = submission_df[[\"row_id\", \"meter_reading\"]].sort_values(\"row_id\").reset_index(drop=True)\n    submission_df.to_csv(\"submission.csv\", index=False)",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-02-12T07:47:21.831987Z",
                    "iopub.execute_input": "2025-02-12T07:47:21.832341Z",
                    "iopub.status.idle": "2025-02-12T07:47:21.850282Z",
                    "shell.execute_reply.started": "2025-02-12T07:47:21.832314Z",
                    "shell.execute_reply": "2025-02-12T07:47:21.849326Z"
                }
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}