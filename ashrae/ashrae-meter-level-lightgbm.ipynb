{
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "sourceId": 9994,
                    "databundleVersionId": 752467,
                    "sourceType": "competition"
                },
                {
                    "sourceId": 10579605,
                    "sourceType": "datasetVersion",
                    "datasetId": 6473980
                }
            ],
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": false
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "!pip install scikit-learn==1.3.1 -q",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "import gc\n\nimport lightgbm as lgbm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import TargetEncoder, OrdinalEncoder",
            "metadata": {
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "SUBMISSION_RUN = True",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Constants\nINPUT_DATA_PATH = \"/kaggle/input/ashrae-energy-prediction\"\n\nMIN_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-01-01 00:00:00\")\nMAX_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-12-31 23:00:00\")\nMIN_TEST_TIMESTAMP = pd.Timestamp(\"2017-01-01 00:00:00\")\nMAX_TEST_TIMESTAMP = pd.Timestamp('2018-12-31 23:00:00')\n\nDATA_RESOLUTION = \"1h\"\n\nVALIDATION_PERIODS = [\n    (pd.Timestamp(\"2016-10-01 00:00:00\"), pd.Timestamp(\"2016-11-01 00:00:00\")),\n    (pd.Timestamp(\"2016-11-01 00:00:00\"), pd.Timestamp(\"2016-12-01 00:00:00\")),\n    (pd.Timestamp(\"2016-12-01 00:00:00\"), pd.Timestamp(\"2017-01-01 00:00:00\")),\n]\n\nMETER_IDS = [0, 1, 2, 3]",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Data loading",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "CATEGORY_COLS = [\"building_id\", \"meter_id\", \"site_id\", \"primary_use\"]\nUINT8_COLS = [\"hour\", \"day_of_week\", \"month\"]\n\n\ndef drop_cols(df: pd.DataFrame) -> pd.DataFrame:\n    cols_to_drop = [\"hour\", \"day_of_week\", \"month\"]\n    cols_to_drop = cols_to_drop + ([\"timestamp\"] if SUBMISSION_RUN else [])\n    df = df.drop(columns=cols_to_drop)\n    return df\n\n\ndef cast_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n\n    # Timestamps\n    try:\n        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n    except KeyError:\n        print(\"Col 'timestamp' missing from df. Skipping ...\")\n\n    # Categories\n    for col in CATEGORY_COLS:\n        try:\n            df[col] = df[col].astype(\"category\")\n        except KeyError:\n            print(f\"Col '{col}' missing from df. Skipping ...\")\n\n    # UINT8\n    for col in UINT8_COLS:\n        try:\n            if df[col].max() > np.iinfo(np.uint8).max:\n                print(f\"Col max for '{col}' exceeds np.uint8 max. Skipping ...\")\n                continue\n            df[col] = df[col].astype(np.uint8)\n        except KeyError:\n            print(f\"Col '{col}' missing from df. Skipping ...\")\n    \n    return df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "train_dataset = pd.read_parquet(\"/kaggle/input/ashrae-iii/train_df.parquet\")\ntrain_dataset = drop_cols(train_dataset)\ntrain_dataset = cast_dtypes(train_dataset)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Cross Validation",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "FEATURES = [\n    \"square_feet\",\n    \"floor_count\",\n    \"air_temperature\",\n    \"cloud_coverage\",\n    \"dew_temperature\",\n    \"precip_depth_1_hr\",\n    \"sea_level_pressure\",\n    \"wind_direction_sin\",\n    \"wind_direction_cos\",\n    \"wind_speed\",\n    \"air_temperature_lag_1\",\n    \"air_temperature_lag_2\",\n    \"dew_temperature_lag_1\",\n    \"dew_temperature_lag_2\",\n    \"sea_level_pressure_lag_1\",\n    \"sea_level_pressure_lag_2\",\n    \"hour_sin\",\n    \"hour_cos\",\n    \"day_of_week_sin\",\n    \"day_of_week_cos\",\n    \"month_sin\",\n    \"month_cos\",\n    \"is_weekend\",\n    \"building_age_years\",\n    \"building_area_square_feet\",\n    \"relative_humidity\",\n    \"cold_chill\",\n    \"apparent_temperature\",\n    \"heat_index\",\n    \"site_id\",\n    \"primary_use\",\n    \"building_id\"\n]\n\nLABEL = \"meter_reading\"",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "N_ITERATIONS = 2000\nTRAIN_PARAMETERS = {\n    \"objective\": \"mean_squared_error\",\n    \"learning_rate\": 0.01,\n    \"seed\": 1,\n    \"max_bin\": 200,\n    \"num_leaves\": 2 ** 5 - 1,\n    \"min_data_in_leaf\": 1000,\n    \"bagging_fraction\": 0.7,\n    \"bagging_freq\": 1,\n    \"metric\": [\"rmse\"],\n}\nDATASET_PARAMETERS = {\"categorical_feature\": [\"site_id\", \"primary_use\"]}",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "def get_column_transformer() -> ColumnTransformer:\n    ordinal_encoder = OrdinalEncoder(\n        categories=\"auto\",\n        handle_unknown=\"use_encoded_value\",\n        unknown_value=-1,\n        dtype=np.int32,\n    )\n    target_encoder = TargetEncoder(\n        categories=\"auto\",\n        target_type=\"continuous\",\n        smooth=\"auto\"\n    )\n    transformer = ColumnTransformer(\n        transformers=[\n            (\"ordinal_encoder\", ordinal_encoder, [\"primary_use\"]),\n            (\"target_encoder\", target_encoder, [\"building_id\"]),\n        ],\n        remainder=\"passthrough\",\n        verbose_feature_names_out=False,\n    )\n    transformer.set_output(transform=\"pandas\")\n    return transformer\n\n\ndef target_transform(y: pd.Series) -> pd.Series:\n    return np.log1p(y)\n\n\ndef inverse_target_transform(y: pd.Series) -> pd.Series:\n    return np.expm1(y).clip(lower=0.0)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "def train_valid_split(train_df: pd.DataFrame):\n    for val_start, val_end in VALIDATION_PERIODS:\n        train_mask = train_df[\"timestamp\"] < val_start\n        test_mask = (train_df[\"timestamp\"] >= val_start) & (train_df[\"timestamp\"] < val_end)\n        yield train_df.loc[train_mask], train_df.loc[test_mask]\n\n\ndef train_predict_score(train_df: pd.DataFrame, valid_df: pd.DataFrame):\n    results_by_meter_id = {}\n    for meter_id in METER_IDS:\n        print(f\"Running train/predict/score for meter id {meter_id}\")\n        \n        train_meter_df = train_df[train_df[\"meter_id\"] == meter_id]\n        valid_meter_df = valid_df[valid_df[\"meter_id\"] == meter_id]\n\n        X_train, y_train = train_meter_df[FEATURES], train_meter_df[LABEL]\n        X_valid, y_valid = valid_meter_df[FEATURES], valid_meter_df[LABEL]\n\n        print(f\"Train shape: {X_train.shape, y_train.shape}\")\n        print(f\"Valid shape: {X_valid.shape, y_valid.shape}\\n\")\n\n        # Target transform\n        y_train = target_transform(y_train)\n        y_valid = target_transform(y_valid)\n\n        # Feature transforms\n        col_transformer = get_column_transformer()\n        col_transformer.fit(X_train, y_train)\n        X_train = col_transformer.transform(X_train)\n        X_train = X_train.astype({\"building_id\": np.float32, \"primary_use\": \"category\"})\n        X_valid = col_transformer.transform(X_valid)\n        X_valid = X_valid.astype({\"building_id\": np.float32, \"primary_use\": \"category\"})\n\n        # Train LightGBM\n        train_ds = lgbm.Dataset(data=X_train, label=y_train, **DATASET_PARAMETERS)\n        valid_ds = lgbm.Dataset(data=X_valid, label=y_valid, **DATASET_PARAMETERS)\n\n        train_valid_loss = {}\n        model = lgbm.train(\n            TRAIN_PARAMETERS,\n            num_boost_round=N_ITERATIONS,\n            train_set=train_ds,\n            valid_sets=[train_ds, valid_ds],\n            valid_names=[\"train\", \"valid\"],\n            callbacks=[\n                # lgbm.early_stopping(stopping_rounds=5),\n                lgbm.log_evaluation(period=10),\n                lgbm.record_evaluation(train_valid_loss),\n            ]\n        )\n\n        y_hat = model.predict(X_valid)\n        results = {\"y_true\": y_valid, \"y_pred\": y_hat, \"train_valid_loss\": train_valid_loss}\n        results_by_meter_id[meter_id] = results\n\n        print(\"====================================\")\n\n    return results_by_meter_id",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "if not SUBMISSION_RUN:\n    cv_results = []\n    for i, (train_df, valid_df) in enumerate(train_valid_split(train_dataset)):\n        print(f\"Running cross validation on split {i}\\n\")\n        results = train_predict_score(train_df, valid_df)\n        cv_results.append(results)\n        print(\"====================================\")\n\nelse:\n    print(f\"Training models for submission run.\")\n    COL_TRANSFORMERS, MODELS = {}, {}\n    for meter_id in METER_IDS:\n        print(f\"Training models for meter id {meter_id}\")\n        \n        train_meter_df = train_dataset[train_dataset[\"meter_id\"] == meter_id]\n        X_train, y_train = train_meter_df[FEATURES], train_meter_df[LABEL]\n        print(f\"Train shape: {X_train.shape, y_train.shape}\")\n\n        # Target and feature transform\n        y_train = target_transform(y_train)\n\n        col_transformer = get_column_transformer()\n        col_transformer.fit(X_train, y_train)\n        X_train = col_transformer.transform(X_train)\n        X_train = X_train.astype({\"building_id\": np.float32, \"primary_use\": \"category\"})\n\n        # Train LightGBM\n        train_ds = lgbm.Dataset(data=X_train, label=y_train, **DATASET_PARAMETERS)\n        model = lgbm.train(\n            TRAIN_PARAMETERS,\n            num_boost_round=N_ITERATIONS,\n            train_set=train_ds,\n            valid_sets=[train_ds],\n            valid_names=[\"train\"],\n            callbacks=[lgbm.log_evaluation(period=10)]\n        )\n\n        # Save transformer and model for inference\n        COL_TRANSFORMERS[meter_id] = col_transformer\n        MODELS[meter_id] = model\n\n    del train_dataset\n    gc.collect()",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Plot training loss\nif not SUBMISSION_RUN:\n    fig, ax = plt.subplots(4, 2, figsize=(10, 12), sharex=True)\n    \n    for split_idx, split_scores in enumerate(cv_results):\n        for meter_id, meter_scores in split_scores.items():\n            ax[meter_id, 0].plot(\n                meter_scores[\"train_valid_loss\"][\"train\"][\"rmse\"],\n                label=f\"split {split_idx}\",\n            )\n            \n            ax[meter_id, 1].plot(\n                meter_scores[\"train_valid_loss\"][\"valid\"][\"rmse\"],\n                label=f\"split {split_idx}\",\n            )\n\n    for meter_id in METER_IDS:\n        ax[meter_id, 0].legend()\n        ax[meter_id, 0].set(ylabel=f\"loss, meter_id {meter_id}\")\n        ax[meter_id, 1].legend()\n    \n    ax[0, 0].set(title=\"train\")\n    ax[0, 1].set(title=\"valid\")\n\n    fig.tight_layout();\n    plt.savefig(\"loss_curves.png\", dpi=300)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Submission",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "def kwh_to_kbtu(df: pd.DataFrame) -> pd.DataFrame:\n    mask = (df[\"building_id\"] == 0) & (df[\"meter_id\"] == 0)\n    df.loc[mask, \"meter_reading\"] = df.loc[mask, \"meter_reading\"] * 3.4118\n    return df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "if SUBMISSION_RUN:\n    # Load data\n    test_data = pd.read_parquet(\"/kaggle/input/ashrae-iii/test_df.parquet\")\n    test_data = drop_cols(test_data)\n    test_data = cast_dtypes(test_data)\n    \n    # Predict\n    predictions_by_meter = []\n    for meter_id in METER_IDS:\n        test_meter_df = test_data[test_data[\"meter_id\"] == meter_id]\n        X_test = test_meter_df[FEATURES]\n\n        transformer = COL_TRANSFORMERS[meter_id]\n        X_test = transformer.transform(X_test)\n        X_test = X_test.astype({\"building_id\": np.float32, \"primary_use\": \"category\"})\n        \n        model = MODELS[meter_id]\n        y_hat = np.expm1(model.predict(X_test))\n        y_hat = np.clip(y_hat, a_min=0.0, a_max=None).astype(np.float32)\n\n        predictions_df = test_meter_df[[\"row_id\", \"building_id\", \"meter_id\"]].copy()\n        predictions_df[\"meter_reading\"] = y_hat\n        predictions_by_meter.append(predictions_df)\n\n        del test_meter_df\n        gc.collect()\n    \n    # Submit\n    submission_df = pd.concat(predictions_by_meter, axis=0, ignore_index=True)\n    submission_df = kwh_to_kbtu(submission_df)\n    submission_df = submission_df[[\"row_id\", \"meter_reading\"]].sort_values(\"row_id\").reset_index(drop=True)\n    submission_df.to_csv(\"submission.csv\", index=False)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}