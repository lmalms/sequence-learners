{
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "sourceId": 9994,
                    "databundleVersionId": 752467,
                    "sourceType": "competition"
                },
                {
                    "sourceId": 10515906,
                    "sourceType": "datasetVersion",
                    "datasetId": 6473980
                }
            ],
            "dockerImageVersionId": 30839,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": false
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "!pip install -q scikit-learn==1.3.1",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import TargetEncoder, OrdinalEncoder",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Constants\nINPUT_DATA_PATH = \"/kaggle/input/ashrae-energy-prediction\"\n\nMIN_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-01-01 00:00:00\")\nMAX_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-12-31 23:00:00\")\nMIN_TEST_TIMESTAMP = pd.Timestamp(\"2017-01-01 00:00:00\")\nMAX_TEST_TIMESTAMP = pd.Timestamp('2018-12-31 23:00:00')\n\nDATA_RESOLUTION = \"1h\"",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "# Data Loading",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "CATEGORY_COLS = [\"building_id\", \"meter_id\", \"site_id\", \"primary_use\", \"primary_use_id\"]\nUINT8_COLS = [\"hour\", \"day_of_week\", \"month\"]\n\n\ndef cast_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n\n    # Timestamps\n    try:\n        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n    except KeyError:\n        print(\"Col 'timestamp' missing from df. Skipping ...\")\n\n    # Categories\n    for col in CATEGORY_COLS:\n        try:\n            df[col] = df[col].astype(\"category\")\n        except KeyError:\n            print(f\"Col '{col}' missing from df. Skipping ...\")\n\n    # UINT8\n    for col in UINT8_COLS:\n        try:\n            if df[col].max() > np.iinfo(np.uint8).max:\n                print(f\"Col max for '{col}' exceeds np.uint8 max. Skipping ...\")\n                continue\n            df[col] = df[col].astype(np.uint8)\n        except KeyError:\n            print(f\"Col '{col}' missing from df. Skipping ...\")\n    \n    return df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "train_dataset = pd.read_parquet(\"/kaggle/input/ashrae-iii/train_df.parquet\")\ntrain_dataset = cast_dtypes(train_dataset)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "# Target Encoding",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "VALIDATION_PERIODS = [\n    (pd.Timestamp(\"2016-10-01 00:00:00\"), pd.Timestamp(\"2016-11-01 00:00:00\")),\n    (pd.Timestamp(\"2016-11-01 00:00:00\"), pd.Timestamp(\"2016-12-01 00:00:00\")),\n    (pd.Timestamp(\"2016-12-01 00:00:00\"), pd.Timestamp(\"2017-01-01 00:00:00\")),\n]\n\nval_start, val_end = VALIDATION_PERIODS[0]\n\ntrain_mask = train_dataset[\"timestamp\"] < val_start\ntrain_df = train_dataset.loc[train_mask]\n\nval_mask = (train_dataset[\"timestamp\"] >= val_start) & (train_dataset[\"timestamp\"] < val_end)\nval_df = train_dataset.loc[val_mask]",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "cols = [\"building_id\", \"meter_id\", \"log_meter_reading\"]\ntrain_df = train_df[cols]\nval_df = val_df[cols]\n\ntrain_encodings, val_encodings = [], []\nfor meter_id in train_df[\"meter_id\"].unique():\n    \n    train_meter_df = train_df[train_df[\"meter_id\"] == meter_id]\n    X_train, y_train = train_meter_df[[\"building_id\"]], train_meter_df[\"log_meter_reading\"]\n    \n    val_meter_df = val_df[val_df[\"meter_id\"] == meter_id]\n    X_val, y_val = val_meter_df[[\"building_id\"]], val_meter_df[\"log_meter_reading\"]\n    \n    encoder = TargetEncoder(categories=\"auto\", target_type=\"continuous\", smooth=\"auto\")\n    encoder = encoder.fit(X_train, y_train)\n\n    X_train_trans = encoder.transform(X_train)\n    X_train_trans = pd.DataFrame(X_train_trans, columns=[\"building_id_transform\"])\n    X_train_trans = pd.concat([train_meter_df.reset_index(drop=True), X_train_trans], axis=1)\n    train_encodings.append(X_train_trans)\n\n    X_val_trans = encoder.transform(X_val)\n    X_val_trans = pd.DataFrame(X_val_trans, columns=[\"building_id_transform\"])\n    X_val_trans = pd.concat([val_meter_df.reset_index(drop=True), X_val_trans], axis=1)\n    val_encodings.append(X_val_trans)\n    \ntrain_encodings = pd.concat(train_encodings, ignore_index=True)\nval_encodings = pd.concat(val_encodings, ignore_index=True)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "fig, ax = plt.subplots(1, 4, figsize=(15, 3.5), sharey=True)\nfor meter_id in train_df[\"meter_id\"].unique():\n    meter_df = train_encodings[train_encodings[\"meter_id\"] == meter_id]\n    meter_df = meter_df.sample(750)\n    ax[meter_id].scatter(\n        x=meter_df[\"building_id_transform\"].values,\n        y=meter_df[\"log_meter_reading\"].values,\n        alpha=0.2\n    )\n    ax[meter_id].set(\n        title=f\"Meter id: {meter_id}\",\n        xlabel=\"building_id_encoding\"\n    )\nax[0].set(ylabel=\"log_meter_reading\")\n\nfig.tight_layout()",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "fig, ax = plt.subplots(1, 4, figsize=(15, 3.5), sharey=True)\nfor meter_id in val_df[\"meter_id\"].unique():\n    meter_df = val_encodings[val_encodings[\"meter_id\"] == meter_id]\n    meter_df = meter_df.sample(750)\n    ax[meter_id].scatter(\n        x=meter_df[\"building_id_transform\"].values,\n        y=meter_df[\"log_meter_reading\"].values,\n        alpha=0.2\n    )\n    ax[meter_id].set(\n        title=f\"Meter id: {meter_id}\",\n        xlabel=\"building_id_encoding\"\n    )\nax[0].set(ylabel=\"log_meter_reading\")\n\nfig.tight_layout()",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}