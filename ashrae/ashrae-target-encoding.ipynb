{
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "sourceId": 9994,
                    "databundleVersionId": 752467,
                    "sourceType": "competition"
                },
                {
                    "sourceId": 10515906,
                    "sourceType": "datasetVersion",
                    "datasetId": 6473980
                }
            ],
            "dockerImageVersionId": 30839,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": false
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "!pip install -q scikit-learn==1.3.1",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "import pandas as pd\nimport numpy as np\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import TargetEncoder, OrdinalEncoder",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Constants\nINPUT_DATA_PATH = \"/kaggle/input/ashrae-energy-prediction\"\n\nMIN_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-01-01 00:00:00\")\nMAX_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-12-31 23:00:00\")\nMIN_TEST_TIMESTAMP = pd.Timestamp(\"2017-01-01 00:00:00\")\nMAX_TEST_TIMESTAMP = pd.Timestamp('2018-12-31 23:00:00')\n\nDATA_RESOLUTION = \"1h\"\n\nVALIDATION_PERIODS = [\n    (pd.Timestamp(\"2016-10-01 00:00:00\"), pd.Timestamp(\"2016-11-01 00:00:00\")),\n    # (pd.Timestamp(\"2016-11-01 00:00:00\"), pd.Timestamp(\"2016-12-01 00:00:00\")),\n    # (pd.Timestamp(\"2016-12-01 00:00:00\"), pd.Timestamp(\"2017-01-01 00:00:00\")),\n]",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "# Data Loading",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "CATEGORY_COLS = [\"building_id\", \"meter_id\", \"site_id\", \"primary_use\", \"primary_use_id\"]\nUINT8_COLS = [\"hour\", \"day_of_week\", \"month\"]\n\n\ndef cast_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n\n    # Timestamps\n    try:\n        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n    except KeyError:\n        print(\"Col 'timestamp' missing from df. Skipping ...\")\n\n    # Categories\n    for col in CATEGORY_COLS:\n        try:\n            df[col] = df[col].astype(\"category\")\n        except KeyError:\n            print(f\"Col '{col}' missing from df. Skipping ...\")\n\n    # UINT8\n    for col in UINT8_COLS:\n        try:\n            if df[col].max() > np.iinfo(np.uint8).max:\n                print(f\"Col max for '{col}' exceeds np.uint8 max. Skipping ...\")\n                continue\n            df[col] = df[col].astype(np.uint8)\n        except KeyError:\n            print(f\"Col '{col}' missing from df. Skipping ...\")\n    \n    return df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "train_dataset = pd.read_parquet(\"/kaggle/input/ashrae-iii/train_df.parquet\")\ntrain_dataset = cast_dtypes(train_dataset)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "# Target Encoding",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "train_dataset.head()",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "\"building_id\",\n    \"meter_id\",\n    # \"site_id\",\n    # \"square_feet\",\n    # \"floor_count\",\n    # \"air_temperature\",\n    # \"cloud_coverage\",\n    # \"dew_temperature\",\n    # \"precip_depth_1_hr\",\n    # \"sea_level_pressure\",\n    # \"wind_direction_sin\",\n    # \"wind_direction_cos\",\n    # \"wind_speed\",\n    # \"air_temperature_lag_1\",\n    # \"air_temperature_lag_2\",\n    # \"dew_temperature_lag_1\",\n    # \"dew_temperature_lag_2\",\n    # \"sea_level_pressure_lag_1\",\n    # \"sea_level_pressure_lag_2\",\n    \"hour_sin\",\n    \"hour_cos\",\n    \"day_of_week_sin\",\n    \"day_of_week_cos\",\n    \"month_sin\",\n    \"month_cos\",\n    \"is_weekend\",\n    # \"building_age_years\",\n    # \"building_area_square_feet\",\n    # \"primary_use_id\",\n    # \"relative_humidity\",\n    # \"cold_chill\",\n    # \"apparent_temperature\",\n    # \"heat_index\",",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "NUMERICAL_FEATURES = [\n    \"meter_id\",\n    \"hour_sin\",\n    \"hour_cos\",\n    \"day_of_week_sin\",\n    \"day_of_week_cos\",\n    \"month_sin\",\n    \"month_cos\",\n    \"is_weekend\",\n    \"square_feet\",\n    \"floor_count\",\n    \"building_age_years\",\n    \"building_area_square_feet\",\n    \"air_temperature\",\n    \"cloud_coverage\",\n    \"dew_temperature\",\n    \"precip_depth_1_hr\",\n    \"sea_level_pressure\",\n    \"wind_direction_sin\",\n    \"wind_direction_cos\",\n    \"wind_speed\",\n    \"air_temperature_lag_1\",\n    \"air_temperature_lag_2\",\n    \"dew_temperature_lag_1\",\n    \"dew_temperature_lag_2\",\n    \"sea_level_pressure_lag_1\",\n    \"sea_level_pressure_lag_2\",\n    \"relative_humidity\",\n    \"cold_chill\",\n    \"apparent_temperature\",\n    \"heat_index\",\n]\nHIGH_CATEGORICAL_FEATURES = [\"building_id\"]\nLOW_CATEGORICAL_FEATURES = [\"primary_use\"]\nLABEL_COLUMN = \"log_meter_reading\"",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "target_encoder = TargetEncoder(categories=\"auto\", target_type=\"continuous\", smooth=\"auto\")\nordinal_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n\ncol_transformer = ColumnTransformer(\n    transformers=[\n        (\"numerical\", \"passthrough\", NUMERICAL_FEATURES),\n        (\"categorical\", target_encoder, CATEGORICAL_FEATURES),\n    ],\n    remainder=\"drop\",\n    verbose_feature_names_out=False,\n)\ncol_transformer.set_output(transform=\"pandas\")\n\nmodel = HistGradientBoostingRegressor(\n    random_state=0,\n    categorical_features=[\"meter_id\", \"is_weekend\"]\n)\n\npipeline = Pipeline(steps=[(\"transformer\", col_transformer), (\"estimator\", model)])",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "def train_valid_split(train_df: pd.DataFrame):\n    for val_start, val_end in VALIDATION_PERIODS:\n        train_mask = train_df[\"timestamp\"] < val_start\n        test_mask = (train_df[\"timestamp\"] >= val_start) & (train_df[\"timestamp\"] < val_end)\n        yield train_df.loc[train_mask], train_df.loc[test_mask]\n\n\ndef _train_valid_split(train_df: pd.DataFrame):\n    for val_start, val_end in VALIDATION_PERIODS:\n        train_mask = train_df[\"timestamp\"] < val_start\n        train_idx = train_df.loc[train_mask].index\n        \n        test_mask = (train_df[\"timestamp\"] >= val_start) & (train_df[\"timestamp\"] < val_end)\n        test_idx = train_df.loc[test_mask].index\n        yield np.array(train_idx), np.array(test_idx)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "for train_idx, val_idx in _train_valid_split(train_dataset):\n    break",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "for split, (train_df, val_df) in enumerate(train_valid_split(train_dataset)):\n    break",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "X_train = train_df[NUMERICAL_FEATURES + CATEGORICAL_FEATURES]\ny_train = train_df[LABEL_COLUMN]\n\nX_val = val_df[NUMERICAL_FEATURES + CATEGORICAL_FEATURES]\ny_val = val_df[LABEL_COLUMN]",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "pipeline.fit(X, y)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "y_hat = pipeline.predict(X_val)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "scores = cross_validate(\n    pipeline,\n    X=train_dataset[NUMERICAL_FEATURES + CATEGORICAL_FEATURES + [\"timestamp\"]],\n    y=train_dataset[LABEL_COLUMN],\n    scoring=[\"neg_mean_squared_error\"],\n    cv=_train_valid_split(train_dataset),\n    return_indices=True,\n    verbose=1\n)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "scores",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "scores[\"inde\"]",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}