{
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.12",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "sourceId": 9994,
                    "databundleVersionId": 752467,
                    "sourceType": "competition"
                },
                {
                    "sourceId": 10515906,
                    "sourceType": "datasetVersion",
                    "datasetId": 6473980
                }
            ],
            "dockerImageVersionId": 30839,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": false
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "import gc\n\nimport lightgbm as lgbm\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pyarrow.parquet as pq\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm import tqdm",
            "metadata": {
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-01-19T16:00:40.132780Z",
                    "iopub.execute_input": "2025-01-19T16:00:40.133277Z",
                    "iopub.status.idle": "2025-01-19T16:00:47.929610Z",
                    "shell.execute_reply.started": "2025-01-19T16:00:40.133234Z",
                    "shell.execute_reply": "2025-01-19T16:00:47.928323Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "SUBMISSION_RUN = True",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-01-19T16:00:49.211129Z",
                    "iopub.execute_input": "2025-01-19T16:00:49.212192Z",
                    "iopub.status.idle": "2025-01-19T16:00:49.217879Z",
                    "shell.execute_reply.started": "2025-01-19T16:00:49.212073Z",
                    "shell.execute_reply": "2025-01-19T16:00:49.216223Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Constants\nINPUT_DATA_PATH = \"/kaggle/input/ashrae-energy-prediction\"\n\nMIN_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-01-01 00:00:00\")\nMAX_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-12-31 23:00:00\")\nMIN_TEST_TIMESTAMP = pd.Timestamp(\"2017-01-01 00:00:00\")\nMAX_TEST_TIMESTAMP = pd.Timestamp('2018-12-31 23:00:00')\n\nDATA_RESOLUTION = \"1h\"\n\nVALIDATION_PERIODS = [\n    (pd.Timestamp(\"2016-10-01 00:00:00\"), pd.Timestamp(\"2016-11-01 00:00:00\")),\n    (pd.Timestamp(\"2016-11-01 00:00:00\"), pd.Timestamp(\"2016-12-01 00:00:00\")),\n    (pd.Timestamp(\"2016-12-01 00:00:00\"), pd.Timestamp(\"2017-01-01 00:00:00\")),\n]",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-01-19T16:00:49.619420Z",
                    "iopub.execute_input": "2025-01-19T16:00:49.619855Z",
                    "iopub.status.idle": "2025-01-19T16:00:49.628729Z",
                    "shell.execute_reply.started": "2025-01-19T16:00:49.619819Z",
                    "shell.execute_reply": "2025-01-19T16:00:49.626540Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Data loading",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "CATEGORY_COLS = [\"building_id\", \"meter_id\", \"site_id\", \"primary_use\", \"primary_use_id\"]\nUINT8_COLS = [\"hour\", \"day_of_week\", \"month\"]\n\n\ndef cast_dtypes(df: pd.DataFrame) -> pd.DataFrame:\n\n    # Timestamps\n    try:\n        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n    except KeyError:\n        print(\"Col 'timestamp' missing from df. Skipping ...\")\n\n    # Categories\n    for col in CATEGORY_COLS:\n        try:\n            df[col] = df[col].astype(\"category\")\n        except KeyError:\n            print(f\"Col '{col}' missing from df. Skipping ...\")\n\n    # UINT8\n    for col in UINT8_COLS:\n        try:\n            if df[col].max() > np.iinfo(np.uint8).max:\n                print(f\"Col max for '{col}' exceeds np.uint8 max. Skipping ...\")\n                continue\n            df[col] = df[col].astype(np.uint8)\n        except KeyError:\n            print(f\"Col '{col}' missing from df. Skipping ...\")\n    \n    return df",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-01-19T16:00:51.548568Z",
                    "iopub.execute_input": "2025-01-19T16:00:51.549023Z",
                    "iopub.status.idle": "2025-01-19T16:00:51.557506Z",
                    "shell.execute_reply.started": "2025-01-19T16:00:51.548991Z",
                    "shell.execute_reply": "2025-01-19T16:00:51.556052Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# train_pq_file = pq.ParquetFile(\"/kaggle/input/ashrae-iii/train_df.parquet\")\n\n# train_dataset = pd.DataFrame()\n# for batch in tqdm(train_pq_file.iter_batches(batch_size=131_072)):\n#     train_batch_df = batch.to_pandas()\n#     train_batch_df = cast_dtypes(train_batch_df)\n#     train_dataset = pd.concat([train_dataset, train_batch_df], ignore_index=True)\n    \n#     del train_batch_df\n#     _ = gc.collect()\n\n# train_dataset = cast_dtypes(train_dataset)",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-01-19T16:00:53.279927Z",
                    "iopub.execute_input": "2025-01-19T16:00:53.280424Z",
                    "iopub.status.idle": "2025-01-19T16:00:53.285735Z",
                    "shell.execute_reply.started": "2025-01-19T16:00:53.280381Z",
                    "shell.execute_reply": "2025-01-19T16:00:53.284039Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "train_dataset = pd.read_parquet(\"/kaggle/input/ashrae-iii/train_df.parquet\")\ntrain_dataset = cast_dtypes(train_dataset)",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-01-19T16:00:53.612449Z",
                    "iopub.execute_input": "2025-01-19T16:00:53.612927Z",
                    "iopub.status.idle": "2025-01-19T16:01:03.223729Z",
                    "shell.execute_reply.started": "2025-01-19T16:00:53.612889Z",
                    "shell.execute_reply": "2025-01-19T16:01:03.222089Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Cross Validation",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "FEATURES = [\n    \"building_id\",\n    \"meter_id\",\n    # \"site_id\",\n    # \"square_feet\",\n    # \"floor_count\",\n    # \"air_temperature\",\n    # \"cloud_coverage\",\n    # \"dew_temperature\",\n    # \"precip_depth_1_hr\",\n    # \"sea_level_pressure\",\n    # \"wind_direction_sin\",\n    # \"wind_direction_cos\",\n    # \"wind_speed\",\n    # \"air_temperature_lag_1\",\n    # \"air_temperature_lag_2\",\n    # \"dew_temperature_lag_1\",\n    # \"dew_temperature_lag_2\",\n    # \"sea_level_pressure_lag_1\",\n    # \"sea_level_pressure_lag_2\",\n    \"hour_sin\",\n    \"hour_cos\",\n    \"day_of_week_sin\",\n    \"day_of_week_cos\",\n    \"month_sin\",\n    \"month_cos\",\n    \"is_weekend\",\n    # \"building_age_years\",\n    # \"building_area_square_feet\",\n    # \"primary_use_id\",\n    # \"relative_humidity\",\n    # \"cold_chill\",\n    # \"apparent_temperature\",\n    # \"heat_index\",\n]\n\nLABEL = \"log_meter_reading\"",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-01-19T16:01:03.225588Z",
                    "iopub.execute_input": "2025-01-19T16:01:03.226038Z",
                    "iopub.status.idle": "2025-01-19T16:01:03.231734Z",
                    "shell.execute_reply.started": "2025-01-19T16:01:03.226000Z",
                    "shell.execute_reply": "2025-01-19T16:01:03.230057Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "TRAIN_PARAMETERS = {\n    \"objective\": \"mean_squared_error\",\n    \"learning_rate\": 0.01,\n    \"seed\": 1,\n    \"max_bin\": 255,\n    \"num_leaves\": 2 ** 6 - 1,\n}",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-01-19T16:01:03.233989Z",
                    "iopub.execute_input": "2025-01-19T16:01:03.234449Z",
                    "iopub.status.idle": "2025-01-19T16:01:03.270802Z",
                    "shell.execute_reply.started": "2025-01-19T16:01:03.234410Z",
                    "shell.execute_reply": "2025-01-19T16:01:03.268795Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "def train_valid_split(train_df: pd.DataFrame):\n    for val_start, val_end in VALIDATION_PERIODS:\n        train_mask = train_df[\"timestamp\"] < val_start\n        test_mask = (train_df[\"timestamp\"] >= val_start) & (train_df[\"timestamp\"] < val_end)\n        yield train_df.loc[train_mask], train_df.loc[test_mask]\n\n\n\ndef train_predict_score(\n    X_train: pd.DataFrame,\n    y_train: pd.Series,\n    X_test: pd.DataFrame,\n    y_test: pd.Series,\n):\n    \n    train_ds = lgbm.Dataset(data=X_train, label=y_train)\n    valid_ds = lgbm.Dataset(data=X_valid, label=y_valid)\n\n    # Train and log evals.\n    eval_results = {}\n    model = lgbm.train(\n        TRAIN_PARAMETERS,\n        num_boost_round=1000,\n        train_set=train_ds,\n        valid_sets=[train_ds, valid_ds],\n        valid_names=[\"train\", \"valid\"],\n        callbacks=[\n            # lgbm.early_stopping(stopping_rounds=5),\n            lgbm.log_evaluation(period=10),\n            lgbm.record_evaluation(eval_results),\n        ]\n    )\n\n    # Predict and score\n    y_hat = model.predict(X_test)\n    metrics = {\n        \"mse\": mean_squared_error(np.array(y_valid), np.array(y_hat)),\n        \"rmse\": np.sqrt(mean_squared_error(np.array(y_valid), np.array(y_hat))),\n        \"eval_results\": eval_results\n    }\n    \n    return metrics",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-01-19T16:01:10.104635Z",
                    "iopub.execute_input": "2025-01-19T16:01:10.105096Z",
                    "iopub.status.idle": "2025-01-19T16:01:10.114480Z",
                    "shell.execute_reply.started": "2025-01-19T16:01:10.105057Z",
                    "shell.execute_reply": "2025-01-19T16:01:10.112917Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "if not SUBMISSION_RUN:\n    cv_results = []\n    for i, (train_df, valid_df) in enumerate(train_valid_split(train_dataset)):\n        print(f\"Running cross validation on split {i}\")\n        X_train, y_train = train_df[FEATURES], train_df[LABEL]\n        X_valid, y_valid = valid_df[FEATURES], valid_df[LABEL]\n        scores = train_predict_score(X_train, y_train, X_valid, y_valid)\n        cv_results.append(scores)\n        print(\"====================================\")\n\nelse:\n    X_train, y_train = train_dataset[FEATURES], train_dataset[LABEL]\n    train_ds = lgbm.Dataset(data=X_train, label=y_train)\n    model = lgbm.train(\n        TRAIN_PARAMETERS,\n        num_boost_round=1000,\n        train_set=train_ds,\n        valid_sets=[train_ds],\n        valid_names=[\"train\"],\n        callbacks=[lgbm.log_evaluation(period=10)]\n    )",
            "metadata": {
                "trusted": true,
                "execution": {
                    "iopub.status.busy": "2025-01-19T16:01:13.623807Z",
                    "iopub.execute_input": "2025-01-19T16:01:13.624233Z",
                    "execution_failed": "2025-01-19T16:03:36.652Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Plot training loss\nif not SUBMISSION_RUN:\n    fig, ax = plt.subplots(1, 2, figsize=(10, 3.5), sharex=True, sharey=True)\n    \n    for split_idx, split_scores in enumerate(cv_results):\n        loss_by_iteration = split_scores[\"eval_results\"]\n        \n        ax[0].plot(\n            loss_by_iteration[\"train\"][\"l2\"],\n            label=f\"split {split_idx}\",\n        )\n        ax[0].legend()\n        \n        ax[1].plot(\n            loss_by_iteration[\"valid\"][\"l2\"],\n            label=f\"split {split_idx}\",\n        )\n        ax[1].legend()\n        ",
            "metadata": {
                "trusted": true,
                "execution": {
                    "execution_failed": "2025-01-19T16:03:36.653Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Submission",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "def kwh_to_kbtu(df: pd.DataFrame) -> pd.DataFrame:\n    mask = (df[\"building_id\"] == 0) & (df[\"meter_id\"] == 0)\n    df.loc[mask, \"meter_reading\"] = df.loc[mask, \"meter_reading\"] * 3.4118\n    return df",
            "metadata": {
                "trusted": true,
                "execution": {
                    "execution_failed": "2025-01-19T16:03:36.653Z"
                }
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Load data\ntest_data = pd.read_parquet(\"/kaggle/input/ashrae-iii/test_df.parquet\")\ntest_data = cast_dtypes(test_data)\n\n# Predict\nX_test = test_data[FEATURES]\ny_hat = np.expm1(model.predict(X_test))\ny_hat = pd.DataFrame(y_hat, columns=[\"meter_reading\"])\n\n# Submit\nsubmission_df = pd.concat([test_data, y_hat], axis=1)\nsubmission_df = kwh_to_kbtu(submission_df)\nsubmission_df = submission_df[[\"row_id\", \"meter_reading\"]].sort_values(\"row_id\")\nsubmission_df.to_csv(\"submission.csv\", index=False)",
            "metadata": {
                "trusted": true,
                "execution": {
                    "execution_failed": "2025-01-19T16:03:36.653Z"
                }
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}