{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "b38f3a4b",
            "metadata": {
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:53:31.779225Z",
                    "iopub.status.busy": "2025-02-05T09:53:31.778817Z",
                    "iopub.status.idle": "2025-02-05T09:53:33.821176Z",
                    "shell.execute_reply": "2025-02-05T09:53:33.820123Z"
                },
                "papermill": {
                    "duration": 2.053406,
                    "end_time": "2025-02-05T09:53:33.823725",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:31.770319",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "from datetime import datetime, date\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from scipy.signal import savgol_filter\n",
                "from tqdm import tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "5c9d73f9",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:53:33.839445Z",
                    "iopub.status.busy": "2025-02-05T09:53:33.838925Z",
                    "iopub.status.idle": "2025-02-05T09:53:33.845395Z",
                    "shell.execute_reply": "2025-02-05T09:53:33.844295Z"
                },
                "papermill": {
                    "duration": 0.016691,
                    "end_time": "2025-02-05T09:53:33.847684",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:33.830993",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Constants\n",
                "INPUT_DATA_PATH = \"/kaggle/input/ashrae-energy-prediction\"\n",
                "\n",
                "MIN_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-01-01 00:00:00\")\n",
                "MAX_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-12-31 23:00:00\")\n",
                "MIN_TEST_TIMESTAMP = pd.Timestamp(\"2017-01-01 00:00:00\")\n",
                "MAX_TEST_TIMESTAMP = pd.Timestamp('2018-12-31 23:00:00')\n",
                "DATA_RESOLUTION = \"1h\"\n",
                "\n",
                "WEATHER_FEATURE_COLUMNS = [\n",
                "    'air_temperature',\n",
                "    'cloud_coverage',\n",
                "    'dew_temperature',\n",
                "    'precip_depth_1_hr',\n",
                "    'sea_level_pressure',\n",
                "    'wind_direction',\n",
                "    'wind_speed'\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "37380817",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:53:33.863511Z",
                    "iopub.status.busy": "2025-02-05T09:53:33.862763Z",
                    "iopub.status.idle": "2025-02-05T09:53:33.870916Z",
                    "shell.execute_reply": "2025-02-05T09:53:33.869908Z"
                },
                "papermill": {
                    "duration": 0.018535,
                    "end_time": "2025-02-05T09:53:33.873273",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:33.854738",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def cast_readings_data(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    df[\"building_id\"] = df[\"building_id\"].astype(\"category\")\n",
                "    df[\"meter_id\"] = df[\"meter_id\"].astype(\"category\")\n",
                "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
                "    try:\n",
                "        df[\"meter_reading\"] = df[\"meter_reading\"].astype(np.float32)\n",
                "    except KeyError:\n",
                "        pass\n",
                "    return df\n",
                "\n",
                "\n",
                "def cast_weather_data(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    df[\"site_id\"] = df[\"site_id\"].astype(\"category\")\n",
                "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
                "    for col in WEATHER_FEATURE_COLUMNS:\n",
                "        df[col] = df[col].astype(np.float32)\n",
                "    return df\n",
                "\n",
                "\n",
                "def cast_buildings_data(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    df[\"site_id\"] = df[\"site_id\"].astype(\"category\")\n",
                "    df[\"building_id\"] = df[\"building_id\"].astype(\"category\")\n",
                "    df[\"primary_use\"] = df[\"primary_use\"].astype(\"category\")\n",
                "    for col in [\"square_feet\", \"year_built\", \"floor_count\"]:\n",
                "        df[col] = df[col].astype(np.float32)\n",
                "    return df"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6131ce25",
            "metadata": {
                "papermill": {
                    "duration": 0.006089,
                    "end_time": "2025-02-05T09:53:33.886085",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:33.879996",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "## Train data"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bf40f9b0",
            "metadata": {
                "papermill": {
                    "duration": 0.006083,
                    "end_time": "2025-02-05T09:53:33.899428",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:33.893345",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "### Load raw data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "47c41ab1",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:53:33.914322Z",
                    "iopub.status.busy": "2025-02-05T09:53:33.913422Z",
                    "iopub.status.idle": "2025-02-05T09:53:57.492756Z",
                    "shell.execute_reply": "2025-02-05T09:53:57.491729Z"
                },
                "papermill": {
                    "duration": 23.589269,
                    "end_time": "2025-02-05T09:53:57.495196",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:33.905927",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Meter readings\n",
                "readings_df_train = pd.read_csv(\n",
                "    f\"{INPUT_DATA_PATH}/train.csv\",\n",
                "    header=0,\n",
                "    names=[\"building_id\", \"meter_id\", \"timestamp\", \"meter_reading\"],\n",
                ")\n",
                "readings_df_train = cast_readings_data(readings_df_train)\n",
                "\n",
                "# Weather\n",
                "weather_df_train = pd.read_csv(f\"{INPUT_DATA_PATH}/weather_train.csv\")\n",
                "weather_df_train = cast_weather_data(weather_df_train)\n",
                "\n",
                "# Buildings\n",
                "buildings_df = pd.read_csv(f\"{INPUT_DATA_PATH}/building_metadata.csv\")\n",
                "buildings_df = cast_buildings_data(buildings_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "868f3998",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-01-30T07:58:23.983382Z",
                    "iopub.status.busy": "2025-01-30T07:58:23.982880Z",
                    "iopub.status.idle": "2025-01-30T07:58:23.989539Z",
                    "shell.execute_reply": "2025-01-30T07:58:23.988093Z",
                    "shell.execute_reply.started": "2025-01-30T07:58:23.983342Z"
                },
                "papermill": {
                    "duration": 0.006163,
                    "end_time": "2025-02-05T09:53:57.508030",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:57.501867",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "### Filtering & Outlier Removal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "2ae4b00a",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:53:57.523211Z",
                    "iopub.status.busy": "2025-02-05T09:53:57.522192Z",
                    "iopub.status.idle": "2025-02-05T09:53:57.532173Z",
                    "shell.execute_reply": "2025-02-05T09:53:57.531125Z"
                },
                "papermill": {
                    "duration": 0.01972,
                    "end_time": "2025-02-05T09:53:57.534166",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:57.514446",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def _find_constant_streaks(\n",
                "    df: pd.DataFrame,\n",
                "    streak_length: int = 25,\n",
                "    target_column: str = \"meter_reading\"\n",
                "):\n",
                "    # Compute diffs on target col\n",
                "    df = df.copy()\n",
                "    df = df.sort_values(\"timestamp\")\n",
                "    df[\"target_col_diff\"] = df[target_column].diff()\n",
                "    \n",
                "    # First find any periods of constant meter readings\n",
                "    streaks = []\n",
                "    current_streak_start = 0\n",
                "    for idx, row in df.iterrows():\n",
                "        if pd.isna(row[\"target_col_diff\"]):\n",
                "            continue\n",
                "        \n",
                "        elif row[\"target_col_diff\"] == 0:\n",
                "            # Start a new streak if not already a running streak\n",
                "            current_streak_start = current_streak_start or idx - 1\n",
                "        \n",
                "        else:\n",
                "            # Streak finished\n",
                "            # Save if there is currently a running streak\n",
                "            if current_streak_start is not None:\n",
                "                streaks.append((current_streak_start, idx - 1))\n",
                "    \n",
                "            # Reset\n",
                "            current_streak_start = None\n",
                "            \n",
                "\n",
                "    # Only keep streaks with length >= streak_length\n",
                "    filtered_streaks = []\n",
                "    for start, end in streaks:\n",
                "        streak_df = df.loc[start: end]\n",
                "        assert (streak_df[\"target_col_diff\"].dropna() == 0).all(), print(start, end)\n",
                "        if len(streak_df) >= streak_length:\n",
                "            start_t = streak_df[\"timestamp\"].min().to_pydatetime()\n",
                "            end_t = streak_df[\"timestamp\"].max().to_pydatetime()\n",
                "            filtered_streaks.append((start_t, end_t))\n",
                "    \n",
                "    return filtered_streaks\n",
                "\n",
                "\n",
                "def find_constant_streaks(\n",
                "    readings_df: pd.DataFrame,\n",
                "    meter_id: int,\n",
                "    building_id: int,\n",
                "    streak_length: int = 25,\n",
                "    target_column: str = \"meter_reading\"\n",
                ") -> list[tuple[datetime | None, datetime | None]]:\n",
                "    bm_df = readings_df[\n",
                "        (readings_df[\"building_id\"] == building_id)\n",
                "        & (readings_df[\"meter_id\"] == meter_id)\n",
                "    ]\n",
                "    return _find_constant_streaks(bm_df, streak_length, target_column)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "4b3c9267",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:53:57.548802Z",
                    "iopub.status.busy": "2025-02-05T09:53:57.548430Z",
                    "iopub.status.idle": "2025-02-05T09:53:57.557681Z",
                    "shell.execute_reply": "2025-02-05T09:53:57.556728Z"
                },
                "papermill": {
                    "duration": 0.018896,
                    "end_time": "2025-02-05T09:53:57.559742",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:57.540846",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def construct_keep_filter(\n",
                "    timestamps: pd.Series,\n",
                "    to_keep: list[tuple[datetime | None, datetime | None]],\n",
                "):\n",
                "    filter_ = pd.Series(\n",
                "        data=np.full(shape=(len(timestamps, )), fill_value=False),\n",
                "        index=timestamps.index,\n",
                "    )\n",
                "    for start, end in to_keep:\n",
                "    \n",
                "        match (start, end):\n",
                "            case None, None:\n",
                "                pass\n",
                "            case (datetime(), None):\n",
                "                period_filter = timestamps >= start\n",
                "            case (None, datetime()):\n",
                "                period_filter = timestamps <= end\n",
                "            case (datetime(), datetime()):\n",
                "                period_filter = (timestamps >= start) & (timestamps <= end)\n",
                "            case _:\n",
                "                print(start, end)\n",
                "                print(\"Unrecognised filter pattern. Skipping ...\")\n",
                "                continue\n",
                "        \n",
                "        filter_ |= period_filter\n",
                "    \n",
                "    return filter_\n",
                "\n",
                "\n",
                "def keep_filter(\n",
                "    data: pd.DataFrame,\n",
                "    to_keep: list[tuple[datetime | None, datetime | None]]\n",
                "):\n",
                "    \"\"\"\n",
                "    Filter data to only include observations included in to_keep filters.\n",
                "    Filters are tuples of datetimes specifying start and end timestamps\n",
                "    (inclusive) of periods to be included.\n",
                "    \"\"\"\n",
                "    keep_filter = construct_keep_filter(data[\"timestamp\"], to_keep)\n",
                "    return data.loc[keep_filter]\n",
                "\n",
                "\n",
                "def remove_filter(\n",
                "    data: pd.DataFrame,\n",
                "    to_remove: list[tuple[datetime | None, datetime | None]]\n",
                "):\n",
                "    \"\"\"\n",
                "    Filter data by removing all observations included in the to_remove filter.\n",
                "    Only observations outside of the filter will be retained in the final data.\n",
                "    Filters are tuples of datetimes specifying start and end timestamps\n",
                "    (inclusive) of periods to be removed.\n",
                "    \"\"\"\n",
                "    remove_filter = construct_keep_filter(data[\"timestamp\"], to_remove)\n",
                "    return data.loc[~remove_filter]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "67043978",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:53:57.574750Z",
                    "iopub.status.busy": "2025-02-05T09:53:57.573908Z",
                    "iopub.status.idle": "2025-02-05T09:53:57.582345Z",
                    "shell.execute_reply": "2025-02-05T09:53:57.581361Z"
                },
                "papermill": {
                    "duration": 0.01793,
                    "end_time": "2025-02-05T09:53:57.584240",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:57.566310",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def filter_readings_data(\n",
                "    readings_df: pd.DataFrame,\n",
                "    meter_id: int,\n",
                "    to_keep_filters: dict[int, list[tuple[datetime | None, datetime | None]]] | None = None,\n",
                "    to_remove_filters: dict[int, list[tuple[datetime | None, datetime | None]]] | None = None,\n",
                "):\n",
                "    to_keep_filters = to_keep_filters or {}\n",
                "    to_remove_filters = to_remove_filters or {}\n",
                "    \n",
                "    to_drop_index_values = np.array([])\n",
                "    filtered_bm_dfs = []\n",
                "\n",
                "    # To keep filters\n",
                "    for b_id, b_filter in tqdm(to_keep_filters.items()):\n",
                "        bm_df = readings_df[\n",
                "            (readings_df[\"building_id\"] == b_id)\n",
                "            & (readings_df[\"meter_id\"] == meter_id)\n",
                "        ]\n",
                "        to_drop_index_values = np.concatenate([to_drop_index_values, bm_df.index])\n",
                "        \n",
                "        bm_df_filtered = keep_filter(bm_df, b_filter)\n",
                "        filtered_bm_dfs.append(bm_df_filtered)\n",
                "\n",
                "    # To remove filters\n",
                "    for b_id, b_filter in tqdm(to_remove_filters.items()):\n",
                "        bm_df = readings_df[\n",
                "            (readings_df[\"building_id\"] == b_id)\n",
                "            & (readings_df[\"meter_id\"] == meter_id)\n",
                "        ]\n",
                "        to_drop_index_values = np.concatenate([to_drop_index_values, bm_df.index])\n",
                "        \n",
                "        bm_df_filtered = remove_filter(bm_df, b_filter)\n",
                "        filtered_bm_dfs.append(bm_df_filtered)\n",
                "    \n",
                "    readings_df = readings_df.drop(index=to_drop_index_values)\n",
                "    filtered_bm_df = pd.concat(filtered_bm_dfs, axis=0)\n",
                "    readings_df = pd.concat([readings_df, filtered_bm_df], axis=0)\n",
                "    \n",
                "    return readings_df"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b5f71161",
            "metadata": {
                "papermill": {
                    "duration": 0.006263,
                    "end_time": "2025-02-05T09:53:57.597257",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:57.590994",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "#### Electricity data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "553b46fb",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:53:57.612376Z",
                    "iopub.status.busy": "2025-02-05T09:53:57.611961Z",
                    "iopub.status.idle": "2025-02-05T09:53:57.620678Z",
                    "shell.execute_reply": "2025-02-05T09:53:57.619736Z"
                },
                "papermill": {
                    "duration": 0.018502,
                    "end_time": "2025-02-05T09:53:57.622679",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:57.604177",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "to_keep_electricity = {\n",
                "    \n",
                "    # Keep everything after May 21\n",
                "    i: [(datetime(2016, 5, 21), None)]\n",
                "    for i in (\n",
                "        list(range(29)) \n",
                "        + list(range(30, 45)) \n",
                "        + list(range(47, 53)) \n",
                "        + list(range(54, 105))\n",
                "    )\n",
                "} | {\n",
                "    \n",
                "    # Some building specific filters\n",
                "    29: [(datetime(2016, 8, 10), None)],\n",
                "    45: [(datetime(2016, 7, 1), None)],\n",
                "    53: [(datetime(2016, 12, 15), None)],  # Only keeping the final timestamp\n",
                "    106: [(datetime(2016, 11, 1), None)],\n",
                "    180: [(None, datetime(2016, 2, 17, 10))],\n",
                "    218: [(None, datetime(2016, 2, 17, 10))],\n",
                "    604: [(datetime(2016, 12, 1), None)],\n",
                "    740: [(datetime(2016, 12, 31), None)], # Only keeping the final timestamp\n",
                "    803: [(None, datetime(2016, 9, 24))],\n",
                "    857: [(None, datetime(2016, 4, 13))],\n",
                "    1113: [(datetime(2016, 7, 27, 10), None)],\n",
                "    1153: [(datetime(2016, 1, 20, 14), None)],\n",
                "    1264: [(None, datetime(2016, 8, 23))],\n",
                "    1345: [(None, datetime(2016, 2, 11))],\n",
                "    46: [(None, datetime(2016, 3, 1)), (datetime(2016, 5, 21), None)],\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "25d70814",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:53:57.637535Z",
                    "iopub.status.busy": "2025-02-05T09:53:57.637177Z",
                    "iopub.status.idle": "2025-02-05T09:57:08.079814Z",
                    "shell.execute_reply": "2025-02-05T09:57:08.078544Z"
                },
                "papermill": {
                    "duration": 190.452537,
                    "end_time": "2025-02-05T09:57:08.081987",
                    "exception": false,
                    "start_time": "2025-02-05T09:53:57.629450",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 274/274 [03:10<00:00,  1.44it/s]\n"
                    ]
                }
            ],
            "source": [
                "to_remove_electricity = {\n",
                "    b_id: find_constant_streaks(readings_df_train, meter_id=0, building_id=b_id)\n",
                "    for b_id in tqdm(\n",
                "        [105]\n",
                "        + list(range(107, 128))\n",
                "        + list(range(136, 156))\n",
                "        + [177]\n",
                "        + list(range(245, 255))\n",
                "        + [269, 278, 376, 537, 545, 577, 681, 693, 723, 733, 738, 799, 802, 874]\n",
                "        + list(range(875, 885))\n",
                "        + [886, 897]\n",
                "        + list(range(905, 946))\n",
                "        + list(range(954, 997))\n",
                "        + [1066, 1079, 1096, 1098, 1128, 1154, 1157, 1160, 1169, 1177, 1185, 1202, 1221, 1225, 1226]\n",
                "        + list(range(1228, 1281))\n",
                "        + list(range(1282, 1314))\n",
                "        + list(range(1315, 1325))\n",
                "        + [1359]\n",
                "    )\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "d486b257",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:57:08.126720Z",
                    "iopub.status.busy": "2025-02-05T09:57:08.126322Z",
                    "iopub.status.idle": "2025-02-05T09:57:37.145964Z",
                    "shell.execute_reply": "2025-02-05T09:57:37.144982Z"
                },
                "papermill": {
                    "duration": 29.044748,
                    "end_time": "2025-02-05T09:57:37.148509",
                    "exception": false,
                    "start_time": "2025-02-05T09:57:08.103761",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 116/116 [00:06<00:00, 18.03it/s]\n",
                        "100%|██████████| 274/274 [00:16<00:00, 16.63it/s]\n"
                    ]
                }
            ],
            "source": [
                "# Apply filters\n",
                "readings_df_train = filter_readings_data(\n",
                "    readings_df_train,\n",
                "    meter_id=0,\n",
                "    to_keep_filters=to_keep_electricity,\n",
                "    to_remove_filters=to_remove_electricity,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a7d0aa58",
            "metadata": {
                "papermill": {
                    "duration": 0.031528,
                    "end_time": "2025-02-05T09:57:37.211930",
                    "exception": false,
                    "start_time": "2025-02-05T09:57:37.180402",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "#### Chilled Water"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "9359450a",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:57:37.277225Z",
                    "iopub.status.busy": "2025-02-05T09:57:37.276818Z",
                    "iopub.status.idle": "2025-02-05T09:58:48.242253Z",
                    "shell.execute_reply": "2025-02-05T09:58:48.241287Z"
                },
                "papermill": {
                    "duration": 71.001967,
                    "end_time": "2025-02-05T09:58:48.245351",
                    "exception": false,
                    "start_time": "2025-02-05T09:57:37.243384",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 138/138 [01:10<00:00,  1.95it/s]\n"
                    ]
                }
            ],
            "source": [
                "to_keep_chilled_water = {\n",
                "    43: [(None, datetime(2016, 4, 4, 19)), (datetime(2016, 6, 6, 11), None)],\n",
                "    60: [(datetime(2016, 4, 29, 10, 0), None)],\n",
                "    162: [(None, datetime(2016, 9, 13, 14)), (datetime(2016, 10, 10, 8), None)],\n",
                "    192: [(None, datetime(2016, 5, 9, 13))],\n",
                "    195: [(None, datetime(2016, 3, 17, 12)), (datetime(2016, 3, 22), None)],\n",
                "    236: [(None, datetime(2016, 1, 24, 2)), (datetime(2016, 3, 21, 12), None)],\n",
                "    258: [(None, datetime(2016, 8, 29, 10)), (datetime(2016, 9, 8, 13), datetime(2016, 9, 19, 6)), (datetime(2016, 12, 12, 9,), None)],\n",
                "    264: [(datetime(2016, 2, 8, 10), None)],\n",
                "    290: [(None, datetime(2016, 8, 19, 1)), (datetime(2016, 9, 9, 7), datetime(2016, 9, 14, 17)), (datetime(2016, 9, 23, 1), datetime(2016, 10, 8, 14)), (datetime(2016, 10, 14, 9), None)],\n",
                "    765: [(datetime(2016, 4, 22, 12), None)],\n",
                "    778: [(datetime(2016, 9, 8, 9), datetime(2016, 10, 20))],\n",
                "    780: [(None, datetime(2016, 8, 2))],\n",
                "    \n",
                "    # Filters for same / similar October pattern\n",
                "    770: [(None, datetime(2016, 10, 4, 10, 0)), (datetime(2016, 10, 10, 11, 0), None)],\n",
                "    777: [(None, datetime(2016, 10, 4, 9)), (datetime(2016, 10, 10, 8), None)],\n",
                "    787: [(None, datetime(2016, 10, 4, 9)), (datetime(2016, 10, 10, 8), None)],\n",
                "\n",
                "    # Filters for same July and October pattern\n",
                "    880: [(None, datetime(2016, 3, 18, 23)), (datetime(2016, 5, 18, 10), datetime(2016, 7, 1, 16)), (datetime(2016, 7, 5, 4), datetime(2016, 10, 15)), (datetime(2016, 10, 17, 6), None)],\n",
                "    954: [(datetime(2016, 8, 8, 11), datetime(2016, 10, 15)), (datetime(2016, 10, 17, 8), None)],\n",
                "    990: [(None, datetime(2016, 7, 1, 16)), (datetime(2016, 7, 5, 4), datetime(2016, 10, 15)), (datetime(2016, 10, 17, 8), None)],\n",
                "    \n",
                "    1167: [(None, datetime(2016, 5, 18, 16)), (datetime(2016, 6, 25, 7), None)],\n",
                "    1225: [(None, datetime(2016, 8, 23, 12)), (datetime(2016, 10, 11, 13), None)],\n",
                "    1226: [(None, datetime(2016, 8, 23, 12)), (datetime(2016, 10, 20, 12), None)],\n",
                "    1232: [(None, datetime(2016, 6, 23, 18)), (datetime(2016, 8, 31, 19), None)],\n",
                "    1244: [(None, datetime(2016, 7, 13, 16)), (datetime(2016, 8, 31, 19), None)],\n",
                "    1246: [(datetime(2016, 3, 2, 19), None)],\n",
                "    1272: [(None, datetime(2016, 9, 28, 9)), (datetime(2016, 10, 20, 12), None)],\n",
                "    1273: [(None, datetime(2016, 5, 31, 16)), (datetime(2016, 6, 16, 23), None)],\n",
                "} | {\n",
                "    # Filters for same July and October pattern\n",
                "    building_id: [(None, datetime(2016, 7, 1, 16)), (datetime(2016, 7, 5, 4), datetime(2016, 10, 15)), (datetime(2016, 10, 17, 6), None)]\n",
                "    for building_id in (\n",
                "        [910, 920, 923, 926, 927, 929, 931, 934, 955, 957]\n",
                "        + [961, 963, 965, 967, 969, 973, 976, 989]\n",
                "        + [993, 994, 996]\n",
                "    )\n",
                "}\n",
                "\n",
                "to_remove_chilled_water = {\n",
                "    b_id: find_constant_streaks(readings_df_train, meter_id=1, building_id=b_id, streak_length=35)\n",
                "    for b_id in tqdm(\n",
                "        [7, 75, 97, 98, 163, 167, 171, 172, 177, 188, 190, 191, 195, 200, 207, 231, 233, 235, 260, 265, 267]        \n",
                "\n",
                "        # Filters for same October pattern\n",
                "        + [748, 750, 752, 755, 763, 776, 786]\n",
                "        \n",
                "        + [789, 790, 792, 801]      \n",
                "\n",
                "        # Filters for same July and October pattern\n",
                "        + [874, 890, 893, 894, 895, 896, 898, 899, 911, 915, 916, 917, 918, 929, 932 ]      \n",
                "        + [933, 935, 942, 951, 952, 953, 957, 958, 959, 960, 961, 962, 964, 965, 966, 968 ]      \n",
                "        + [971, 972, 974, 975, 978, 979, 980, 981, 983, 987, 991, 992, 994, 995, 997 ]           \n",
                "\n",
                "        # Filters for same mid July pattern. All ids contain that period in addition to\n",
                "        # other constant streak periods\n",
                "        + [1223, 1225, 1226, 1227, 1229, 1230, 1233, 1234, 1235, 1236, 1238, 1239, ]             \n",
                "        + [1240, 1241, 1242, 1243, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1255 ]                                \n",
                "        + [1258, 1259, 1260, 1262, 1263, 1264, 1266, 1267, 1280, 1285 ]\n",
                "        + list(range(1286, 1301))\n",
                "        + [1301, 1302, 1303, 1306, 1307, 1308, 1309, 1310, 1311, 1312]\n",
                "    )\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "09e5971c",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:58:48.324678Z",
                    "iopub.status.busy": "2025-02-05T09:58:48.323880Z",
                    "iopub.status.idle": "2025-02-05T09:59:14.923528Z",
                    "shell.execute_reply": "2025-02-05T09:59:14.922556Z"
                },
                "papermill": {
                    "duration": 26.641814,
                    "end_time": "2025-02-05T09:59:14.925829",
                    "exception": false,
                    "start_time": "2025-02-05T09:58:48.284015",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 47/47 [00:01<00:00, 32.27it/s]\n",
                        "100%|██████████| 138/138 [00:04<00:00, 30.23it/s]\n"
                    ]
                }
            ],
            "source": [
                "# Apply filters\n",
                "readings_df_train = filter_readings_data(\n",
                "    readings_df_train,\n",
                "    meter_id=1,\n",
                "    to_keep_filters=to_keep_chilled_water,\n",
                "    to_remove_filters=to_remove_chilled_water,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "c5bf0093",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:15.011601Z",
                    "iopub.status.busy": "2025-02-05T09:59:15.010523Z",
                    "iopub.status.idle": "2025-02-05T09:59:15.016743Z",
                    "shell.execute_reply": "2025-02-05T09:59:15.015622Z"
                },
                "papermill": {
                    "duration": 0.051206,
                    "end_time": "2025-02-05T09:59:15.018644",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:14.967438",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# # Test that filters are working\n",
                "\n",
                "# meter_id = 1\n",
                "# building_id = 1272\n",
                "# building_id_filter = to_keep_chilled_water[building_id]\n",
                "\n",
                "# print(building_id, building_id_filter)\n",
                "\n",
                "# bm_df_before = readings_df_train_before[\n",
                "#     (readings_df_train_before[\"building_id\"] == building_id)\n",
                "#     & (readings_df_train_before[\"meter_id\"] == meter_id)\n",
                "# ]\n",
                "# bm_df_after = readings_df_train_after[\n",
                "#     (readings_df_train_after[\"building_id\"] == building_id)\n",
                "#     & (readings_df_train_after[\"meter_id\"] == meter_id)\n",
                "# ].sort_values(\"timestamp\")\n",
                "\n",
                "# fig, ax = plt.subplots(3, 1, figsize=(15, 10), sharex=True, sharey=True)\n",
                "# ax[0].plot(\n",
                "#     bm_df_before[\"timestamp\"].values,\n",
                "#     bm_df_before[\"meter_reading\"].values,\n",
                "#     label=f\"Before filter\"\n",
                "# )\n",
                "# ax[0].legend()\n",
                "# ax[1].plot(\n",
                "#     bm_df_after[\"timestamp\"].values,\n",
                "#     bm_df_after[\"meter_reading\"].values,\n",
                "#     label=f\"After filter\"\n",
                "# )\n",
                "# ax[1].legend();\n",
                "\n",
                "# ax[2].plot(\n",
                "#     bm_df_before[\"timestamp\"].values,\n",
                "#     bm_df_before[\"meter_reading\"].values,\n",
                "#     label=f\"Before filter\"\n",
                "# )\n",
                "# ax[2].plot(\n",
                "#     bm_df_after[\"timestamp\"].values,\n",
                "#     bm_df_after[\"meter_reading\"].values,\n",
                "#     label=f\"After filter\"\n",
                "# )\n",
                "\n",
                "\n",
                "# for start, end in building_id_filter:\n",
                "#     if start is not None: ax[1].axvline(start, color=\"red\", lw=2)\n",
                "#     if end is not None: ax[1].axvline(end, color=\"red\", lw=2)\n",
                "    \n",
                "# fig.tight_layout();"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3aa68081",
            "metadata": {
                "papermill": {
                    "duration": 0.040692,
                    "end_time": "2025-02-05T09:59:15.100426",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:15.059734",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "### Weather data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "c984df71",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:15.183779Z",
                    "iopub.status.busy": "2025-02-05T09:59:15.183401Z",
                    "iopub.status.idle": "2025-02-05T09:59:15.190335Z",
                    "shell.execute_reply": "2025-02-05T09:59:15.189284Z"
                },
                "papermill": {
                    "duration": 0.051131,
                    "end_time": "2025-02-05T09:59:15.192320",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:15.141189",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Reindex weather data such that every site has a measurement\n",
                "# for each training timestamp\n",
                "\n",
                "\n",
                "def reindex_weather_data(\n",
                "    weather_df: pd.DataFrame,\n",
                "    start_timestamp: pd.Timestamp,\n",
                "    end_timestamp: pd.Timestamp,\n",
                "    freq: str = \"1h\"\n",
                ") -> pd.DataFrame:\n",
                "    weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
                "    timestamps = pd.date_range(\n",
                "        start_timestamp,\n",
                "        end_timestamp,\n",
                "        freq=freq,\n",
                "        inclusive=\"both\"\n",
                "    )\n",
                "    timestamps = pd.DatetimeIndex(timestamps, name=\"timestamp\")\n",
                "    site_dfs = []\n",
                "    for site_id, site_df in weather_df.groupby(\"site_id\", observed=True):\n",
                "        site_df = site_df.set_index(\"timestamp\").reindex(timestamps).reset_index()\n",
                "        site_df[\"site_id\"] = site_df[\"site_id\"].fillna(value=site_id)\n",
                "        site_dfs.append(site_df)\n",
                "\n",
                "    weather_df = pd.concat(site_dfs, ignore_index=True)\n",
                "    return weather_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "e1edd7cb",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:15.283658Z",
                    "iopub.status.busy": "2025-02-05T09:59:15.282851Z",
                    "iopub.status.idle": "2025-02-05T09:59:15.350107Z",
                    "shell.execute_reply": "2025-02-05T09:59:15.349200Z"
                },
                "papermill": {
                    "duration": 0.118205,
                    "end_time": "2025-02-05T09:59:15.352473",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:15.234268",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "weather_df_train = reindex_weather_data(\n",
                "    weather_df=weather_df_train,\n",
                "    start_timestamp=MIN_TRAIN_TIMESTAMP,\n",
                "    end_timestamp=MAX_TRAIN_TIMESTAMP,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "a785553a",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:15.516649Z",
                    "iopub.status.busy": "2025-02-05T09:59:15.515653Z",
                    "iopub.status.idle": "2025-02-05T09:59:15.527688Z",
                    "shell.execute_reply": "2025-02-05T09:59:15.526723Z"
                },
                "papermill": {
                    "duration": 0.135637,
                    "end_time": "2025-02-05T09:59:15.529924",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:15.394287",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Functionality for imputing missing weather data\n",
                "\n",
                "def interpolate(weather_df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
                "    weather_df[column] = weather_df[column].interpolate(\"linear\", limit=12)\n",
                "    weather_df[column] = weather_df[column].ffill(limit=2)\n",
                "    weather_df[column] = weather_df[column].bfill(limit=2)\n",
                "    return weather_df\n",
                "\n",
                "\n",
                "def _mean_weather_by_date_and_site(weather_df, column) -> pd.DataFrame:\n",
                "    mean_values = (\n",
                "        weather_df\n",
                "        .groupby([\"date\", \"site_id\"])[[column]]\n",
                "        .mean()\n",
                "        .reset_index()\n",
                "    )\n",
                "    return mean_values\n",
                "\n",
                "\n",
                "def _merge_onto_weather_df(weather_df, right, right_suffix) -> pd.DataFrame:\n",
                "    weather_df = weather_df.merge(\n",
                "        right=right,\n",
                "        how=\"left\",\n",
                "        on=[\"date\", \"site_id\"],\n",
                "        suffixes=(\"\", right_suffix)\n",
                "    )\n",
                "    return weather_df\n",
                "\n",
                "\n",
                "def impute_with_same_day_mean(weather_df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
                "    # Compute same day mean values and merge onto weather df\n",
                "    mean_values = _mean_weather_by_date_and_site(weather_df, column)\n",
                "    weather_df = _merge_onto_weather_df(weather_df, mean_values, \"_mean\")\n",
                "    \n",
                "    # Fill with means from same day\n",
                "    weather_df[column] = weather_df[column].fillna(weather_df[f\"{column}_mean\"])\n",
                "    weather_df = weather_df.drop(f\"{column}_mean\", axis=1)\n",
                "    return weather_df\n",
                "\n",
                "\n",
                "def ffill_mean_by_date(weather_df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
                "    # Compute same day mean values and merge onto weather df\n",
                "    mean_values = _mean_weather_by_date_and_site(weather_df, column)\n",
                "    \n",
                "    # ffill by site and date\n",
                "    site_dfs = []\n",
                "    for site_id, site_df in mean_values.groupby(\"site_id\"):\n",
                "        site_df = site_df.sort_values(\"date\")\n",
                "        site_df[column] = site_df[column].ffill().bfill()\n",
                "        site_dfs.append(site_df)\n",
                "    mean_values = pd.concat(site_dfs, ignore_index=True)\n",
                "    \n",
                "    # Merge back onto main and fill with mean values\n",
                "    weather_df = _merge_onto_weather_df(weather_df, mean_values, \"_mean\")\n",
                "    weather_df[column] = weather_df[column].fillna(weather_df[f\"{column}_mean\"])\n",
                "    weather_df = weather_df.drop(f\"{column}_mean\", axis=1)\n",
                "    return weather_df\n",
                "\n",
                "\n",
                "def fill_missing_weather_data(weather_df: pd.DataFrame) -> pd.DataFrame:\n",
                "    weather_df[\"date\"] = weather_df[\"timestamp\"].dt.date\n",
                "\n",
                "    for column in WEATHER_FEATURE_COLUMNS:\n",
                "        weather_df = interpolate(weather_df, column)\n",
                "        weather_df = impute_with_same_day_mean(weather_df, column)\n",
                "        weather_df = ffill_mean_by_date(weather_df, column)\n",
                "\n",
                "    weather_df = weather_df.drop(columns=[\"date\"])\n",
                "    \n",
                "    return weather_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "17825c14",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:15.615460Z",
                    "iopub.status.busy": "2025-02-05T09:59:15.615100Z",
                    "iopub.status.idle": "2025-02-05T09:59:15.627039Z",
                    "shell.execute_reply": "2025-02-05T09:59:15.626123Z"
                },
                "papermill": {
                    "duration": 0.057345,
                    "end_time": "2025-02-05T09:59:15.629229",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:15.571884",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Weather data feature engineering\n",
                "# Lagged / rolling features. Compute these before merging to make merges\n",
                "# less memory intensive.\n",
                "\n",
                "def add_smoothed_weather_feature(df: pd.DataFrame, feature: str) -> pd.DataFrame:\n",
                "    site_dfs = []\n",
                "    for site_id, site_df in df.groupby(\"site_id\", observed=True):\n",
                "        site_df = site_df[[\"site_id\", \"timestamp\", feature]]\n",
                "        site_df = site_df.sort_values(\"timestamp\").drop_duplicates(keep=\"first\")\n",
                "        site_df[f\"{feature}_smoothed\"] = savgol_filter(\n",
                "            np.array(site_df[feature]),\n",
                "            window_length=12,\n",
                "            polyorder=2,\n",
                "        )\n",
                "        site_df[f\"{feature}_smoothed\"] = site_df[f\"{feature}_smoothed\"].astype(np.float32)\n",
                "        site_dfs.append(site_df)\n",
                "    site_dfs = pd.concat(site_dfs, ignore_index=True).drop(columns=[feature])\n",
                "    df = df.merge(right=site_dfs, on=[\"site_id\", \"timestamp\"], how=\"left\")\n",
                "    return df\n",
                "\n",
                "\n",
                "def add_lagged_weather_feature(df: pd.DataFrame, feature: str, lag: int) -> pd.DataFrame:\n",
                "    site_dfs = []\n",
                "    for site_id, site_df in df.groupby(\"site_id\", observed=True):\n",
                "        site_df = site_df[[\"site_id\", \"timestamp\", feature]]\n",
                "        site_df = site_df.sort_values(\"timestamp\").drop_duplicates(keep=\"first\")\n",
                "        lag_series = site_df[feature].shift(lag).astype(np.float32)\n",
                "        site_df[f\"{feature}_lag_{lag}\"] = lag_series\n",
                "        site_dfs.append(site_df)\n",
                "    site_dfs = pd.concat(site_dfs, ignore_index=True).drop(columns=[feature])\n",
                "    df = df.merge(right=site_dfs, on=[\"site_id\", \"timestamp\"], how=\"left\")\n",
                "    return df\n",
                "    \n",
                "\n",
                "def add_rolling_mean_weather_feature(df: pd.DataFrame, feature: str, window: int) -> pd.DataFrame:\n",
                "    site_dfs = []\n",
                "    for site_id, site_df in df.groupby(\"site_id\", observed=True):\n",
                "        site_df = site_df[[\"site_id\", \"timestamp\", feature]]\n",
                "        site_df = site_df.sort_values(\"timestamp\").drop_duplicates(keep=\"first\")\n",
                "        rolling_series = site_df[feature].rolling(window).mean().astype(np.float32)\n",
                "        site_df[f\"{feature}_rolling_{window}\"] = rolling_series\n",
                "        site_dfs.append(site_df)\n",
                "    site_dfs = pd.concat(site_dfs, ignore_index=True).drop(columns=[feature])\n",
                "    df = df.merge(right=site_dfs, on=[\"site_id\", \"timestamp\"], how=\"left\")\n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "a674e732",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:15.715650Z",
                    "iopub.status.busy": "2025-02-05T09:59:15.715240Z",
                    "iopub.status.idle": "2025-02-05T09:59:16.181834Z",
                    "shell.execute_reply": "2025-02-05T09:59:16.180772Z"
                },
                "papermill": {
                    "duration": 0.513435,
                    "end_time": "2025-02-05T09:59:16.184432",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:15.670997",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "WEATHER_LAGS = [1, 2]\n",
                "\n",
                "# Air temperature\n",
                "feature_name = \"air_temperature\"\n",
                "for lag in WEATHER_LAGS:\n",
                "    weather_df_train = add_lagged_weather_feature(weather_df_train, feature_name, lag)\n",
                "\n",
                "# Dew temperature\n",
                "feature_name = \"dew_temperature\"\n",
                "for lag in WEATHER_LAGS:\n",
                "    weather_df_train = add_lagged_weather_feature(weather_df_train, feature_name, lag)\n",
                "\n",
                "# Sea level pressure\n",
                "feature_name = \"sea_level_pressure\"\n",
                "for lag in WEATHER_LAGS:\n",
                "    weather_df_train = add_lagged_weather_feature(weather_df_train, feature_name, lag)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "88959c1b",
            "metadata": {
                "papermill": {
                    "duration": 0.041349,
                    "end_time": "2025-02-05T09:59:16.268205",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:16.226856",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "## Merge"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "72cc3157",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:16.355564Z",
                    "iopub.status.busy": "2025-02-05T09:59:16.355191Z",
                    "iopub.status.idle": "2025-02-05T09:59:16.360623Z",
                    "shell.execute_reply": "2025-02-05T09:59:16.359730Z"
                },
                "papermill": {
                    "duration": 0.050296,
                    "end_time": "2025-02-05T09:59:16.362777",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:16.312481",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def merge_dfs(readings_df: pd.DataFrame, buildings_df: pd.DataFrame, weather_df: pd.DataFrame) -> pd.DataFrame:\n",
                "\n",
                "    # Merge\n",
                "    merged_df = pd.merge(left=readings_df, right=buildings_df, how=\"left\", on=\"building_id\")\n",
                "    merged_df = pd.merge(left=merged_df, right=weather_df, how=\"left\", on=[\"site_id\", \"timestamp\"])\n",
                "\n",
                "    return merged_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "304d32a4",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:16.449722Z",
                    "iopub.status.busy": "2025-02-05T09:59:16.448921Z",
                    "iopub.status.idle": "2025-02-05T09:59:23.276398Z",
                    "shell.execute_reply": "2025-02-05T09:59:23.275269Z"
                },
                "papermill": {
                    "duration": 6.874197,
                    "end_time": "2025-02-05T09:59:23.278884",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:16.404687",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "train_df = merge_dfs(readings_df_train, buildings_df, weather_df_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a36a0479",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-01-08T07:28:05.620589Z",
                    "iopub.status.busy": "2025-01-08T07:28:05.619410Z",
                    "iopub.status.idle": "2025-01-08T07:28:07.073796Z",
                    "shell.execute_reply": "2025-01-08T07:28:07.072645Z",
                    "shell.execute_reply.started": "2025-01-08T07:28:05.620539Z"
                },
                "papermill": {
                    "duration": 0.042575,
                    "end_time": "2025-02-05T09:59:23.365419",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:23.322844",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "## Feature engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "20ec0e9e",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:23.451184Z",
                    "iopub.status.busy": "2025-02-05T09:59:23.450240Z",
                    "iopub.status.idle": "2025-02-05T09:59:23.468731Z",
                    "shell.execute_reply": "2025-02-05T09:59:23.467666Z"
                },
                "papermill": {
                    "duration": 0.063615,
                    "end_time": "2025-02-05T09:59:23.471007",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:23.407392",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def kbtu_to_kwh(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    mask = (df[\"building_id\"] == 0) & (df[\"meter_id\"] == 0)\n",
                "    df.loc[mask, \"meter_reading\"] = df.loc[mask, \"meter_reading\"] * 0.2931\n",
                "    return df\n",
                "\n",
                "\n",
                "def add_periodic_features(df: pd.DataFrame, feature: str, period: int) -> pd.DataFrame:\n",
                "    df[f\"{feature}_sin\"] = np.sin(2 * np.pi * df[feature] / period)\n",
                "    df[f\"{feature}_sin\"] = df[f\"{feature}_sin\"].astype(np.float32)\n",
                "    \n",
                "    df[f\"{feature}_cos\"] = np.cos(2 * np.pi * df[feature] / period).astype(np.float32)\n",
                "    df[f\"{feature}_cos\"] = df[f\"{feature}_cos\"].astype(np.float32)\n",
                "    \n",
                "    return df\n",
                "\n",
                "\n",
                "def add_temporal_features(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    df[\"hour\"] = df[\"timestamp\"].dt.hour.astype(np.uint8)\n",
                "    df = add_periodic_features(df, \"hour\", 24)\n",
                "\n",
                "    df[\"day_of_week\"] = df[\"timestamp\"].dt.weekday.astype(np.uint8)\n",
                "    df = add_periodic_features(df, \"day_of_week\", 7)\n",
                "\n",
                "    df[\"month\"] = df[\"timestamp\"].dt.month.astype(np.uint8)\n",
                "    df = add_periodic_features(df, \"month\", 12)\n",
                "\n",
                "    is_weekend = (df[\"timestamp\"].dt.weekday >= 5)\n",
                "    df[\"is_weekend\"] = is_weekend.astype(np.uint8)\n",
                "    \n",
                "    return df\n",
                "\n",
                "\n",
                "def add_building_age_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    df[\"building_age_years\"] = df[\"timestamp\"].dt.year - df[\"year_built\"]\n",
                "    return df\n",
                "\n",
                "\n",
                "def add_building_area_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    df[\"building_area_square_feet\"] = df[\"square_feet\"] * df[\"floor_count\"]\n",
                "    return df\n",
                "\n",
                "\n",
                "def saturation_vapour_pressure(temperature: pd.Series) -> pd.Series:\n",
                "    return 6.1094 * np.exp(17.625 * temperature / (temperature + 243.04))\n",
                "\n",
                "\n",
                "def add_relative_humidity_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    svp_air_temp = saturation_vapour_pressure(df[\"air_temperature\"])\n",
                "    svp_dew_temp = saturation_vapour_pressure(df[\"dew_temperature\"])\n",
                "    rh = 100 * svp_dew_temp / svp_air_temp\n",
                "    df[\"relative_humidity\"] = rh.astype(np.float32)\n",
                "    return df\n",
                "\n",
                "\n",
                "def add_cold_chill_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    # Cold chill only defined for temps below 10C and wind speeds above 1.3 m/s\n",
                "    mask = (df[\"air_temperature\"] <= 10.0) & (df[\"wind_speed\"] >= 1.3)\n",
                "    air_temp = df.loc[mask, \"air_temperature\"]\n",
                "    wind_speed = df.loc[mask, \"wind_speed\"]\n",
                "    cold_chill = (\n",
                "        13.12 \n",
                "        +  0.6215 * air_temp\n",
                "        - 11.37 * (3.6 * wind_speed) ** 0.16\n",
                "        + 0.3965 * air_temp * (3.6 * wind_speed) ** 0.16\n",
                "    )\n",
                "    df.loc[mask, \"cold_chill\"] = cold_chill.astype(np.float32)\n",
                "    return df\n",
                "\n",
                "\n",
                "def add_apparent_temperature_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    mask = df[\"air_temperature\"].between(10, 27, inclusive=\"both\")\n",
                "    air_temp = df.loc[mask, \"air_temperature\"]\n",
                "    wind_speed = df.loc[mask, \"wind_speed\"]\n",
                "    humidity = df.loc[mask, \"relative_humidity\"] / 100\n",
                "    pressure = humidity * 6.105 * np.exp((17.27 * air_temp) / (air_temp + 237.7))\n",
                "    apparent_temp = air_temp + 0.33 * pressure - 0.7 * wind_speed - 4\n",
                "    df.loc[mask, \"apparent_temperature\"] = apparent_temp.astype(np.float32)\n",
                "    return df\n",
                "\n",
                "\n",
                "def add_heat_index_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    mask = df[\"air_temperature\"] >= 27\n",
                "    air_temp = df.loc[mask, \"air_temperature\"]\n",
                "    humidity = df.loc[mask, \"relative_humidity\"]\n",
                "    heat_index = (\n",
                "        - 8.7847 \n",
                "        + 1.6114 * air_temp \n",
                "        + 2.3385 * humidity\n",
                "        - 0.1461 * air_temp * humidity\n",
                "        - 0.0123 * air_temp ** 2 \n",
                "        - 0.0164 * humidity ** 2\n",
                "        + 2.212e-03 * air_temp ** 2 * humidity\n",
                "        + 7.255e-04 * air_temp * humidity ** 2\n",
                "        - 3.582e-06 * air_temp ** 2 * humidity ** 2\n",
                "    )\n",
                "    df.loc[mask, \"heat_index\"] = heat_index.astype(np.float32)\n",
                "    return df\n",
                "\n",
                "\n",
                "def cooling_degree_days(df: pd.DataFrame) -> pd.DataFrame:\n",
                "    # https://www.investopedia.com/terms/c/colddegreeday.asp\n",
                "    ...\n",
                "\n",
                "\n",
                "def heating_degree_days():\n",
                "    ..."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "f7e99b91",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:23.558446Z",
                    "iopub.status.busy": "2025-02-05T09:59:23.557638Z",
                    "iopub.status.idle": "2025-02-05T09:59:33.792219Z",
                    "shell.execute_reply": "2025-02-05T09:59:33.790777Z"
                },
                "papermill": {
                    "duration": 10.281379,
                    "end_time": "2025-02-05T09:59:33.795214",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:23.513835",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Timestamp features\n",
                "train_df = add_temporal_features(train_df)\n",
                "\n",
                "# Meter reading features\n",
                "train_df = kbtu_to_kwh(train_df)\n",
                "\n",
                "# Building features\n",
                "train_df = add_building_age_feature(train_df)\n",
                "train_df = add_building_area_feature(train_df)\n",
                "\n",
                "# Weather features\n",
                "train_df = add_relative_humidity_feature(train_df)\n",
                "train_df = add_cold_chill_feature(train_df)\n",
                "train_df = add_apparent_temperature_feature(train_df)\n",
                "train_df = add_heat_index_feature(train_df)\n",
                "train_df = add_periodic_features(train_df, \"wind_direction\", 360)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "2b48a00e",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:33.887835Z",
                    "iopub.status.busy": "2025-02-05T09:59:33.887228Z",
                    "iopub.status.idle": "2025-02-05T09:59:58.287657Z",
                    "shell.execute_reply": "2025-02-05T09:59:58.285684Z"
                },
                "papermill": {
                    "duration": 24.453146,
                    "end_time": "2025-02-05T09:59:58.295253",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:33.842107",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "train_df.to_parquet(\"train_df.parquet\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1f88d0fa",
            "metadata": {
                "papermill": {
                    "duration": 0.042262,
                    "end_time": "2025-02-05T09:59:58.390875",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:58.348613",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "## Test data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "ad46a1ce",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T09:59:58.480422Z",
                    "iopub.status.busy": "2025-02-05T09:59:58.479960Z",
                    "iopub.status.idle": "2025-02-05T10:00:50.983537Z",
                    "shell.execute_reply": "2025-02-05T10:00:50.981909Z"
                },
                "papermill": {
                    "duration": 52.552785,
                    "end_time": "2025-02-05T10:00:50.988330",
                    "exception": false,
                    "start_time": "2025-02-05T09:59:58.435545",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Meter readings\n",
                "readings_df_test = pd.read_csv(\n",
                "    f\"{INPUT_DATA_PATH}/test.csv\",\n",
                "    header=0,\n",
                "    names=[\"row_id\", \"building_id\", \"meter_id\", \"timestamp\"],\n",
                ")\n",
                "readings_df_test = cast_readings_data(readings_df_test)\n",
                "readings_df_test[\"row_id\"] = readings_df_test[\"row_id\"].astype(np.uint32)\n",
                "\n",
                "# Weather\n",
                "weather_df_test = pd.read_csv(f\"{INPUT_DATA_PATH}/weather_test.csv\")\n",
                "weather_df_test = cast_weather_data(weather_df_test)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "6672b627",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T10:00:51.081526Z",
                    "iopub.status.busy": "2025-02-05T10:00:51.081122Z",
                    "iopub.status.idle": "2025-02-05T10:00:51.190956Z",
                    "shell.execute_reply": "2025-02-05T10:00:51.189783Z"
                },
                "papermill": {
                    "duration": 0.157272,
                    "end_time": "2025-02-05T10:00:51.193481",
                    "exception": false,
                    "start_time": "2025-02-05T10:00:51.036209",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Reindex weather data\n",
                "weather_df_test = reindex_weather_data(\n",
                "    weather_df=weather_df_test,\n",
                "    start_timestamp=MIN_TEST_TIMESTAMP,\n",
                "    end_timestamp=MAX_TEST_TIMESTAMP,\n",
                ")\n",
                "\n",
                "# Concat train and test weather data\n",
                "train_timestamp_cutoff = MIN_TEST_TIMESTAMP - pd.Timedelta(\"1d\")  # More than enough\n",
                "timestamp_mask = weather_df_train[\"timestamp\"] >= train_timestamp_cutoff\n",
                "weather_cols = [\"timestamp\", \"site_id\"] + WEATHER_FEATURE_COLUMNS\n",
                "weather_df_test = pd.concat(\n",
                "    [\n",
                "        weather_df_test,\n",
                "        weather_df_train[timestamp_mask][weather_cols]\n",
                "        \n",
                "    ],\n",
                "    axis=0,\n",
                "    ignore_index=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "15be8890",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T10:00:51.282024Z",
                    "iopub.status.busy": "2025-02-05T10:00:51.281533Z",
                    "iopub.status.idle": "2025-02-05T10:00:52.352004Z",
                    "shell.execute_reply": "2025-02-05T10:00:52.350849Z"
                },
                "papermill": {
                    "duration": 1.118488,
                    "end_time": "2025-02-05T10:00:52.354721",
                    "exception": false,
                    "start_time": "2025-02-05T10:00:51.236233",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Compute lagged / rolling weather features\n",
                "WEATHER_LAGS = [1, 2]\n",
                "\n",
                "# Air temperature\n",
                "feature_name = \"air_temperature\"\n",
                "for lag in WEATHER_LAGS:\n",
                "    weather_df_test = add_lagged_weather_feature(weather_df_test, feature_name, lag)\n",
                "\n",
                "# Dew temperature\n",
                "feature_name = \"dew_temperature\"\n",
                "for lag in WEATHER_LAGS:\n",
                "    weather_df_test = add_lagged_weather_feature(weather_df_test, feature_name, lag)\n",
                "\n",
                "# Sea level pressure\n",
                "feature_name = \"sea_level_pressure\"\n",
                "for lag in WEATHER_LAGS:\n",
                "    weather_df_test = add_lagged_weather_feature(weather_df_test, feature_name, lag)\n",
                "\n",
                "\n",
                "weather_df_test = weather_df_test.sort_values([\"site_id\", \"timestamp\"]).reset_index(drop=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "4db65e5c",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T10:00:52.442364Z",
                    "iopub.status.busy": "2025-02-05T10:00:52.441951Z",
                    "iopub.status.idle": "2025-02-05T10:01:03.510727Z",
                    "shell.execute_reply": "2025-02-05T10:01:03.509359Z"
                },
                "papermill": {
                    "duration": 11.115841,
                    "end_time": "2025-02-05T10:01:03.513840",
                    "exception": false,
                    "start_time": "2025-02-05T10:00:52.397999",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Merge all dfs\n",
                "test_df = merge_dfs(readings_df_test, buildings_df, weather_df_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5f1723d9",
            "metadata": {
                "papermill": {
                    "duration": 0.042648,
                    "end_time": "2025-02-05T10:01:03.600158",
                    "exception": false,
                    "start_time": "2025-02-05T10:01:03.557510",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "### Feature engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "582fa22a",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T10:01:03.690450Z",
                    "iopub.status.busy": "2025-02-05T10:01:03.690019Z",
                    "iopub.status.idle": "2025-02-05T10:01:25.149818Z",
                    "shell.execute_reply": "2025-02-05T10:01:25.148934Z"
                },
                "papermill": {
                    "duration": 21.509369,
                    "end_time": "2025-02-05T10:01:25.152208",
                    "exception": false,
                    "start_time": "2025-02-05T10:01:03.642839",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Timestamp features\n",
                "test_df = add_temporal_features(test_df)\n",
                "\n",
                "# Building features\n",
                "test_df = add_building_age_feature(test_df)\n",
                "test_df = add_building_area_feature(test_df)\n",
                "\n",
                "# Weather features\n",
                "test_df = add_relative_humidity_feature(test_df)\n",
                "test_df = add_cold_chill_feature(test_df)\n",
                "test_df = add_apparent_temperature_feature(test_df)\n",
                "test_df = add_heat_index_feature(test_df)\n",
                "test_df = add_periodic_features(test_df, \"wind_direction\", 360)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "a3bb50d0",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2025-02-05T10:01:25.238689Z",
                    "iopub.status.busy": "2025-02-05T10:01:25.238315Z",
                    "iopub.status.idle": "2025-02-05T10:02:02.705371Z",
                    "shell.execute_reply": "2025-02-05T10:02:02.704160Z"
                },
                "papermill": {
                    "duration": 37.513165,
                    "end_time": "2025-02-05T10:02:02.707906",
                    "exception": false,
                    "start_time": "2025-02-05T10:01:25.194741",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "test_df.to_parquet(\"test_df.parquet\")"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "databundleVersionId": 752467,
                    "sourceId": 9994,
                    "sourceType": "competition"
                }
            ],
            "dockerImageVersionId": 30786,
            "isGpuEnabled": false,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        },
        "papermill": {
            "default_parameters": {},
            "duration": 514.856547,
            "end_time": "2025-02-05T10:02:03.573868",
            "environment_variables": {},
            "exception": null,
            "input_path": "__notebook__.ipynb",
            "output_path": "__notebook__.ipynb",
            "parameters": {},
            "start_time": "2025-02-05T09:53:28.717321",
            "version": "2.6.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}