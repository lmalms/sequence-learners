{
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.14",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "sourceId": 9994,
                    "databundleVersionId": 752467,
                    "sourceType": "competition"
                }
            ],
            "dockerImageVersionId": 30786,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": false
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "from datetime import datetime, date\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import savgol_filter",
            "metadata": {
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Constants\nINPUT_DATA_PATH = \"/kaggle/input/ashrae-energy-prediction\"\n\nMIN_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-01-01 00:00:00\")\nMAX_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-12-31 23:00:00\")\nTRAIN_DATA_RESOLUTION = \"1h\"",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Load raw data",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Meter readings\nreadings_df = pd.read_csv(\n    f\"{INPUT_DATA_PATH}/train.csv\",\n    header=0,\n    names=[\"building_id\", \"meter_id\", \"timestamp\", \"meter_reading\"],\n)\nreadings_df[\"timestamp\"] = pd.to_datetime(readings_df[\"timestamp\"])\n\n# Buildings\nbuildings_df = pd.read_csv(f\"{INPUT_DATA_PATH}/building_metadata.csv\")\n\n# Weather\nweather_df = pd.read_csv(f\"{INPUT_DATA_PATH}/weather_train.csv\")\nweather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Preprocess weather data",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "WEATHER_FEATURE_COLUMNS = [\n    'air_temperature',\n    'cloud_coverage',\n    'dew_temperature',\n    'precip_depth_1_hr',\n    'sea_level_pressure',\n    'wind_direction',\n    'wind_speed'\n]",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "def reindex_weather_data(weather_df: pd.DataFrame) -> pd.DataFrame:\n    # Reindex weather data such that every site has a measurement\n    # for each training timestamp\n    weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])\n    timestamps = pd.date_range(\n        MIN_TRAIN_TIMESTAMP,\n        MAX_TRAIN_TIMESTAMP,\n        freq=TRAIN_DATA_RESOLUTION,\n        inclusive=\"both\"\n    )\n    timestamps = pd.DatetimeIndex(timestamps, name=\"timestamp\")\n    site_dfs = []\n    for site_id, site_df in weather_df.groupby(\"site_id\", observed=True):\n        site_df = site_df.set_index(\"timestamp\").reindex(timestamps).reset_index()\n        site_df[\"site_id\"] = site_df[\"site_id\"].fillna(value=site_id)\n        site_dfs.append(site_df)\n\n    weather_df = pd.concat(site_dfs, ignore_index=True)\n    return weather_df\n\n\ndef interpolate(weather_df: pd.DataFrame, column: str) -> pd.DataFrame:\n    weather_df[column] = weather_df[column].interpolate(\"linear\", limit=12)\n    weather_df[column] = weather_df[column].ffill(limit=2)\n    weather_df[column] = weather_df[column].bfill(limit=2)\n    return weather_df\n\n\ndef _mean_weather_by_date_and_site(weather_df, column) -> pd.DataFrame:\n    mean_values = (\n        weather_df\n        .groupby([\"date\", \"site_id\"])[[column]]\n        .mean()\n        .reset_index()\n    )\n    return mean_values\n\n\ndef _merge_onto_weather_df(weather_df, right, right_suffix) -> pd.DataFrame:\n    weather_df = weather_df.merge(\n        right=right,\n        how=\"left\",\n        on=[\"date\", \"site_id\"],\n        suffixes=(\"\", right_suffix)\n    )\n    return weather_df\n\n\ndef impute_with_same_day_mean(weather_df: pd.DataFrame, column: str) -> pd.DataFrame:\n    # Compute same day mean values and merge onto weather df\n    mean_values = _mean_weather_by_date_and_site(weather_df, column)\n    weather_df = _merge_onto_weather_df(weather_df, mean_values, \"_mean\")\n    \n    # Fill with means from same day\n    weather_df[column] = weather_df[column].fillna(weather_df[f\"{column}_mean\"])\n    weather_df = weather_df.drop(f\"{column}_mean\", axis=1)\n    return weather_df\n\n\ndef ffill_mean_by_date(weather_df: pd.DataFrame, column: str) -> pd.DataFrame:\n    # Compute same day mean values and merge onto weather df\n    mean_values = _mean_weather_by_date_and_site(weather_df, column)\n    \n    # ffill by site and date\n    site_dfs = []\n    for site_id, site_df in mean_values.groupby(\"site_id\"):\n        site_df = site_df.sort_values(\"date\")\n        site_df[column] = site_df[column].ffill().bfill()\n        site_dfs.append(site_df)\n    mean_values = pd.concat(site_dfs, ignore_index=True)\n    \n    # Merge back onto main and fill with mean values\n    weather_df = _merge_onto_weather_df(weather_df, mean_values, \"_mean\")\n    weather_df[column] = weather_df[column].fillna(weather_df[f\"{column}_mean\"])\n    weather_df = weather_df.drop(f\"{column}_mean\", axis=1)\n    return weather_df\n\n\ndef fill_missing_weather_data(weather_df: pd.DataFrame) -> pd.DataFrame:\n    weather_df[\"date\"] = weather_df[\"timestamp\"].dt.date\n\n    for column in WEATHER_FEATURE_COLUMNS:\n        weather_df = interpolate(weather_df, column)\n        weather_df = impute_with_same_day_mean(weather_df, column)\n        weather_df = ffill_mean_by_date(weather_df, column)\n\n    weather_df = weather_df.drop(columns=[\"date\"])\n    \n    return weather_df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "weather_df = reindex_weather_data(weather_df)\nweather_df = fill_missing_weather_data(weather_df)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Weather feature engineering",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "def add_smoothed_weather_feature(df: pd.DataFrame, feature: str) -> pd.DataFrame:\n    site_dfs = []\n    for site_id, site_df in df.groupby(\"site_id\"):\n        site_df = site_df[[\"site_id\", \"timestamp\", feature]]\n        site_df = site_df.drop_duplicates(keep=\"first\")\n        site_df[f\"{feature}_smoothed\"] = savgol_filter(\n            np.array(site_df[feature]),\n            window_length=12,\n            polyorder=2,\n        )\n        site_dfs.append(site_df)\n    site_dfs = pd.concat(site_dfs, ignore_index=True).drop(columns=[feature])\n    df = df.merge(right=site_dfs, on=[\"site_id\", \"timestamp\"], how=\"left\")\n    return df\n\n\ndef add_lagged_weather_feature(df: pd.DataFrame, feature: str, lag: int) -> pd.DataFrame:\n    site_dfs = []\n    for site_id, site_df in df.groupby(\"site_id\"):\n        site_df = site_df[[\"site_id\", \"timestamp\", feature]]\n        site_df = site_df.drop_duplicates(keep=\"first\")\n        site_df[f\"{feature}_lag_{lag}\"] = site_df[feature].shift(lag)\n        site_dfs.append(site_df)\n    site_dfs = pd.concat(site_dfs, ignore_index=True).drop(columns=[feature])\n    df = df.merge(right=site_dfs, on=[\"site_id\", \"timestamp\"], how=\"left\")\n    return df\n    \n\ndef add_rolling_mean_weather_feature(df: pd.DataFrame, feature_name: str) -> pd.DataFrame:\n    # Do this by site!!\n    ...",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Air temperature\n\nweather_df = add_smoothed_weather_feature(weather_df, \"air_temperature\")\nweather_df = add_lagged_weather_feature(weather_df, \"air_temperature\", 1)\nweather_df = add_lagged_weather_feature(weather_df, \"air_temperature\", 2)\n\n\n# Dew temperature\n...\n\n\n# Sea level pressure\n...",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "weather_df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Merge",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "def merge_dfs(readings_df: pd.DataFrame, buildings_df: pd.DataFrame, weather_df: pd.DataFrame) -> pd.DataFrame:\n    # Cast merge cols to the same type\n    readings_df[\"building_id\"] = readings_df[\"building_id\"].astype(int)\n    readings_df[\"timestamp\"] = pd.to_datetime(readings_df[\"timestamp\"])\n\n    buildings_df[\"building_id\"] = buildings_df[\"building_id\"].astype(int)\n    buildings_df[\"site_id\"] = buildings_df[\"site_id\"].astype(int)\n\n    weather_df[\"site_id\"] = weather_df[\"site_id\"].astype(int)\n    weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])\n\n    # Merge\n    merged_df = pd.merge(left=readings_df, right=buildings_df, how=\"left\", on=\"building_id\")\n    merged_df = pd.merge(left=merged_df, right=weather_df, how=\"left\", on=[\"site_id\", \"timestamp\"])\n\n    return merged_df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "train_df = merge_dfs(readings_df, buildings_df, weather_df)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Feature engineering",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2025-01-08T07:28:05.619410Z",
                    "iopub.execute_input": "2025-01-08T07:28:05.620589Z",
                    "iopub.status.idle": "2025-01-08T07:28:07.073796Z",
                    "shell.execute_reply.started": "2025-01-08T07:28:05.620539Z",
                    "shell.execute_reply": "2025-01-08T07:28:07.072645Z"
                }
            }
        },
        {
            "cell_type": "code",
            "source": "def add_periodic_features(df: pd.DataFrame, feature: str, period: int) -> pd.DataFrame:\n    df[f\"{feature}_sin\"] = np.sin(2 * np.pi * df[feature] / period)\n    df[f\"{feature}_cos\"] = np.cos(2 * np.pi * df[feature] / period)\n    return df\n",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Meter reading features\n\ndef kbtu_to_kwh(df: pd.DataFrame) -> pd.DataFrame:\n    mask = (df[\"building_id\"] == 0) & (df[\"meter_id\"] == 0)\n    df.loc[mask, \"meter_reading\"] = df.loc[mask, \"meter_reading\"] * 0.2931\n    return df\n\n\ndef add_temporal_features(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"hour\"] = df[\"timestamp\"].dt.hour\n    df = add_periodic_features(df, \"hour\", 24)\n    \n    df[\"day_of_week\"] = df[\"timestamp\"].dt.weekday\n    df = add_periodic_features(df, \"day_of_week\", 7)\n    \n    df[\"month\"] = df[\"timestamp\"].dt.month\n    df = add_periodic_features(df, \"month\", 12)\n    \n    df[\"is_weekend\"] = (df[\"timestamp\"].dt.weekday >= 5).astype(float)\n    \n    return df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "train_df = kbtu_to_kwh(train_df)\ntrain_df = add_temporal_features(train_df)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Building features\n\ndef add_building_age_feature(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"building_age_years\"] = df[\"timestamp\"].dt.year - df[\"year_built\"]\n    return df\n\n\ndef add_building_area_feature(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"building_area_square_feet\"] = df[\"square_feet\"] * df[\"floor_count\"]\n    return df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "train_df = add_building_age_feature(train_df)\ntrain_df = add_building_area_feature(train_df)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Weather features\n\n# https://www.kaggle.com/code/selfishgene/filtering-and-auto-correlation-tutorial\n\nWEATHER_FEATURE_COLUMNS = [\n    'air_temperature',  # smooth out using sg filter + rolling 24hr mean\n    'cloud_coverage',\n    'dew_temperature',  # smooth out using sg filter\n    'precip_depth_1_hr',\n    'sea_level_pressure',  # smooth out using sg filter + rolling 24hr mean\n    'wind_direction',  # sin / cos \n    'wind_speed'\n]\n\n\ndef feels_like_temperature_feature(df: pd.DataFrame) -> pd.DataFrame:\n    ...\n\n\ndef wet_bulb_temperature_feature(df: pd.DataFrame) -> pd.DataFrame:\n    ...\n\n\ndef cooling_degree_days(df: pd.DataFrame) -> pd.DataFrame:\n    # https://www.investopedia.com/terms/c/colddegreeday.asp\n    ...\n\n\ndef heating_degree_days():\n    ...",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "def target_transform(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"log_meter_reading\"] = np.log1p(np.array(df[\"meter_reading\"]))\n    return df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}