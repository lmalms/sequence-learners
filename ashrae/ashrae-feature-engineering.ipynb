{
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.14",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "sourceId": 9994,
                    "databundleVersionId": 752467,
                    "sourceType": "competition"
                }
            ],
            "dockerImageVersionId": 30786,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": false
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "from datetime import datetime, date\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import savgol_filter",
            "metadata": {
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Constants\nINPUT_DATA_PATH = \"/kaggle/input/ashrae-energy-prediction\"\n\nMIN_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-01-01 00:00:00\")\nMAX_TRAIN_TIMESTAMP = pd.Timestamp(\"2016-12-31 23:00:00\")\nMIN_TEST_TIMESTAMP = pd.Timestamp(\"2017-01-01 00:00:00\")\nMAX_TEST_TIMESTAMP = pd.Timestamp('2018-12-31 23:00:00')\nDATA_RESOLUTION = \"1h\"\n\nWEATHER_FEATURE_COLUMNS = [\n    'air_temperature',\n    'cloud_coverage',\n    'dew_temperature',\n    'precip_depth_1_hr',\n    'sea_level_pressure',\n    'wind_direction',\n    'wind_speed'\n]",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "def cast_readings_data(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"building_id\"] = df[\"building_id\"].astype(\"category\")\n    df[\"meter_id\"] = df[\"meter_id\"].astype(\"category\")\n    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n    try:\n        df[\"meter_reading\"] = df[\"meter_reading\"].astype(np.float32)\n    except KeyError:\n        pass\n    return df\n\n\ndef cast_weather_data(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"site_id\"] = df[\"site_id\"].astype(\"category\")\n    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n    for col in WEATHER_FEATURE_COLUMNS:\n        df[col] = df[col].astype(np.float32)\n    return df\n\n\ndef cast_buildings_data(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"site_id\"] = df[\"site_id\"].astype(\"category\")\n    df[\"building_id\"] = df[\"building_id\"].astype(\"category\")\n    df[\"primary_use\"] = df[\"primary_use\"].astype(\"category\")\n    for col in [\"square_feet\", \"year_built\", \"floor_count\"]:\n        df[col] = df[col].astype(np.float32)\n    return df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Train data",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": "### Load raw data",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Meter readings\nreadings_df_train = pd.read_csv(\n    f\"{INPUT_DATA_PATH}/train.csv\",\n    header=0,\n    names=[\"building_id\", \"meter_id\", \"timestamp\", \"meter_reading\"],\n)\nreadings_df_train = cast_readings_data(readings_df_train)\n\n# Weather\nweather_df_train = pd.read_csv(f\"{INPUT_DATA_PATH}/weather_train.csv\")\nweather_df_train = cast_weather_data(weather_df_train)\n\n# Buildings\nbuildings_df = pd.read_csv(f\"{INPUT_DATA_PATH}/building_metadata.csv\")\nbuildings_df = cast_buildings_data(buildings_df)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "### Weather data",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Reindex weather data such that every site has a measurement\n# for each training timestamp\n\n\ndef reindex_weather_data(\n    weather_df: pd.DataFrame,\n    start_timestamp: pd.Timestamp,\n    end_timestamp: pd.Timestamp,\n    freq: str = \"1h\"\n) -> pd.DataFrame:\n    weather_df[\"timestamp\"] = pd.to_datetime(weather_df[\"timestamp\"])\n    timestamps = pd.date_range(\n        start_timestamp,\n        end_timestamp,\n        freq=freq,\n        inclusive=\"both\"\n    )\n    timestamps = pd.DatetimeIndex(timestamps, name=\"timestamp\")\n    site_dfs = []\n    for site_id, site_df in weather_df.groupby(\"site_id\", observed=True):\n        site_df = site_df.set_index(\"timestamp\").reindex(timestamps).reset_index()\n        site_df[\"site_id\"] = site_df[\"site_id\"].fillna(value=site_id)\n        site_dfs.append(site_df)\n\n    weather_df = pd.concat(site_dfs, ignore_index=True)\n    return weather_df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "weather_df_train = reindex_weather_data(\n    weather_df=weather_df_train,\n    start_timestamp=MIN_TRAIN_TIMESTAMP,\n    end_timestamp=MAX_TRAIN_TIMESTAMP,\n)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Functionality for imputing missing weather data\n\ndef interpolate(weather_df: pd.DataFrame, column: str) -> pd.DataFrame:\n    weather_df[column] = weather_df[column].interpolate(\"linear\", limit=12)\n    weather_df[column] = weather_df[column].ffill(limit=2)\n    weather_df[column] = weather_df[column].bfill(limit=2)\n    return weather_df\n\n\ndef _mean_weather_by_date_and_site(weather_df, column) -> pd.DataFrame:\n    mean_values = (\n        weather_df\n        .groupby([\"date\", \"site_id\"])[[column]]\n        .mean()\n        .reset_index()\n    )\n    return mean_values\n\n\ndef _merge_onto_weather_df(weather_df, right, right_suffix) -> pd.DataFrame:\n    weather_df = weather_df.merge(\n        right=right,\n        how=\"left\",\n        on=[\"date\", \"site_id\"],\n        suffixes=(\"\", right_suffix)\n    )\n    return weather_df\n\n\ndef impute_with_same_day_mean(weather_df: pd.DataFrame, column: str) -> pd.DataFrame:\n    # Compute same day mean values and merge onto weather df\n    mean_values = _mean_weather_by_date_and_site(weather_df, column)\n    weather_df = _merge_onto_weather_df(weather_df, mean_values, \"_mean\")\n    \n    # Fill with means from same day\n    weather_df[column] = weather_df[column].fillna(weather_df[f\"{column}_mean\"])\n    weather_df = weather_df.drop(f\"{column}_mean\", axis=1)\n    return weather_df\n\n\ndef ffill_mean_by_date(weather_df: pd.DataFrame, column: str) -> pd.DataFrame:\n    # Compute same day mean values and merge onto weather df\n    mean_values = _mean_weather_by_date_and_site(weather_df, column)\n    \n    # ffill by site and date\n    site_dfs = []\n    for site_id, site_df in mean_values.groupby(\"site_id\"):\n        site_df = site_df.sort_values(\"date\")\n        site_df[column] = site_df[column].ffill().bfill()\n        site_dfs.append(site_df)\n    mean_values = pd.concat(site_dfs, ignore_index=True)\n    \n    # Merge back onto main and fill with mean values\n    weather_df = _merge_onto_weather_df(weather_df, mean_values, \"_mean\")\n    weather_df[column] = weather_df[column].fillna(weather_df[f\"{column}_mean\"])\n    weather_df = weather_df.drop(f\"{column}_mean\", axis=1)\n    return weather_df\n\n\ndef fill_missing_weather_data(weather_df: pd.DataFrame) -> pd.DataFrame:\n    weather_df[\"date\"] = weather_df[\"timestamp\"].dt.date\n\n    for column in WEATHER_FEATURE_COLUMNS:\n        weather_df = interpolate(weather_df, column)\n        weather_df = impute_with_same_day_mean(weather_df, column)\n        weather_df = ffill_mean_by_date(weather_df, column)\n\n    weather_df = weather_df.drop(columns=[\"date\"])\n    \n    return weather_df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Weather data feature engineering\n# Lagged / rolling features. Compute these before merging to make merges\n# less memory intensive.\n\ndef add_smoothed_weather_feature(df: pd.DataFrame, feature: str) -> pd.DataFrame:\n    site_dfs = []\n    for site_id, site_df in df.groupby(\"site_id\", observed=True):\n        site_df = site_df[[\"site_id\", \"timestamp\", feature]]\n        site_df = site_df.sort_values(\"timestamp\").drop_duplicates(keep=\"first\")\n        site_df[f\"{feature}_smoothed\"] = savgol_filter(\n            np.array(site_df[feature]),\n            window_length=12,\n            polyorder=2,\n        )\n        site_df[f\"{feature}_smoothed\"] = site_df[f\"{feature}_smoothed\"].astype(np.float32)\n        site_dfs.append(site_df)\n    site_dfs = pd.concat(site_dfs, ignore_index=True).drop(columns=[feature])\n    df = df.merge(right=site_dfs, on=[\"site_id\", \"timestamp\"], how=\"left\")\n    return df\n\n\ndef add_lagged_weather_feature(df: pd.DataFrame, feature: str, lag: int) -> pd.DataFrame:\n    site_dfs = []\n    for site_id, site_df in df.groupby(\"site_id\", observed=True):\n        site_df = site_df[[\"site_id\", \"timestamp\", feature]]\n        site_df = site_df.sort_values(\"timestamp\").drop_duplicates(keep=\"first\")\n        lag_series = site_df[feature].shift(lag).astype(np.float32)\n        site_df[f\"{feature}_lag_{lag}\"] = lag_series\n        site_dfs.append(site_df)\n    site_dfs = pd.concat(site_dfs, ignore_index=True).drop(columns=[feature])\n    df = df.merge(right=site_dfs, on=[\"site_id\", \"timestamp\"], how=\"left\")\n    return df\n    \n\ndef add_rolling_mean_weather_feature(df: pd.DataFrame, feature: str, window: int) -> pd.DataFrame:\n    site_dfs = []\n    for site_id, site_df in df.groupby(\"site_id\", observed=True):\n        site_df = site_df[[\"site_id\", \"timestamp\", feature]]\n        site_df = site_df.sort_values(\"timestamp\").drop_duplicates(keep=\"first\")\n        rolling_series = site_df[feature].rolling(window).mean().astype(np.float32)\n        site_df[f\"{feature}_rolling_{window}\"] = rolling_series\n        site_dfs.append(site_df)\n    site_dfs = pd.concat(site_dfs, ignore_index=True).drop(columns=[feature])\n    df = df.merge(right=site_dfs, on=[\"site_id\", \"timestamp\"], how=\"left\")\n    return df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "WEATHER_LAGS = [1, 2]\n\n# Air temperature\nfeature_name = \"air_temperature\"\nfor lag in WEATHER_LAGS:\n    weather_df_train = add_lagged_weather_feature(weather_df_train, feature_name, lag)\n\n# Dew temperature\nfeature_name = \"dew_temperature\"\nfor lag in WEATHER_LAGS:\n    weather_df_train = add_lagged_weather_feature(weather_df_train, feature_name, lag)\n\n# Sea level pressure\nfeature_name = \"sea_level_pressure\"\nfor lag in WEATHER_LAGS:\n    weather_df_train = add_lagged_weather_feature(weather_df_train, feature_name, lag)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Merge",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "def merge_dfs(readings_df: pd.DataFrame, buildings_df: pd.DataFrame, weather_df: pd.DataFrame) -> pd.DataFrame:\n\n    # Merge\n    merged_df = pd.merge(left=readings_df, right=buildings_df, how=\"left\", on=\"building_id\")\n    merged_df = pd.merge(left=merged_df, right=weather_df, how=\"left\", on=[\"site_id\", \"timestamp\"])\n\n    return merged_df",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "train_df = merge_dfs(readings_df_train, buildings_df, weather_df_train)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Feature engineering",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2025-01-08T07:28:05.619410Z",
                    "iopub.execute_input": "2025-01-08T07:28:05.620589Z",
                    "iopub.status.idle": "2025-01-08T07:28:07.073796Z",
                    "shell.execute_reply.started": "2025-01-08T07:28:05.620539Z",
                    "shell.execute_reply": "2025-01-08T07:28:07.072645Z"
                }
            }
        },
        {
            "cell_type": "code",
            "source": "def kbtu_to_kwh(df: pd.DataFrame) -> pd.DataFrame:\n    mask = (df[\"building_id\"] == 0) & (df[\"meter_id\"] == 0)\n    df.loc[mask, \"meter_reading\"] = df.loc[mask, \"meter_reading\"] * 0.2931\n    return df\n\n\ndef add_target_transform(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"log_meter_reading\"] = np.log1p(np.array(df[\"meter_reading\"]))\n    return df\n\n\ndef add_periodic_features(df: pd.DataFrame, feature: str, period: int) -> pd.DataFrame:\n    df[f\"{feature}_sin\"] = np.sin(2 * np.pi * df[feature] / period)\n    df[f\"{feature}_sin\"] = df[f\"{feature}_sin\"].astype(np.float32)\n    \n    df[f\"{feature}_cos\"] = np.cos(2 * np.pi * df[feature] / period).astype(np.float32)\n    df[f\"{feature}_cos\"] = df[f\"{feature}_cos\"].astype(np.float32)\n    \n    return df\n\n\ndef add_temporal_features(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"hour\"] = df[\"timestamp\"].dt.hour.astype(np.uint8)\n    df = add_periodic_features(df, \"hour\", 24)\n\n    df[\"day_of_week\"] = df[\"timestamp\"].dt.weekday.astype(np.uint8)\n    df = add_periodic_features(df, \"day_of_week\", 7)\n\n    df[\"month\"] = df[\"timestamp\"].dt.month.astype(np.uint8)\n    df = add_periodic_features(df, \"month\", 12)\n\n    is_weekend = (df[\"timestamp\"].dt.weekday >= 5)\n    df[\"is_weekend\"] = is_weekend.astype(np.uint8)\n    \n    return df\n\n\ndef add_building_age_feature(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"building_age_years\"] = df[\"timestamp\"].dt.year - df[\"year_built\"]\n    return df\n\n\ndef add_building_area_feature(df: pd.DataFrame) -> pd.DataFrame:\n    df[\"building_area_square_feet\"] = df[\"square_feet\"] * df[\"floor_count\"]\n    return df\n\n\ndef add_building_purpose_id_feature(df: pd.DataFrame, purpose_id_map: dict[str, int]) -> pd.DataFrame:\n    df[\"primary_use_id\"] = df[\"primary_use\"].map(purpose_id_map)\n    return df\n\n\ndef saturation_vapour_pressure(temperature: pd.Series) -> pd.Series:\n    return 6.1094 * np.exp(17.625 * temperature / (temperature + 243.04))\n\n\ndef add_relative_humidity_feature(df: pd.DataFrame) -> pd.DataFrame:\n    svp_air_temp = saturation_vapour_pressure(df[\"air_temperature\"])\n    svp_dew_temp = saturation_vapour_pressure(df[\"dew_temperature\"])\n    rh = 100 * svp_dew_temp / svp_air_temp\n    df[\"relative_humidity\"] = rh.astype(np.float32)\n    return df\n\n\ndef add_cold_chill_feature(df: pd.DataFrame) -> pd.DataFrame:\n    # Cold chill only defined for temps below 10C and wind speeds above 1.3 m/s\n    mask = (df[\"air_temperature\"] <= 10.0) & (df[\"wind_speed\"] >= 1.3)\n    air_temp = df.loc[mask, \"air_temperature\"]\n    wind_speed = df.loc[mask, \"wind_speed\"]\n    cold_chill = (\n        13.12 \n        +  0.6215 * air_temp\n        - 11.37 * (3.6 * wind_speed) ** 0.16\n        + 0.3965 * air_temp * (3.6 * wind_speed) ** 0.16\n    )\n    df.loc[mask, \"cold_chill\"] = cold_chill.astype(np.float32)\n    return df\n\n\ndef add_apparent_temperature_feature(df: pd.DataFrame) -> pd.DataFrame:\n    mask = df[\"air_temperature\"].between(10, 27, inclusive=\"both\")\n    air_temp = df.loc[mask, \"air_temperature\"]\n    wind_speed = df.loc[mask, \"wind_speed\"]\n    humidity = df.loc[mask, \"relative_humidity\"] / 100\n    pressure = humidity * 6.105 * np.exp((17.27 * air_temp) / (air_temp + 237.7))\n    apparent_temp = air_temp + 0.33 * pressure - 0.7 * wind_speed - 4\n    df.loc[mask, \"apparent_temperature\"] = apparent_temp.astype(np.float32)\n    return df\n\n\ndef add_heat_index_feature(df: pd.DataFrame) -> pd.DataFrame:\n    mask = df[\"air_temperature\"] >= 27\n    air_temp = df.loc[mask, \"air_temperature\"]\n    humidity = df.loc[mask, \"relative_humidity\"]\n    heat_index = (\n        - 8.7847 \n        + 1.6114 * air_temp \n        + 2.3385 * humidity\n        - 0.1461 * air_temp * humidity\n        - 0.0123 * air_temp ** 2 \n        - 0.0164 * humidity ** 2\n        + 2.212e-03 * air_temp ** 2 * humidity\n        + 7.255e-04 * air_temp * humidity ** 2\n        - 3.582e-06 * air_temp ** 2 * humidity ** 2\n    )\n    df.loc[mask, \"heat_index\"] = heat_index.astype(np.float32)\n    return df\n\n\ndef cooling_degree_days(df: pd.DataFrame) -> pd.DataFrame:\n    # https://www.investopedia.com/terms/c/colddegreeday.asp\n    ...\n\n\ndef heating_degree_days():\n    ...",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Timestamp features\ntrain_df = add_temporal_features(train_df)\n\n# Meter reading features\ntrain_df = kbtu_to_kwh(train_df)\ntrain_df = add_target_transform(train_df)\n\n# Building features\ntrain_df = add_building_age_feature(train_df)\ntrain_df = add_building_area_feature(train_df)\nprimary_use_id_map = {\n    use: i\n    for i, use in enumerate(train_df[\"primary_use\"].unique().tolist())\n}\ntrain_df = add_building_purpose_id_feature(train_df, primary_use_id_map)\n\n# Weather features\ntrain_df = add_relative_humidity_feature(train_df)\ntrain_df = add_cold_chill_feature(train_df)\ntrain_df = add_apparent_temperature_feature(train_df)\ntrain_df = add_heat_index_feature(train_df)\ntrain_df = add_periodic_features(train_df, \"wind_direction\", 360)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "train_df.to_parquet(\"train_df.parquet\")",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "## Test data",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Meter readings\nreadings_df_test = pd.read_csv(\n    f\"{INPUT_DATA_PATH}/test.csv\",\n    header=0,\n    names=[\"row_id\", \"building_id\", \"meter_id\", \"timestamp\"],\n)\nreadings_df_test = cast_readings_data(readings_df_test)\nreadings_df_test[\"row_id\"] = readings_df_test[\"row_id\"].astype(np.uint32)\n\n# Weather\nweather_df_test = pd.read_csv(f\"{INPUT_DATA_PATH}/weather_test.csv\")\nweather_df_test = cast_weather_data(weather_df_test)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Reindex weather data\nweather_df_test = reindex_weather_data(\n    weather_df=weather_df_test,\n    start_timestamp=MIN_TEST_TIMESTAMP,\n    end_timestamp=MAX_TEST_TIMESTAMP,\n)\n\n# Concat train and test weather data\ntrain_timestamp_cutoff = MIN_TEST_TIMESTAMP - pd.Timedelta(\"1d\")  # More than enough\ntimestamp_mask = weather_df_train[\"timestamp\"] >= train_timestamp_cutoff\nweather_cols = [\"timestamp\", \"site_id\"] + WEATHER_FEATURE_COLUMNS\nweather_df_test = pd.concat(\n    [\n        weather_df_test,\n        weather_df_train[timestamp_mask][weather_cols]\n        \n    ],\n    axis=0,\n    ignore_index=True\n)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Compute lagged / rolling weather features\nWEATHER_LAGS = [1, 2]\n\n# Air temperature\nfeature_name = \"air_temperature\"\nfor lag in WEATHER_LAGS:\n    weather_df_test = add_lagged_weather_feature(weather_df_test, feature_name, lag)\n\n# Dew temperature\nfeature_name = \"dew_temperature\"\nfor lag in WEATHER_LAGS:\n    weather_df_test = add_lagged_weather_feature(weather_df_test, feature_name, lag)\n\n# Sea level pressure\nfeature_name = \"sea_level_pressure\"\nfor lag in WEATHER_LAGS:\n    weather_df_test = add_lagged_weather_feature(weather_df_test, feature_name, lag)\n\n\nweather_df_test = weather_df_test.sort_values([\"site_id\", \"timestamp\"]).reset_index(drop=True)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "# Merge all dfs\ntest_df = merge_dfs(readings_df_test, buildings_df, weather_df_test)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": "### Feature engineering",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "# Timestamp features\ntest_df = add_temporal_features(test_df)\n\n# Building features\ntest_df = add_building_age_feature(test_df)\ntest_df = add_building_area_feature(test_df)\ntest_df = add_building_purpose_id_feature(test_df, primary_use_id_map)\n\n# Weather features\ntest_df = add_relative_humidity_feature(test_df)\ntest_df = add_cold_chill_feature(test_df)\ntest_df = add_apparent_temperature_feature(test_df)\ntest_df = add_heat_index_feature(test_df)\ntest_df = add_periodic_features(test_df, \"wind_direction\", 360)",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": "test_df.to_parquet(\"test_df.parquet\")",
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}