{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "f779bcfe",
            "metadata": {
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "execution": {
                    "iopub.execute_input": "2024-10-19T17:05:31.493157Z",
                    "iopub.status.busy": "2024-10-19T17:05:31.492705Z",
                    "iopub.status.idle": "2024-10-19T17:05:35.054444Z",
                    "shell.execute_reply": "2024-10-19T17:05:35.053247Z"
                },
                "papermill": {
                    "duration": 3.571359,
                    "end_time": "2024-10-19T17:05:35.057201",
                    "exception": false,
                    "start_time": "2024-10-19T17:05:31.485842",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "import json\n",
                "import gc\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import pyarrow.parquet as pq\n",
                "from tqdm import tqdm\n",
                "\n",
                "import lightgbm as lgbm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "ca91c80e",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-10-19T17:05:35.069378Z",
                    "iopub.status.busy": "2024-10-19T17:05:35.068304Z",
                    "iopub.status.idle": "2024-10-19T17:05:35.073534Z",
                    "shell.execute_reply": "2024-10-19T17:05:35.072393Z"
                },
                "papermill": {
                    "duration": 0.013748,
                    "end_time": "2024-10-19T17:05:35.076000",
                    "exception": false,
                    "start_time": "2024-10-19T17:05:35.062252",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "SUBMISSION_RUN = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "c37a56b5",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-10-19T17:05:35.087706Z",
                    "iopub.status.busy": "2024-10-19T17:05:35.086670Z",
                    "iopub.status.idle": "2024-10-19T17:05:35.092604Z",
                    "shell.execute_reply": "2024-10-19T17:05:35.091526Z"
                },
                "papermill": {
                    "duration": 0.014324,
                    "end_time": "2024-10-19T17:05:35.095041",
                    "exception": false,
                    "start_time": "2024-10-19T17:05:35.080717",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Constants\n",
                "\n",
                "# Paths\n",
                "INPUT_BASE_PATH = \"/kaggle/input/\"\n",
                "RAW_DATA_INPUT_PATH = f\"{INPUT_BASE_PATH}/m5-forecasting-accuracy\"\n",
                "PROCESSED_DATA_INPUT_PATH = f\"{INPUT_BASE_PATH}/m5-acc\"\n",
                "OUTPUT_BASE_BATH = \"/kaggle/working\"\n",
                "\n",
                "# Timestamps\n",
                "MAX_TRAIN_TIMESTAMP = 1941\n",
                "START_TEST_TIMESTAMP = 1942\n",
                "START_TEST_WM_YR_WK = 11617"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a9b97b47",
            "metadata": {
                "papermill": {
                    "duration": 0.004406,
                    "end_time": "2024-10-19T17:05:35.104251",
                    "exception": false,
                    "start_time": "2024-10-19T17:05:35.099845",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "# Data Input"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "630b8ece",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-10-19T17:05:35.116377Z",
                    "iopub.status.busy": "2024-10-19T17:05:35.115347Z",
                    "iopub.status.idle": "2024-10-19T17:05:35.120761Z",
                    "shell.execute_reply": "2024-10-19T17:05:35.119453Z"
                },
                "papermill": {
                    "duration": 0.014042,
                    "end_time": "2024-10-19T17:05:35.123290",
                    "exception": false,
                    "start_time": "2024-10-19T17:05:35.109248",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Load raw data\n",
                "\n",
                "# CALENDAR_DATA = pd.read_csv(f\"{RAW_DATA_INPUT_PATH}/calendar.csv\")\n",
                "# SELL_PRICES = pd.read_csv(f\"{RAW_DATA_INPUT_PATH}/sell_prices.csv\")\n",
                "# SALES_TRAIN_EVALUATION = pd.read_csv(f\"{RAW_DATA_INPUT_PATH}/sales_train_evaluation.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "9ace1840",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-10-19T17:05:35.135510Z",
                    "iopub.status.busy": "2024-10-19T17:05:35.134448Z",
                    "iopub.status.idle": "2024-10-19T17:05:35.148068Z",
                    "shell.execute_reply": "2024-10-19T17:05:35.146704Z"
                },
                "papermill": {
                    "duration": 0.022264,
                    "end_time": "2024-10-19T17:05:35.150709",
                    "exception": false,
                    "start_time": "2024-10-19T17:05:35.128445",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def cast_category_types(dataset: pd.DataFrame) -> pd.DataFrame:\n",
                "    item_category_cols = [\"dept_id\", \"cat_id\", \"store_id\", \"state_id\"]\n",
                "    date_category_cols = [\"weekday\", \"month\", \"quarter\", \"year\"]\n",
                "    event_cols = [\n",
                "        \"event_name\", \"event_type\",\n",
                "        \"event_name_lag_-3\", \"event_type_lag_-3\",\n",
                "        \"event_name_lag_-2\", \"event_type_lag_-2\",\n",
                "        \"event_name_lag_-1\", \"event_type_lag_-1\",\n",
                "        \"event_name_lag_1\", \"event_type_lag_1\",\n",
                "        \"event_name_lag_2\", \"event_type_lag_2\",\n",
                "        \"event_name_lag_3\", \"event_type_lag_3\",\n",
                "        \"snap_CA\", \"snap_TX\", \"snap_WI\"\n",
                "    ]\n",
                "    sale_cols = [\"item_on_sale\"]\n",
                "    \n",
                "    all_cat_cols = item_category_cols + date_category_cols + event_cols + sale_cols\n",
                "    for category_col in all_cat_cols:\n",
                "        try:\n",
                "            dataset[category_col] = dataset[category_col].astype(\"category\")\n",
                "        except KeyError:\n",
                "            # print(f\"Column {category_col} does not exist. Skipping ...\")\n",
                "            pass\n",
                "    \n",
                "    return dataset\n",
                "\n",
                "\n",
                "def cast_int_types(dataset: pd.DataFrame) -> pd.DataFrame:\n",
                "    int_cols = [\"d\", \"count\"]\n",
                "    for int_col in int_cols:\n",
                "        try:\n",
                "            dataset[int_col] = dataset[int_col].astype(np.int16)\n",
                "        except KeyError:\n",
                "            # print(f\"Column {int_col} does not exist. Skipping ...\")\n",
                "            pass\n",
                "    \n",
                "    return dataset\n",
                "\n",
                "\n",
                "def cast_float_types(dataset: pd.DataFrame) -> pd.DataFrame:\n",
                "    item_id_cols = [\"item_id\"]\n",
                "    float_sales_cols = [\n",
                "        \"count_lag_28\", \"count_lag_29\", \"count_lag_30\", \"count_lag_31\",\n",
                "        \"count_lag_28_rolling_mean_window_7\", \"count_lag_28_rolling_std_window_7\", \"count_lag_28_rolling_kurt_window_7\",\n",
                "        \"count_lag_28_rolling_mean_window_14\", \"count_lag_28_rolling_std_window_14\", \"count_lag_28_rolling_kurt_window_14\",\n",
                "        \"count_lag_28_rolling_mean_window_21\", \"count_lag_28_rolling_std_window_21\", \"count_lag_28_rolling_kurt_window_21\",\n",
                "        \"count_lag_28_rolling_mean_window_28\", \"count_lag_28_rolling_std_window_28\", \"count_lag_28_rolling_kurt_window_28\",\n",
                "    ]\n",
                "    float_price_cols = [\n",
                "        \"sell_price\",\n",
                "        \"sell_price_diff_1\", \"sell_price_diff_2\", \"sell_price_diff_3\", \"sell_price_diff_7\",\n",
                "        \"sell_price_rolling_mean_window_7\", \"sell_price_rolling_std_window_7\", \"sell_price_rolling_kurt_window_7\",\n",
                "        \"sell_price_rolling_mean_window_14\", \"sell_price_rolling_std_window_14\", \"sell_price_rolling_kurt_window_14\",\n",
                "        \"sell_price_rolling_mean_window_21\", \"sell_price_rolling_std_window_21\", \"sell_price_rolling_kurt_window_21\",\n",
                "        \"sell_price_rolling_mean_window_28\", \"sell_price_rolling_std_window_28\", \"sell_price_rolling_kurt_window_28\",\n",
                "    ]\n",
                "    float_date_cols = [\n",
                "        \"weekday_sin\", \"weekday_cos\",\n",
                "        \"month_sin\", \"month_cos\",\n",
                "        \"quarter_sin\", \"quarter_cos\",\n",
                "    ]\n",
                "    float_cols = item_id_cols + float_sales_cols + float_price_cols + float_date_cols\n",
                "    for float_col in float_cols:\n",
                "        try:\n",
                "            dataset[float_col] = dataset[float_col].astype(np.float16)\n",
                "        except KeyError:\n",
                "            # print(f\"Column {int_col} does not exist. Skipping ...\")\n",
                "            pass\n",
                "    \n",
                "    return dataset\n",
                "\n",
                "# Cast to lower resolution types to save memory\n",
                "def cast_data_types(dataset: pd.DataFrame) -> pd.DataFrame:\n",
                "    dataset = cast_category_types(dataset)\n",
                "    dataset = cast_int_types(dataset)\n",
                "    dataset = cast_float_types(dataset)\n",
                "    return dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "76af1df5",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-10-19T17:05:35.162232Z",
                    "iopub.status.busy": "2024-10-19T17:05:35.161861Z",
                    "iopub.status.idle": "2024-10-19T17:05:35.169860Z",
                    "shell.execute_reply": "2024-10-19T17:05:35.168428Z"
                },
                "papermill": {
                    "duration": 0.016484,
                    "end_time": "2024-10-19T17:05:35.172253",
                    "exception": false,
                    "start_time": "2024-10-19T17:05:35.155769",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def drop_cols(dataset: pd.DataFrame) -> pd.DataFrame:\n",
                "    date_cols_to_drop = [\"date\", \"weekday\", \"month\", \"quarter\"]\n",
                "    event_cols_to_drop = [\n",
                "        \"event_type\",\n",
                "        \"event_type_lag_-3\", \"event_type_lag_-2\", \"event_type_lag_-1\",\n",
                "        \"event_type_lag_3\", \"event_type_lag_2\", \"event_type_lag_1\", \n",
                "    ]\n",
                "    sell_cols_to_drop = [\n",
                "        \"sell_price_rolling_mean_window_7\", \"sell_price_rolling_std_window_7\", \"sell_price_rolling_kurt_window_7\",\n",
                "        \"sell_price_rolling_mean_window_14\", \"sell_price_rolling_std_window_14\", \"sell_price_rolling_kurt_window_14\",\n",
                "        \"sell_price_rolling_mean_window_21\", \"sell_price_rolling_std_window_21\", \"sell_price_rolling_kurt_window_21\",\n",
                "        \"sell_price_rolling_mean_window_28\", \"sell_price_rolling_std_window_28\", \"sell_price_rolling_kurt_window_28\",\n",
                "    ]\n",
                "    count_cols_to_drop = [\n",
                "#         \"count_lag_28_rolling_mean_window_7\", \"count_lag_28_rolling_std_window_7\", \"count_lag_28_rolling_kurt_window_7\",\n",
                "#         \"count_lag_28_rolling_mean_window_14\", \"count_lag_28_rolling_std_window_14\", \"count_lag_28_rolling_kurt_window_14\",\n",
                "        \"count_lag_28_rolling_mean_window_21\", \"count_lag_28_rolling_std_window_21\", \"count_lag_28_rolling_kurt_window_21\",\n",
                "        \"count_lag_28_rolling_mean_window_28\", \"count_lag_28_rolling_std_window_28\", \"count_lag_28_rolling_kurt_window_28\",\n",
                "\n",
                "    ]\n",
                "\n",
                "    for column_set in (date_cols_to_drop, event_cols_to_drop, sell_cols_to_drop, count_cols_to_drop):\n",
                "        try:\n",
                "            dataset = dataset.drop(columns=column_set)\n",
                "        except KeyError:\n",
                "            # print(f\"Column '{col}' not found in axis. Skipping ...\")\n",
                "            pass\n",
                "\n",
                "        _ = gc.collect()\n",
                "    return dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "07b639cd",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-10-19T17:05:35.183420Z",
                    "iopub.status.busy": "2024-10-19T17:05:35.183003Z",
                    "iopub.status.idle": "2024-10-19T17:16:55.496663Z",
                    "shell.execute_reply": "2024-10-19T17:16:55.495437Z"
                },
                "papermill": {
                    "duration": 680.322142,
                    "end_time": "2024-10-19T17:16:55.499246",
                    "exception": false,
                    "start_time": "2024-10-19T17:05:35.177104",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Load train data in chunks\n",
                "train_pq_file = pq.ParquetFile(f\"{PROCESSED_DATA_INPUT_PATH}/m5-acc-train.parquet\")\n",
                "\n",
                "train_data_set = pd.DataFrame()\n",
                "for batch in tqdm(train_pq_file.iter_batches(batch_size=131_072)):\n",
                "    train_batch_df = batch.to_pandas()\n",
                "    train_batch_df = drop_cols(train_batch_df)\n",
                "    train_batch_df = cast_data_types(train_batch_df)\n",
                "    \n",
                "    train_data_set = pd.concat([train_data_set, train_batch_df], ignore_index=True)\n",
                "    \n",
                "    del train_batch_df\n",
                "    _ = gc.collect()\n",
                "\n",
                "train_data_set = cast_data_types(train_data_set)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "39e07c84",
            "metadata": {
                "papermill": {
                    "duration": 0.033602,
                    "end_time": "2024-10-19T17:16:55.565607",
                    "exception": false,
                    "start_time": "2024-10-19T17:16:55.532005",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "# LightGBM Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "58baebc1",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-10-19T17:16:55.633728Z",
                    "iopub.status.busy": "2024-10-19T17:16:55.633295Z",
                    "iopub.status.idle": "2024-10-19T17:16:55.644566Z",
                    "shell.execute_reply": "2024-10-19T17:16:55.643444Z"
                },
                "papermill": {
                    "duration": 0.048099,
                    "end_time": "2024-10-19T17:16:55.646778",
                    "exception": false,
                    "start_time": "2024-10-19T17:16:55.598679",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "# Rolling window validation\n",
                "\n",
                "def time_series_split(\n",
                "    df: pd.DataFrame,\n",
                "    n_folds: int = 5,\n",
                "    horizon: int = 28,\n",
                "    overlap: int = 0,\n",
                "    max_timestamp: int = MAX_TRAIN_TIMESTAMP,\n",
                "):\n",
                "    min_timestamp = max_timestamp - n_folds * horizon + (n_folds - 1) * overlap\n",
                "    for fold_idx in range(n_folds):\n",
                "        start = min_timestamp + fold_idx * (horizon - overlap)\n",
                "        stop = start + horizon\n",
                "\n",
                "        train_data = df[df[\"d\"] < start]\n",
                "        valid_data = df[(df[\"d\"] >= start) & (df[\"d\"] < stop)]\n",
                "        \n",
                "        print(f\"Fold index: {fold_idx}\")\n",
                "        print(f\"Train idx (start, end): ({train_data['d'].min()}, {train_data['d'].max()})\")\n",
                "        print(f\"Valid idx (start, end): ({valid_data['d'].min()}, {valid_data['d'].max()})\")\n",
                "        print(\"==================\")\n",
                "        \n",
                "        yield train_data, valid_data\n",
                "        \n",
                "        \n",
                "def train_predict_score(\n",
                "    X_train: pd.DataFrame,\n",
                "    y_train: pd.Series,\n",
                "    X_test: pd.DataFrame,\n",
                "    y_test: pd.Series,\n",
                "    train_parameters: dict,\n",
                "    dataset_parameters: dict | None = None,\n",
                ") -> tuple[float, float]:\n",
                "    dataset_parameters = dataset_parameters or {}\n",
                "    train_data = lgbm.Dataset(data=X_train, label=y_train, **dataset_parameters)\n",
                "    valid_data = lgbm.Dataset(data=X_test, label=y_test, **dataset_parameters)\n",
                "    model = lgbm.train(\n",
                "        train_parameters,\n",
                "        num_boost_round=3000,\n",
                "        train_set=train_data,\n",
                "        valid_sets=[train_data, valid_data],\n",
                "        callbacks=[\n",
                "            lgbm.early_stopping(stopping_rounds=5),\n",
                "            lgbm.log_evaluation(period=10),\n",
                "        ]\n",
                "    )\n",
                "    \n",
                "    y_hat = model.predict(X_test)\n",
                "    y_hat = np.clip(y_hat, a_min=0, a_max=np.inf)\n",
                "    rmse = np.sqrt(np.mean((y_test - y_hat) ** 2))\n",
                "\n",
                "    return rmse, model.best_iteration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "04790cd3",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-10-19T17:16:55.782419Z",
                    "iopub.status.busy": "2024-10-19T17:16:55.781584Z",
                    "iopub.status.idle": "2024-10-19T17:16:55.790049Z",
                    "shell.execute_reply": "2024-10-19T17:16:55.788942Z"
                },
                "papermill": {
                    "duration": 0.112858,
                    "end_time": "2024-10-19T17:16:55.792533",
                    "exception": false,
                    "start_time": "2024-10-19T17:16:55.679675",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "CATEGORICAL_FEATURES = [\n",
                "    \"dept_id\",\n",
                "    \"cat_id\",\n",
                "    \"store_id\",\n",
                "    \"state_id\",\n",
                "    \"year\",\n",
                "    \"event_name\",\n",
                "#     \"event_name_lag_-3\",\n",
                "    \"event_name_lag_-2\",\n",
                "    \"event_name_lag_-1\",\n",
                "    \"event_name_lag_1\",\n",
                "    \"event_name_lag_2\",\n",
                "#     \"event_name_lag_3\",\n",
                "    \"snap_CA\",\n",
                "    \"snap_TX\",\n",
                "    \"snap_WI\",\n",
                "    \"item_on_sale\",\n",
                "]\n",
                "CONTINOUS_FEATURES = [\n",
                "    \"item_id\",\n",
                "    \"weekday_sin\",\n",
                "    \"weekday_cos\",\n",
                "    \"month_sin\",\n",
                "    \"month_cos\",\n",
                "    \"quarter_sin\",\n",
                "    \"quarter_cos\",\n",
                "    \"sell_price\",\n",
                "    \"sell_price_diff_1\",\n",
                "    \"sell_price_diff_2\",\n",
                "    \"sell_price_diff_3\",\n",
                "    \"sell_price_diff_7\",\n",
                "    \"count_lag_28\",\n",
                "    \"count_lag_29\",\n",
                "    \"count_lag_30\",\n",
                "    \"count_lag_31\",\n",
                "    \"count_lag_28_rolling_mean_window_7\", \"count_lag_28_rolling_std_window_7\", \"count_lag_28_rolling_kurt_window_7\",\n",
                "    \"count_lag_28_rolling_mean_window_14\", \"count_lag_28_rolling_std_window_14\", \"count_lag_28_rolling_kurt_window_14\",\n",
                "#     \"count_lag_28_rolling_mean_window_21\", \"count_lag_28_rolling_std_window_21\", \"count_lag_28_rolling_kurt_window_21\",\n",
                "#     \"count_lag_28_rolling_mean_window_28\", \"count_lag_28_rolling_std_window_28\", \"count_lag_28_rolling_kurt_window_28\",\n",
                "]\n",
                "FEATURES = CATEGORICAL_FEATURES + CONTINOUS_FEATURES\n",
                "LABEL = \"count\"\n",
                "\n",
                "# Parameters\n",
                "DATASET_PARAMETERS = {}\n",
                "TRAIN_PARAMETERS = {\n",
                "    \"objective\": \"tweedie\",\n",
                "    'tweedie_variance_power': 1.1,\n",
                "    \"learning_rate\": 0.025,\n",
                "    \"num_leaves\": 2 ** 7 - 1,\n",
                "    \"max_bin\": 2 ** 7 - 1,\n",
                "    \"bagging_freq\": 1,\n",
                "    \"bagging_fraction\": 0.8,\n",
                "    \"feature_fraction\": 0.8, \n",
                "    \"metric\": \"rmse\",\n",
                "    \"force_col_wise\": True,\n",
                "    \"seed\": 1,\n",
                "    \"histogram_pool_size\": 11000,\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "30a0165b",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-10-19T17:16:55.860722Z",
                    "iopub.status.busy": "2024-10-19T17:16:55.860333Z",
                    "iopub.status.idle": "2024-10-19T18:26:46.487898Z",
                    "shell.execute_reply": "2024-10-19T18:26:46.484943Z"
                },
                "papermill": {
                    "duration": 4190.66474,
                    "end_time": "2024-10-19T18:26:46.490824",
                    "exception": false,
                    "start_time": "2024-10-19T17:16:55.826084",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "if not SUBMISSION_RUN:\n",
                "    scores = []\n",
                "    best_iterations = []\n",
                "    \n",
                "    for train, valid in tqdm(time_series_split(train_data_set, n_folds=5), total=5):\n",
                "    \n",
                "        X_train, y_train = train[FEATURES], train[LABEL]\n",
                "        X_test, y_test = valid[FEATURES], valid[LABEL]\n",
                "        score, best_iter = train_predict_score(\n",
                "            X_train=X_train,\n",
                "            y_train=y_train,\n",
                "            X_test=X_test,\n",
                "            y_test=y_test,\n",
                "            train_parameters=TRAIN_PARAMETERS,\n",
                "            dataset_parameters=DATASET_PARAMETERS,\n",
                "        )\n",
                "        scores.append(score)\n",
                "        best_iterations.append(best_iter)\n",
                "    \n",
                "    cv_results = {\n",
                "        \"scores\": scores,\n",
                "        \"mean_score\": np.mean(scores),\n",
                "        \"std_score\": np.std(scores),\n",
                "        \"best_iterations\": best_iterations,\n",
                "        \"mean_best_iteration\": np.mean(best_iterations)\n",
                "    }\n",
                "    \n",
                "    with open(f\"{OUTPUT_BASE_BATH}/cv_results.json\", \"w\") as f:\n",
                "        json.dump(cv_results, f)\n",
                "    \n",
                "else:\n",
                "    X_train, y_train = train_data_set[FEATURES], train_data_set[LABEL]\n",
                "    train_data = lgbm.Dataset(data=X_train, label=y_train, **DATASET_PARAMETERS)\n",
                "    model = lgbm.train(\n",
                "        TRAIN_PARAMETERS,\n",
                "        num_boost_round=550,\n",
                "        train_set=train_data,\n",
                "        valid_sets=[train_data],\n",
                "        callbacks=[lgbm.log_evaluation(period=10)]\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f1c4eb1d",
            "metadata": {
                "papermill": {
                    "duration": 0.036658,
                    "end_time": "2024-10-19T18:26:46.564444",
                    "exception": false,
                    "start_time": "2024-10-19T18:26:46.527786",
                    "status": "completed"
                },
                "tags": []
            },
            "source": [
                "# Forecast & Submit"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "19e13b01",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-10-19T18:26:46.642365Z",
                    "iopub.status.busy": "2024-10-19T18:26:46.641734Z",
                    "iopub.status.idle": "2024-10-19T18:26:46.656435Z",
                    "shell.execute_reply": "2024-10-19T18:26:46.655105Z"
                },
                "papermill": {
                    "duration": 0.058188,
                    "end_time": "2024-10-19T18:26:46.659057",
                    "exception": false,
                    "start_time": "2024-10-19T18:26:46.600869",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "def pivot_test_df(test_data_set: pd.DataFrame) -> pd.DataFrame:\n",
                "    test_data_set = test_data_set.pivot(columns=\"d\", index=\"id\", values=\"count\").sort_index(axis=1)\n",
                "    test_data_set = test_data_set.rename_axis(None, axis=1).reset_index()\n",
                "    return test_data_set\n",
                "\n",
                "def rename_forecast_columns(forecast_df: pd.DataFrame, forecast_horizon: int = 28) -> pd.DataFrame:\n",
                "    forecast_df = forecast_df.set_index(\"id\")\n",
                "    forecast_df.columns = [f\"F{i}\" for i in range(1, forecast_horizon + 1)]\n",
                "    return forecast_df.reset_index()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "006ce531",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-10-19T18:26:46.734108Z",
                    "iopub.status.busy": "2024-10-19T18:26:46.733682Z",
                    "iopub.status.idle": "2024-10-19T18:27:26.002902Z",
                    "shell.execute_reply": "2024-10-19T18:27:26.001656Z"
                },
                "papermill": {
                    "duration": 39.310221,
                    "end_time": "2024-10-19T18:27:26.005625",
                    "exception": false,
                    "start_time": "2024-10-19T18:26:46.695404",
                    "status": "completed"
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "if SUBMISSION_RUN:\n",
                "    SAMPLE_SUBMISSION = pd.read_csv(f\"{RAW_DATA_INPUT_PATH}/sample_submission.csv\")\n",
                "    SUBMISSION_INDEX = SAMPLE_SUBMISSION.set_index(\"id\").index\n",
                "    VAL_SUBMISSION = SAMPLE_SUBMISSION[SAMPLE_SUBMISSION[\"id\"].str.contains(\"validation\")]\n",
                "    EVAL_SUBMISSION = SAMPLE_SUBMISSION[SAMPLE_SUBMISSION[\"id\"].str.contains(\"evaluation\")]\n",
                "    \n",
                "    test_data_set = pd.read_parquet(f\"{PROCESSED_DATA_INPUT_PATH}/m5-acc-test.parquet\")\n",
                "    test_data_set = drop_cols(test_data_set)\n",
                "    test_data_set = cast_data_types(test_data_set)\n",
                "\n",
                "    y_hat = model.predict(test_data_set[FEATURES])\n",
                "    y_hat = np.clip(y_hat, a_min=0, a_max=np.inf)\n",
                "    test_data_set[\"count\"] = y_hat\n",
                "    \n",
                "    test_data_set = pivot_test_df(test_data_set)\n",
                "    test_data_set = rename_forecast_columns(test_data_set)\n",
                "    \n",
                "    # Merge with sample submissions\n",
                "    EVAL_SUBMISSION = EVAL_SUBMISSION[[\"id\"]].merge(test_data_set, on=\"id\", how=\"left\")\n",
                "    FINAL_SUBMISSIONS = pd.concat([VAL_SUBMISSION, EVAL_SUBMISSION])\n",
                "    FINAL_SUBMISSIONS = FINAL_SUBMISSIONS.set_index(\"id\").reindex(SUBMISSION_INDEX).reset_index()\n",
                "    \n",
                "    FINAL_SUBMISSIONS.to_csv(f\"{OUTPUT_BASE_BATH}/submission.csv\", index=False)"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "databundleVersionId": 1236839,
                    "sourceId": 18599,
                    "sourceType": "competition"
                },
                {
                    "databundleVersionId": 9898063,
                    "datasetId": 5684895,
                    "sourceId": 9669001,
                    "sourceType": "datasetVersion"
                }
            ],
            "dockerImageVersionId": 30746,
            "isGpuEnabled": false,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        },
        "papermill": {
            "default_parameters": {},
            "duration": 4921.06349,
            "end_time": "2024-10-19T18:27:29.093330",
            "environment_variables": {},
            "exception": null,
            "input_path": "__notebook__.ipynb",
            "output_path": "__notebook__.ipynb",
            "parameters": {},
            "start_time": "2024-10-19T17:05:28.029840",
            "version": "2.5.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
