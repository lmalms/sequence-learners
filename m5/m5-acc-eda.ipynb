{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from matplotlib.pyplot import cm\n",
                "import seaborn as sns\n",
                "from tqdm import tqdm\n",
                "\n",
                "import lightgbm as lgbm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "INPUT_BASE_PATH = \"/kaggle/input/m5-forecasting-accuracy\"\n",
                "OUTPUT_BASE_BATH = \"/kaggle/working\"\n",
                "\n",
                "CALENDAR_DATA = pd.read_csv(f\"{INPUT_BASE_PATH}/calendar.csv\")\n",
                "SELL_PRICES = pd.read_csv(f\"{INPUT_BASE_PATH}/sell_prices.csv\")\n",
                "SALES_TRAIN_EVALUATION = pd.read_csv(f\"{INPUT_BASE_PATH}/sales_train_evaluation.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# Extract categorical mappings\n",
                "def get_unique_value_id_map(df: pd.DataFrame, col_name: str):\n",
                "    return {value_id: i for (i, value_id) in enumerate(df[col_name].unique())}\n",
                "\n",
                "\n",
                "def map_category_ids(sales_df: pd.DataFrame, column_name: str, submission_run: bool):\n",
                "    category_id_map = get_unique_value_id_map(sales_df, column_name)\n",
                "    id_category_map = {v: k for (k, v) in category_id_map.items()}\n",
                "    sales_df[column_name] = sales_df[column_name].map(category_id_map)\n",
                "    return (category_id_map, None) if submission_run else (category_id_map, id_category_map)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# Process sales data\n",
                "def unpivot_sales_df(sales_df: pd.DataFrame, timestamp_cols: list[str]) -> pd.DataFrame:\n",
                "    sales_df = sales_df.melt(\n",
                "        id_vars=[\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n",
                "        value_vars=timestamp_cols,\n",
                "        var_name=\"d\",\n",
                "        value_name=\"count\"\n",
                "    )\n",
                "    sales_df[\"d\"] = sales_df[\"d\"].apply(lambda d: int(d.lstrip(\"d_\")))\n",
                "    return sales_df\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# Process calendar data\n",
                "def select_format_calendar_features(calendar_data: pd.DataFrame) -> pd.DataFrame:\n",
                "    # Drop columns\n",
                "    cols_to_drop = [\"weekday\", \"event_name_2\", \"event_type_2\"]\n",
                "    calendar_data = calendar_data.copy().drop(columns=cols_to_drop)\n",
                "    \n",
                "    # Format cols\n",
                "    calendar_data[\"d\"] = calendar_data[\"d\"].apply(lambda d: int(d.lstrip(\"d_\")))\n",
                "    calendar_data = calendar_data.rename(columns={\n",
                "        \"event_name_1\": \"event_name\",\n",
                "        \"event_type_1\": \"event_type\",\n",
                "        \"wday\": \"weekday\"\n",
                "    })\n",
                "    \n",
                "    return calendar_data\n",
                "\n",
                "\n",
                "# Merge\n",
                "def merge_sales_and_calendar_data(sales_df: pd.DataFrame, calendar_data: pd.DataFrame) -> pd.DataFrame:\n",
                "    return sales_df.merge(right=calendar_data, on=\"d\", how=\"left\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "start_t, end_t = 1000, 1941\n",
                "timestamp_cols = [f\"d_{i}\" for i in range(start_t, end_t + 1)]\n",
                "\n",
                "# Process sales data\n",
                "sales_df = unpivot_sales_df(SALES_TRAIN_EVALUATION, timestamp_cols)\n",
                "\n",
                "# Process calendar data\n",
                "calendar_df = select_format_calendar_features(CALENDAR_DATA)\n",
                "\n",
                "# Merge\n",
                "data = merge_sales_and_calendar_data(sales_df, calendar_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-07-22T20:37:25.946145Z",
                    "iopub.status.busy": "2024-07-22T20:37:25.945738Z",
                    "iopub.status.idle": "2024-07-22T20:37:25.986313Z",
                    "shell.execute_reply": "2024-07-22T20:37:25.985112Z",
                    "shell.execute_reply.started": "2024-07-22T20:37:25.946112Z"
                }
            },
            "source": [
                "# SALES BY STORE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# Aggregate sales by store\n",
                "sales_by_store = data.groupby([\"store_id\", \"date\"])[[\"count\"]].sum()\n",
                "store_ids = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
                "n_samples = 500\n",
                "\n",
                "fig, ax = plt.subplots(5, 2, sharex=True, sharey=True, figsize=(15, 10))\n",
                "ax = ax.flatten()\n",
                "for i, store_id in enumerate(store_ids):\n",
                "    store_df = sales_by_store.loc[(store_id, slice(None))].copy().reset_index()\n",
                "    store_df = store_df.iloc[-n_samples:]\n",
                "    ax[i].plot(np.arange(n_samples), store_df[\"count\"].values, label=store_id)\n",
                "    \n",
                "    date_labels = store_df[\"date\"].values[::100]\n",
                "    x_ticks = np.arange(0, n_samples, 100)\n",
                "    ax[i].set_xticks(x_ticks)\n",
                "    ax[i].set_xticklabels(date_labels, rotation=45)\n",
                "    if i % 2 == 0: ax[i].set_ylabel(\"count\")\n",
                "    ax[i].legend()\n",
                "\n",
                "fig.tight_layout();"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# Compare daily seasonalities across stores\n",
                "total_sales_by_store = data.groupby([\"date\", \"weekday\", \"store_id\"])[[\"count\"]].sum()\n",
                "av_weekday_sales = (\n",
                "    total_sales_by_store\n",
                "    .groupby([\"weekday\", \"store_id\"])\n",
                "    [[\"count\"]]\n",
                "    .mean()\n",
                "    .unstack(level=1)\n",
                "    .droplevel(level=0, axis=1)\n",
                ")\n",
                "std_weekday_sales = (\n",
                "    total_sales_by_store\n",
                "    .groupby([\"weekday\", \"store_id\"])\n",
                "    [[\"count\"]]\n",
                "    .std()\n",
                "    .unstack(level=1)\n",
                "    .droplevel(level=0, axis=1)\n",
                ")\n",
                "\n",
                "\n",
                "store_groups = [\n",
                "    [\"CA_1\", \"CA_2\", \"CA_3\", \"CA_4\"],\n",
                "    [\"TX_1\", \"TX_2\", \"TX_3\"],\n",
                "    [\"WI_1\", \"WI_2\", \"WI_3\"],   \n",
                "]\n",
                "fig, ax = plt.subplots(1, 3, figsize=(15, 3.5),)\n",
                "for i, group in enumerate(store_groups):\n",
                "    for store in group:\n",
                "        ax[i].plot(\n",
                "            av_weekday_sales.index,\n",
                "            av_weekday_sales[store].values,\n",
                "            label=store,\n",
                "        )\n",
                "        ax[i].fill_between(\n",
                "            av_weekday_sales.index,\n",
                "            av_weekday_sales[store].values + std_weekday_sales[store].values,\n",
                "            av_weekday_sales[store].values - std_weekday_sales[store].values,\n",
                "            alpha=0.25,\n",
                "        )\n",
                "    ax[i].set(xlabel=\"weekday\", ylabel=\"count\")\n",
                "    ax[i].legend(ncols=len(group), fontsize=\"small\", loc=1)\n",
                "    \n",
                "fig.tight_layout();"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-07-22T20:39:02.871155Z",
                    "iopub.status.busy": "2024-07-22T20:39:02.870765Z",
                    "iopub.status.idle": "2024-07-22T20:39:02.875995Z",
                    "shell.execute_reply": "2024-07-22T20:39:02.874832Z",
                    "shell.execute_reply.started": "2024-07-22T20:39:02.871125Z"
                }
            },
            "source": [
                "# SALES BY CATEGORY"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "sales_by_category = data.groupby([\"cat_id\", \"date\"])[[\"count\"]].sum()\n",
                "category_ids = [\"FOODS\", \"HOBBIES\", \"HOUSEHOLD\"]\n",
                "\n",
                "n_samples = 500\n",
                "fig, ax = plt.subplots(3, 1, figsize=(8, 6), sharex=True)\n",
                "for i, cat_id in enumerate(category_ids):\n",
                "    cat_df = sales_by_category.loc[(cat_id, slice(None))].copy().reset_index()\n",
                "    cat_df = cat_df.iloc[-n_samples:]\n",
                "    ax[i].plot(np.arange(n_samples), cat_df[\"count\"].values, label=cat_id)\n",
                "    \n",
                "    date_labels = cat_df[\"date\"].values[::100]\n",
                "    x_ticks = np.arange(0, n_samples, 100)\n",
                "    ax[i].set_xticks(x_ticks)\n",
                "    ax[i].set_xticklabels(date_labels, rotation=45)\n",
                "\n",
                "    ax[i].legend()\n",
                "fig.tight_layout();"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SALES BY CATEGORY & STORE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "sales_by_store_and_cat = data.groupby([\"store_id\", \"cat_id\", \"date\"])[[\"count\"]].sum()\n",
                "store_ids = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
                "category_ids = [\"FOODS\", \"HOBBIES\", \"HOUSEHOLD\"]\n",
                "n_samples = 500\n",
                "\n",
                "fig, ax = plt.subplots(5, 2, sharex=True, sharey=True, figsize=(15, 10))\n",
                "ax = ax.flatten()\n",
                "for i, store_id in enumerate(store_ids):\n",
                "    store_df = sales_by_store_and_cat.loc[store_id]\n",
                "    for cat_id in [\"FOODS\", \"HOBBIES\", \"HOUSEHOLD\"]:\n",
                "        cat_df = store_df.loc[cat_id].reset_index()\n",
                "        cat_df = cat_df.iloc[-n_samples:]\n",
                "        ax[i].plot(np.arange(n_samples), cat_df[\"count\"].values, label=(store_id, cat_id))\n",
                "\n",
                "    ax[i].legend(fontsize=\"small\", ncols=3)\n",
                "    \n",
                "    date_labels = cat_df[\"date\"].values[::100]\n",
                "    x_ticks = np.arange(0, n_samples, 100)\n",
                "    ax[i].set_xticks(x_ticks)\n",
                "    ax[i].set_xticklabels(date_labels, rotation=45)\n",
                "\n",
                "fig.tight_layout();"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SALES BY STORE & DEPARTMENT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "sales_by_store_and_dept = data.groupby([\"store_id\", \"dept_id\", \"date\"])[[\"count\"]].sum()\n",
                "store_ids = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n",
                "\n",
                "n_samples = 500\n",
                "\n",
                "fig, ax = plt.subplots(5, 2, sharex=True, sharey=True, figsize=(15, 10))\n",
                "ax = ax.flatten()\n",
                "for i, store_id in enumerate(store_ids):\n",
                "    store_df = sales_by_store_and_dept.loc[store_id]\n",
                "    store_df = store_df.unstack(level=0).droplevel(level=0, axis=1)\n",
                "    store_df = store_df.iloc[-n_samples:]\n",
                "    ax[i] = store_df.plot(ax=ax[i])\n",
                "    \n",
                "    ax[i].legend(fontsize=\"x-small\", ncols=4)\n",
                "    ax[i].set_title(store_id)\n",
                "\n",
                "fig.tight_layout();"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SALES BY ITEM ID & STORE"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "dept_ids = list(data[\"dept_id\"].unique())\n",
                "store_ids = list(data[\"store_id\"].unique())\n",
                "item_ids_by_dept = {}\n",
                "for dept_id in dept_ids:\n",
                "    item_ids = list(data[data[\"dept_id\"] == dept_id][\"item_id\"].unique())\n",
                "    item_ids_by_dept[dept_id] = item_ids"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# Plot sales for different items\n",
                "n_items = 10\n",
                "fig, ax = plt.subplots(len(dept_ids), n_items, figsize=(len(dept_ids) * 3.5, n_items * 1.5), sharey=True)\n",
                "for d, dept_id in enumerate(dept_ids):\n",
                "    print(f\"Plotting count distributions for {dept_id}\")\n",
                "    for i in tqdm(range(5)):\n",
                "        item_ids = np.random.choice(item_ids_by_dept[dept_id], size=n_items)\n",
                "        for i, item_id in enumerate(item_ids):\n",
                "            df_slice = data[(data[\"item_id\"] == item_id)]\n",
                "            counts, bins = np.histogram(df_slice[\"count\"].values, bins=max(df_slice[\"count\"].values))\n",
                "            ax[d, i].stairs(\n",
                "                counts / len(df_slice[\"count\"].values),\n",
                "                bins,\n",
                "                label=item_id\n",
                "            )\n",
                "    \n",
                "    for i in range(n_items):\n",
                "        ax[d, i].legend(fontsize='x-small')\n",
                "        ax[d, i].set(xlim=(-1, 20))\n",
                "    \n",
                "    ax[d, 0].set(ylabel=\"density\")\n",
                "\n",
                "for i in range(n_items):\n",
                "    ax[-1, i].set(xlabel=\"count\")\n",
                "        \n",
                "fig.tight_layout();\n",
                "plt.savefig(f\"{OUTPUT_BASE_BATH}/count_dist_for_item_cross_section.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "# Plot sales for items by store\n",
                "n_items = 10\n",
                "fig, ax = plt.subplots(len(dept_ids), n_items, figsize=(len(dept_ids) * 3.5, n_items * 1.5), sharey=True)\n",
                "for d, dept_id in enumerate(dept_ids):\n",
                "    print(f\"Plotting count distributions for {dept_id}\")\n",
                "    for s, store_id in tqdm(enumerate(store_ids)):\n",
                "        item_ids = np.random.choice(item_ids_by_dept[dept_id], size=n_items)\n",
                "        for i, item_id in enumerate(item_ids):\n",
                "            df_slice = data[(data[\"store_id\"] == store_id) & (data[\"item_id\"] == item_id)]\n",
                "            counts, bins = np.histogram(df_slice[\"count\"].values, bins=max(df_slice[\"count\"].values))\n",
                "            ax[d, i].stairs(\n",
                "                counts / len(df_slice[\"count\"].values),\n",
                "                bins,\n",
                "                label=store_id\n",
                "            )\n",
                "    \n",
                "    # Set plot properties for all plots of this dept\n",
                "    for i, item_id in enumerate(item_ids):\n",
                "        ax[d, i].set_title(item_id, fontsize='small')\n",
                "        ax[d, i].set_xlim((-1, 20))\n",
                "    \n",
                "    # ylabel for first column plots\n",
                "    ax[d, 0].set(ylabel=\"density\")\n",
                "\n",
                "# xlabels for last row plots\n",
                "for i in range(n_items):\n",
                "    ax[-1, i].set(xlabel=\"count\")\n",
                "\n",
                "handles, labels = ax[0,0].get_legend_handles_labels()\n",
                "fig.legend(handles, labels, loc='upper center', ncols=len(store_ids), bbox_to_anchor=[0.5, 1.02])\n",
                "        \n",
                "fig.tight_layout();\n",
                "plt.savefig(f\"{OUTPUT_BASE_BATH}/count_dist_for_item_cross_section_by_store.png\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(1, len(dept_ids), figsize=(len(dept_ids) * 3.5, 3.5), sharey=True)\n",
                "for d, dept_id in enumerate(dept_ids):\n",
                "    print(f\"Plotting count distributions for {dept_id}\")\n",
                "    for i, item_id in tqdm(enumerate(item_ids_by_dept[dept_id])):\n",
                "        item_id_df = data[(data[\"item_id\"] == item_id)]\n",
                "        counts, bins = np.histogram(\n",
                "            item_id_df[\"count\"].values,\n",
                "            bins=max(item_id_df[\"count\"].values)\n",
                "        )\n",
                "        ax[d].stairs(\n",
                "            counts / len(item_id_df[\"count\"].values),\n",
                "            bins,\n",
                "            label=item_id,\n",
                "            color=\"gray\",\n",
                "            alpha=0.5,\n",
                "            lw=0.3,\n",
                "        )\n",
                "    ax[d].set(title=dept_id, xlabel=\"count\", xlim=(-1, 40))\n",
                "\n",
                "ax[0].set(ylabel=\"density\")\n",
                "\n",
                "fig.tight_layout();\n",
                "plt.savefig(f\"{OUTPUT_BASE_BATH}/count_dist_for_items_by_dept.png\")"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "databundleVersionId": 1236839,
                    "sourceId": 18599,
                    "sourceType": "competition"
                }
            ],
            "dockerImageVersionId": 30746,
            "isGpuEnabled": false,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
