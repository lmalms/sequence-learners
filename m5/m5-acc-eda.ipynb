{
    "metadata": {
        "kernelspec": {
            "language": "python",
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.13",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "sourceId": 18599,
                    "databundleVersionId": 1236839,
                    "sourceType": "competition"
                }
            ],
            "dockerImageVersionId": 30746,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook",
            "isGpuEnabled": false
        }
    },
    "nbformat_minor": 4,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "code",
            "source": "import matplotlib.pyplot as plt\nfrom matplotlib.pyplot import cm\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "INPUT_BASE_PATH = \"/kaggle/input/m5-forecasting-accuracy\"\nOUTPUT_BASE_BATH = \"/kaggle/working\"\n\nCALENDAR_DATA = pd.read_csv(f\"{INPUT_BASE_PATH}/calendar.csv\")\nSELL_PRICES = pd.read_csv(f\"{INPUT_BASE_PATH}/sell_prices.csv\")\nSALES_TRAIN_EVALUATION = pd.read_csv(f\"{INPUT_BASE_PATH}/sales_train_evaluation.csv\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "# Extract categorical mappings\ndef get_unique_value_id_map(df: pd.DataFrame, col_name: str):\n    return {value_id: i for (i, value_id) in enumerate(df[col_name].unique())}\n\n\ndef map_category_ids(sales_df: pd.DataFrame, column_name: str, submission_run: bool):\n    category_id_map = get_unique_value_id_map(sales_df, column_name)\n    id_category_map = {v: k for (k, v) in category_id_map.items()}\n    sales_df[column_name] = sales_df[column_name].map(category_id_map)\n    return (category_id_map, None) if submission_run else (category_id_map, id_category_map)",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "# Process sales data\ndef unpivot_sales_df(sales_df: pd.DataFrame, timestamp_cols: list[str]) -> pd.DataFrame:\n    sales_df = sales_df.melt(\n        id_vars=[\"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n        value_vars=timestamp_cols,\n        var_name=\"d\",\n        value_name=\"count\"\n    )\n    sales_df[\"d\"] = sales_df[\"d\"].apply(lambda d: int(d.lstrip(\"d_\")))\n    return sales_df\n    ",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "# Process calendar data\ndef select_format_calendar_features(calendar_data: pd.DataFrame) -> pd.DataFrame:\n    # Drop columns\n    cols_to_drop = [\"weekday\", \"event_name_2\", \"event_type_2\"]\n    calendar_data = calendar_data.copy().drop(columns=cols_to_drop)\n    \n    # Format cols\n    calendar_data[\"d\"] = calendar_data[\"d\"].apply(lambda d: int(d.lstrip(\"d_\")))\n    calendar_data = calendar_data.rename(columns={\n        \"event_name_1\": \"event_name\",\n        \"event_type_1\": \"event_type\",\n        \"wday\": \"weekday\"\n    })\n    \n    return calendar_data\n\n\n# Merge\ndef merge_sales_and_calendar_data(sales_df: pd.DataFrame, calendar_data: pd.DataFrame) -> pd.DataFrame:\n    return sales_df.merge(right=calendar_data, on=\"d\", how=\"left\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "start_t, end_t = 1000, 1941\ntimestamp_cols = [f\"d_{i}\" for i in range(start_t, end_t + 1)]\n\n# Process sales data\nsales_df = unpivot_sales_df(SALES_TRAIN_EVALUATION, timestamp_cols)\n\n# Process calendar data\ncalendar_df = select_format_calendar_features(CALENDAR_DATA)\n\n# Merge\ndata = merge_sales_and_calendar_data(sales_df, calendar_df)",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": "# SALES BY STORE",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-07-22T20:37:25.945738Z",
                    "iopub.execute_input": "2024-07-22T20:37:25.946145Z",
                    "iopub.status.idle": "2024-07-22T20:37:25.986313Z",
                    "shell.execute_reply.started": "2024-07-22T20:37:25.946112Z",
                    "shell.execute_reply": "2024-07-22T20:37:25.985112Z"
                }
            }
        },
        {
            "cell_type": "code",
            "source": "n_samples = 500\nstore_ids = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\nav_sales_by_store = data.groupby([\"store_id\", \"date\"])[[\"count\"]].mean()\n\nfig, ax = plt.subplots(len(store_ids), 1, sharex=True, sharey=True, figsize=(10, 15))\nax = ax.flatten()\nfor i, store_id in enumerate(store_ids):\n    store_df = data[data[\"store_id\"] == store_id]\n    for item_id, item_df in tqdm(store_df.groupby(\"item_id\")):\n        item_df = item_df.sort_values(by=\"d\")\n        item_df = item_df.iloc[-n_samples:]\n        ax[i].plot(\n            item_df[\"date\"].values,\n            item_df[\"count\"].values,\n            color=\"gray\",\n            lw=0.3,\n            alpha=0.25,\n        )\n    \n    mean_store_sales = av_sales_by_store.loc[store_id].reset_index()\n    mean_store_sales = mean_store_sales.sort_values(by=\"date\")\n    mean_store_sales = mean_store_sales.iloc[-n_samples:]\n    axi_2 = ax[i].twinx()\n    axi_2.plot(\n        mean_store_sales[\"date\"].values,\n        mean_store_sales[\"count\"].values,\n        color=\"blue\",\n        alpha=0.75,\n    )\n    axi_2.set(ylabel=\"mean sales\")\n    \n    date_labels = mean_store_sales[\"date\"].values[::100]\n    x_ticks = np.arange(0, n_samples, 100)\n    ax[i].set(xticks=x_ticks, xticklabels=date_labels)\n    ax[i].set(ylabel=\"count\", title=store_id)\n\nfig.tight_layout();\nplt.savefig(f\"{OUTPUT_BASE_BATH}/item_sales_by_store_timeseries.png\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "# Aggregate sales by store\nsales_by_store = data.groupby([\"store_id\", \"date\"])[[\"count\"]].sum()\nstore_ids = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\nn_samples = 500\n\nfig, ax = plt.subplots(5, 2, sharex=True, sharey=True, figsize=(15, 10))\nax = ax.flatten()\nfor i, store_id in enumerate(store_ids):\n    store_df = sales_by_store.loc[(store_id, slice(None))].copy().reset_index()\n    store_df = store_df.iloc[-n_samples:]\n    ax[i].plot(np.arange(n_samples), store_df[\"count\"].values, label=store_id)\n    \n    date_labels = store_df[\"date\"].values[::100]\n    x_ticks = np.arange(0, n_samples, 100)\n    ax[i].set_xticks(x_ticks)\n    ax[i].set_xticklabels(date_labels)\n    if i % 2 == 0: ax[i].set_ylabel(\"count\")\n    ax[i].legend()\n\nfig.tight_layout();\nplt.savefig(f\"{OUTPUT_BASE_BATH}/total_sales_by_store_timeseries.png\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "# Compare daily seasonalities across stores\ntotal_sales_by_store = data.groupby([\"date\", \"weekday\", \"store_id\"])[[\"count\"]].sum()\nav_weekday_sales = (\n    total_sales_by_store\n    .groupby([\"weekday\", \"store_id\"])\n    [[\"count\"]]\n    .mean()\n    .unstack(level=1)\n    .droplevel(level=0, axis=1)\n)\nstd_weekday_sales = (\n    total_sales_by_store\n    .groupby([\"weekday\", \"store_id\"])\n    [[\"count\"]]\n    .std()\n    .unstack(level=1)\n    .droplevel(level=0, axis=1)\n)\n\n\nstore_groups = [\n    [\"CA_1\", \"CA_2\", \"CA_3\", \"CA_4\"],\n    [\"TX_1\", \"TX_2\", \"TX_3\"],\n    [\"WI_1\", \"WI_2\", \"WI_3\"],   \n]\nfig, ax = plt.subplots(1, 3, figsize=(15, 3.5),)\nfor i, group in enumerate(store_groups):\n    for store in group:\n        ax[i].plot(\n            av_weekday_sales.index,\n            av_weekday_sales[store].values,\n            label=store,\n        )\n        ax[i].fill_between(\n            av_weekday_sales.index,\n            av_weekday_sales[store].values + std_weekday_sales[store].values,\n            av_weekday_sales[store].values - std_weekday_sales[store].values,\n            alpha=0.25,\n        )\n    ax[i].set(xlabel=\"weekday\", ylabel=\"count\")\n    ax[i].legend(ncols=len(group), fontsize=\"small\", loc=1)\n    \nfig.tight_layout();\nplt.savefig(f\"{OUTPUT_BASE_BATH}/total_sales_by_weekday_and_store.png\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": "# SALES BY CATEGORY",
            "metadata": {
                "execution": {
                    "iopub.status.busy": "2024-07-22T20:39:02.870765Z",
                    "iopub.execute_input": "2024-07-22T20:39:02.871155Z",
                    "iopub.status.idle": "2024-07-22T20:39:02.875995Z",
                    "shell.execute_reply.started": "2024-07-22T20:39:02.871125Z",
                    "shell.execute_reply": "2024-07-22T20:39:02.874832Z"
                }
            }
        },
        {
            "cell_type": "code",
            "source": "sales_by_category = data.groupby([\"cat_id\", \"date\"])[[\"count\"]].sum()\ncategory_ids = [\"FOODS\", \"HOBBIES\", \"HOUSEHOLD\"]\n\nn_samples = 500\nfig, ax = plt.subplots(3, 1, figsize=(8, 6), sharex=True)\nfor i, cat_id in enumerate(category_ids):\n    cat_df = sales_by_category.loc[(cat_id, slice(None))].copy().reset_index()\n    cat_df = cat_df.iloc[-n_samples:]\n    ax[i].plot(np.arange(n_samples), cat_df[\"count\"].values, label=cat_id)\n    \n    date_labels = cat_df[\"date\"].values[::100]\n    x_ticks = np.arange(0, n_samples, 100)\n    ax[i].set_xticks(x_ticks)\n    ax[i].set_xticklabels(date_labels)\n    ax[i].set_ylabel(\"total sales\")\n    ax[i].legend()\n\n\nfig.tight_layout();\nplt.savefig(f\"{OUTPUT_BASE_BATH}/total_sales_by_category_timeseries.png\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": "# SALES BY CATEGORY & STORE",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "sales_by_store_and_cat = data.groupby([\"store_id\", \"cat_id\", \"date\"])[[\"count\"]].sum()\nstore_ids = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\ncategory_ids = [\"FOODS\", \"HOBBIES\", \"HOUSEHOLD\"]\nn_samples = 500\n\nfig, ax = plt.subplots(5, 2, sharex=True, sharey=True, figsize=(15, 10))\nax = ax.flatten()\nfor i, store_id in enumerate(store_ids):\n    store_df = sales_by_store_and_cat.loc[store_id]\n    for cat_id in [\"FOODS\", \"HOBBIES\", \"HOUSEHOLD\"]:\n        cat_df = store_df.loc[cat_id].reset_index()\n        cat_df = cat_df.iloc[-n_samples:]\n        ax[i].plot(np.arange(n_samples), cat_df[\"count\"].values, label=(store_id, cat_id))\n\n    ax[i].legend(fontsize=\"small\", ncols=3)\n\n    date_labels = cat_df[\"date\"].values[::100]\n    x_ticks = np.arange(0, n_samples, 100)\n    ax[i].set_xticks(x_ticks)\n    ax[i].set_xticklabels(date_labels)\n    if i % 2 == 0: ax[i].set_ylabel(\"total sales\")\n\nfig.tight_layout();\nplt.savefig(f\"{OUTPUT_BASE_BATH}/total_sales_by_category_and_store_timeseries.png\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": "# SALES BY STORE & DEPARTMENT",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "n_samples = 500\nstore_ids = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\ndept_ids = ['HOBBIES_1', 'HOBBIES_2', 'HOUSEHOLD_1', 'HOUSEHOLD_2', 'FOODS_1', 'FOODS_2', 'FOODS_3']\nitem_ids_by_dept = {}\nfor dept_id in dept_ids:\n    item_ids = list(data[data[\"dept_id\"] == dept_id][\"item_id\"].unique())\n    item_ids_by_dept[dept_id] = item_ids\n\nav_store_dept_sales = data.groupby([\"store_id\", \"dept_id\", \"date\"])[[\"count\"]].mean()",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "store_id = 'WI_3'\nstore_df = data[data[\"store_id\"] == store_id]\n\nfig, ax = plt.subplots(len(dept_ids), 1, figsize=(10, 12), sharex=True)\ncolors = cm.viridis(np.linspace(0, 1, len(dept_ids)))\n\nfor d, dept_id in enumerate(dept_ids):\n    dept_df = store_df[store_df[\"dept_id\"] == dept_id]\n    item_ids = item_ids_by_dept[dept_id]\n    for item_id in tqdm(item_ids):\n        item_df = dept_df[dept_df[\"item_id\"] == item_id]\n        item_df = item_df.sort_values(by=\"d\")\n        item_df = item_df.iloc[-n_samples:]\n        ax[d].plot(\n            item_df[\"date\"].values,\n            item_df[\"count\"].values,\n            color=colors[d],\n            lw=0.2,\n            alpha=0.25,\n        )\n\n    av_sales = av_store_dept_sales.loc[store_id, dept_id]\n    av_sales = av_sales.reset_index().sort_values(by=\"date\")\n    av_sales = av_sales.iloc[-n_samples:]\n    axd_2 = ax[d].twinx()\n    axd_2.plot(\n        av_sales[\"date\"].values,\n        av_sales[\"count\"].values,\n        color=colors[d],\n        lw=2\n    )\n    axd_2.set(ylabel=\"mean sales\")\n\n    date_labels = av_sales[\"date\"].values[::100]\n    x_ticks = np.arange(0, n_samples, 100)\n    ax[d].set(xticks=x_ticks, xticklabels=date_labels)\n    ax[d].set(ylabel=\"sales\", title=dept_id)\n\nfig.tight_layout();\nplt.savefig(f\"{OUTPUT_BASE_BATH}/item_sales_by_dept_store_{store_id}_timeseries.png\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "sales_by_store_and_dept = data.groupby([\"store_id\", \"dept_id\", \"date\"])[[\"count\"]].sum()\nstore_ids = ['CA_1', 'CA_2', 'CA_3', 'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n\nn_samples = 500\n\nfig, ax = plt.subplots(5, 2, sharex=True, sharey=True, figsize=(15, 10))\nax = ax.flatten()\nfor i, store_id in enumerate(store_ids):\n    store_df = sales_by_store_and_dept.loc[store_id]\n    store_df = store_df.unstack(level=0).droplevel(level=0, axis=1)\n    store_df = store_df.iloc[-n_samples:]\n    ax[i] = store_df.plot(ax=ax[i])\n\n    if i % 2 == 0: ax[i].set_ylabel(\"total sales\")\n    ax[i].legend(fontsize=\"x-small\", ncols=4)\n    ax[i].set_title(store_id)\n\nfig.tight_layout();\nplt.savefig(f\"{OUTPUT_BASE_BATH}/total_sales_by_dept_and_store_timeseries.png\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": "# SALES BY ITEM ID & STORE",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": "dept_ids = list(data[\"dept_id\"].unique())\nstore_ids = list(data[\"store_id\"].unique())\nitem_ids_by_dept = {}\nfor dept_id in dept_ids:\n    item_ids = list(data[data[\"dept_id\"] == dept_id][\"item_id\"].unique())\n    item_ids_by_dept[dept_id] = item_ids",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "# Plot sales for different items\nn_items = 10\nfig, ax = plt.subplots(len(dept_ids), n_items, figsize=(len(dept_ids) * 3.5, n_items * 1.5), sharey=True)\nfor d, dept_id in enumerate(dept_ids):\n    print(f\"Plotting count distributions for {dept_id}\")\n    for i in tqdm(range(5)):\n        item_ids = np.random.choice(item_ids_by_dept[dept_id], size=n_items)\n        for i, item_id in enumerate(item_ids):\n            df_slice = data[(data[\"item_id\"] == item_id)]\n            counts, bins = np.histogram(df_slice[\"count\"].values, bins=max(df_slice[\"count\"].values))\n            ax[d, i].stairs(\n                counts / len(df_slice[\"count\"].values),\n                bins,\n                label=item_id\n            )\n    \n    for i in range(n_items):\n        ax[d, i].legend(fontsize='x-small')\n        ax[d, i].set(xlim=(-1, 20))\n    \n    ax[d, 0].set(ylabel=\"density\")\n\nfor i in range(n_items):\n    ax[-1, i].set(xlabel=\"count\")\n        \nfig.tight_layout();\nplt.savefig(f\"{OUTPUT_BASE_BATH}/count_dist_for_item_cross_section.png\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "# Plot sales for items by store\nn_items = 10\nfig, ax = plt.subplots(len(dept_ids), n_items, figsize=(len(dept_ids) * 3.5, n_items * 1.5), sharey=True)\nfor d, dept_id in enumerate(dept_ids):\n    print(f\"Plotting count distributions for {dept_id}\")\n    for s, store_id in tqdm(enumerate(store_ids)):\n        item_ids = np.random.choice(item_ids_by_dept[dept_id], size=n_items)\n        for i, item_id in enumerate(item_ids):\n            df_slice = data[(data[\"store_id\"] == store_id) & (data[\"item_id\"] == item_id)]\n            counts, bins = np.histogram(df_slice[\"count\"].values, bins=max(df_slice[\"count\"].values))\n            ax[d, i].stairs(\n                counts / len(df_slice[\"count\"].values),\n                bins,\n                label=store_id\n            )\n    \n    # Set plot properties for all plots of this dept\n    for i, item_id in enumerate(item_ids):\n        ax[d, i].set_title(item_id, fontsize='small')\n        ax[d, i].set_xlim((-1, 20))\n    \n    # ylabel for first column plots\n    ax[d, 0].set(ylabel=\"density\")\n\n# xlabels for last row plots\nfor i in range(n_items):\n    ax[-1, i].set(xlabel=\"count\")\n\nhandles, labels = ax[0,0].get_legend_handles_labels()\nfig.legend(handles, labels, loc='upper center', ncols=len(store_ids), bbox_to_anchor=[0.5, 1.02])\n        \nfig.tight_layout();\nplt.savefig(f\"{OUTPUT_BASE_BATH}/count_dist_for_item_cross_section_by_store.png\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": "fig, ax = plt.subplots(1, len(dept_ids), figsize=(len(dept_ids) * 3.5, 3.5), sharey=True)\nfor d, dept_id in enumerate(dept_ids):\n    print(f\"Plotting count distributions for {dept_id}\")\n    for i, item_id in tqdm(enumerate(item_ids_by_dept[dept_id])):\n        item_id_df = data[(data[\"item_id\"] == item_id)]\n        counts, bins = np.histogram(\n            item_id_df[\"count\"].values,\n            bins=max(item_id_df[\"count\"].values)\n        )\n        ax[d].stairs(\n            counts / len(item_id_df[\"count\"].values),\n            bins,\n            label=item_id,\n            color=\"gray\",\n            alpha=0.5,\n            lw=0.3,\n        )\n    ax[d].set(title=dept_id, xlabel=\"count\", xlim=(-1, 40))\n\nax[0].set(ylabel=\"density\")\n\nfig.tight_layout();\nplt.savefig(f\"{OUTPUT_BASE_BATH}/count_dist_for_items_by_dept.png\")",
            "metadata": {
                "trusted": true
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}